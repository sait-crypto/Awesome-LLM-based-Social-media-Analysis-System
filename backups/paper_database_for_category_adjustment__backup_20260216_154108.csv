doi,title,authors,publish date,category,summary motivation,summary innovation,summary method,summary conclusion,summary limitation,paper url,project url,conference,title translation,analogy summary,pipeline figure,abstract,contributor,notes,show in readme,status,submission time,conflict marker,invalid fields,is placeholder
doi,title,authors,date,category,summary_motivation,summary_innovation,summary_method,summary_conclusion,summary_limitation,paper_url,project_url,conference,title_translation,analogy_summary,pipeline_figure,abstract,contributor,notes,show_in_readme,status,submission_time,conflict_marker,invalid_fields,is_placeholder
10.48550/arXiv.2407.07061,Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence,"Weize Chen*, Ziming You*, Ran Li*, Yitong Guan*, Chen Qian, Chenyang Zhao Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun",2024-10-04,Base Techniques,先前的multi-agent系统的局限性，系统化平台化程度不足（缺乏第三方集成支持，无法分布式，通信协议和状态转换依赖于硬编码）,将互联网的开放、分布式、服务化思想引入，构建一种标准化、可扩展的支持分布式、异构的智能体集成与通信协议。,服务器：智能体注册（分发系统提示词）、管理已注册智能体（专家）、专家发现服务、群聊管理和消息传递；客户端：包装具体智能体，提供通信接口；三层结构；通信即可嵌套灵活群聊；群聊采用**有限状态机**管理流程；平台初始化与注册->任务触发团队形成->内部嵌套协作,在 GAIA 基准测试中，仅使用四个基础 ReAct 智能体即达到最佳性能；在 RAG 任务中，基于 GPT-3.5 的 IoA 达到或超过 GPT-4 的性能,实验中存在冗余消息，通信 Token 消耗增加近一倍，这证明agent作为对话者而非执行者的本质能力区别；单点服务器可能存在瓶颈；智能体通过注册获取提示词成为不同专家，仍高度依赖人工实验设计，且这种专家的能力是否可靠,https://openreview.net/forum?id=o1Et3MogPw,https://github.com/OpenBMB/IoA,The Thirteenth International Conference on Learning Representations,"[AI generated] **智能体互联网：构建异构智能体网络以实现协同智能**

**说明：**
1.  **核心概念直译**：将 ""Internet of Agents"" 直译为“智能体互联网”，准确对应其借鉴互联网理念的核心创新，并与物联网（IoT）等术语形成概念类比，符合学术语境。
2.  **副标题意译与优化**：将 ""Weaving a web of heterogeneous agents for collaborative intelligence"" 意译为“构建异构智能体网络",agent互联网，升级版ABM系统，采用类似互联网思想，C/S架构，分布化、服务化、平台化,figures/IoA.png;figures/IoA2.png,"The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. We will release our code to facilitate further research.",anonymous,每个agent被一个客户端包装；服务器不是agent，它只做四件事：注册、发现、建群、路由；相对于传统ABM，这是一个更大型的服务系统，该方法通过基于任务的“群聊”方式组织问题解决，相对传统回合制方式更加自由。本身也是一个高度可扩展系统。问题在于智能体通过注册获取提示词成为不同专家，仍依赖手工设计，且这种专家的能力是否可靠。对于社会模拟任务相对于传统方法有何决定性优势仍未可知,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1609/icwsm.v19i1.35800,Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Understanding,"Vibhor Agarwal,Arjoo Gupta,Suparna De,Nishanth Sastry",2025-06-07,Base Techniques;Comment Generation,"Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.
[翻译] 针对在线言论固有的稀疏性和语境依赖性问题，即传统模型往往难以捕捉对话树内的隐式依赖关系，或因无差别地引入上下文而产生噪声","The proposal of ""Conversation Kernels,"" a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the ""right"" structural neighborhood rather than merely increasing context length.
[翻译] 提出了“对话核”这一通用机制，利用灵活的拓扑形状来检索细粒度的结构化对话上下文；其独到之处在于通过识别“正确”的结构邻域而非单纯增加上下文长度来理解对话。","An end-to-end trained probabilistic framework that first retrieves relevant structural windows (e.g., ancestors, neighbors) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.
[翻译] 一个端到端训练的概率框架，首先通过相似度评分检索相关的结构化窗口（如祖先、邻居），随后通过对RoBERTa编码器生成的预测分布进行加权求和（边缘化），从而融合这些上下文信息。[通俗核心]针对目标评论构建回复树，取几个窗口（如父评论窗口、1跳窗口），每个窗口中所有评论与原评论拼接，并进行预测，最后不同窗口与原评论的相关性经过softmax作为权重，对所有预测置信度加权和，得到最终结果","Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs (GPT-3.5/4) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.
[翻译] 在Slashdot数据上的广泛实验表明，上下文增强的核机制在准确率上比基线Transformer模型高出20%，并在特定分类任务中超越了通用大语言模型（GPT-3.5/4），揭示了不同任务需要截然不同的结构化上下文模式。","The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.
[翻译] 该方法严重依赖显式的树状回复线索，限制了其在扁平化讨论形式中的适用性，并且在上下文稀疏的对话早期阶段可能面临冷启动挑战。",https://ojs.aaai.org/index.php/ICWSM/article/view/35800,https://netsys.surrey.ac.uk/datasets/slashdot/,ICWSM,[AI generated] **中文标题：对话核：一种学习在线对话理解相关上下文的灵活机制**,"A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.[翻译] 一个灵活的结构化上下文发现框架，通过学习关注对话树内相关的拓扑邻域来增强对话理解能力。",figures/Conversation Kernels.png;figures/Conversation Kernels2.png,"Understanding online conversations has attracted research attention with the growth of social networks and online discussion forums. Content analysis of posts and replies in online conversations is difficult because each individual utterance is usually short and may implicitly refer to other posts within the same conversation. Thus, understanding individual posts requires capturing the conversational context and dependencies between different parts of a conversation tree and then encoding the context dependencies between posts and comments/replies into the language model.

To this end, we propose a general-purpose mechanism to discover appropriate conversational context for various aspects about an online post in a conversation, such as whether it is informative, insightful, interesting or funny. Specifically, we design two families of Conversation Kernels, which explore different parts of the neighborhood of a post in the tree representing the conversation and through this, build relevant conversational context that is appropriate for each task being considered. We apply our developed method to conversations crawled from slashdot.org, which allows users to apply highly different labels to posts, such as `insightful', `funny', etc., and therefore provides an ideal experimental platform to study whether a framework such as Conversation Kernels is general-purpose and flexible enough to be adapted to disparately different conversation understanding tasks.

We perform extensive experiments and find that context-augmented conversation kernels can significantly outperform transformer-based baselines, with absolute improvements in accuracy up to 20% and up to 19% for macro-F1 score. Our evaluations also show that conversation kernels outperform state-of-the-art large language models including GPT-4. We also showcase the generalizability and demonstrate that conversation kernels can be a general-purpose approach that flexibly handles distinctly different conversation understanding tasks in a unified manner.",anonymous,"【基础技术―上下文感知方法】可用于所有内容理解任务，论文中的实验用的是是否受欢迎二分类
[引用文]To better bridge pattern recognition with social interaction structures, Agarwal et al. (2025) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods (e.g., ancestors or siblings) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.
[翻译]
为了更好地将模式识别与社会互动结构联系起来，Agarwal等人 (2025) 提出了“对话核（Conversation Kernels）”，这是一种旨在从对话树中提取细粒度上下文的端到端框架。通过动态检索并加权特定的拓扑邻域（如祖先或兄弟节点）而非摄入线性历史，该方法有效地过滤了社会讨论中固有的噪声。这种结构选择性证明，结合显式的互动拓扑对于准确解读在线对话的性质至关重要，其表现甚至超越了像 GPT-4 这样的通用大语言模型。",TRUE,,2026-01-23 19:15:29,FALSE,,FALSE
10.48550/arXiv.2402.18950,PopALM: Popularity-aligned language models for social media trendy response prediction,"Erxin Yu1,Jing Li1?,Chunpu Xu",2024-05,Comment Generation,"Motivated by the need to simulate mainstream public reactions on social media, this study identifies response popularity―quantified by ""like"" counts―as a crucial yet noisy signal for aligning language models with collective preferences.
[翻译] 出于模拟社交媒体上主流公众反应的需求，本研究将通过“点赞数”量化的回复流行度视为一种关键信号，旨在将语言模型与群体偏好对齐，尽管该指标本身存在噪声。","The authors propose PopALM, which introduces a curriculum learning-enhanced Proximal Policy Optimization (CL-PPO) strategy to robustly align generation with popularity by mitigating the significant noise inherent in
[翻译] 作者提出了 PopALM，该模型引入了一种增强了课程学习的近端策略优化（CL-PPO）策略，通过缓解原始互动指标中存在的显著噪声，稳健地将生成内容与流行度对齐。","The framework follows a sequential ""SFT-RM-RL"" pipeline, where the CL-PPO algorithm specifically incorporates reward enhancement, ranking, and self-paced sampling to transition training from high-confidence samples to complex scenarios, thereby filtering environmental noise.
[翻译] 该框架遵循顺序的“有监督微调-奖励建模-强化学习”流程，其中CL-PPO算法特别结合了奖励增强、排序和自步采样机制，以实现从高置信度样本到复杂场景的过渡训练，从而过滤环境噪声。","Experiments on a large-scale Weibo benchmark demonstrate that PopALM outperforms state-of-the-art baselines in both automatic metrics and human evaluation, generating responses that are more specific and aligned with public sentiment.
[翻译] 在大规模微博基准上的实验表明，PopALM 在自动指标和人工评估方面均优于最先进的基线模型，生成的回复更加具体且符合公众情绪。","A primary limitation lies in the reliance on ""like"" counts as the sole proxy for popularity, which may not fully capture multi-dimensional user engagement or generalize across different platform algorithms.
[翻译] 一个主要的局限性在于依赖“点赞数”作为衡量流行度的单一代理指标，这可能无法完全捕捉多维度的用户参与度，也难以在不同平台的算法间泛化。",https://aclanthology.org/2024.lrec-main.1127/,https://github.com/ErxinYu/PopALM,LREC-COLING 2024,[AI generated] **中文标题：** PopALM：面向社交媒体热门回复预测的流行度对齐语言模型,先练“选手”（SFT），再练“裁判”（RM），最后让“裁判”指导“选手”训练（RL）,figures/PopALM.png,"Social media platforms are daily exhibiting millions of events. To preliminarily predict the mainstream public reaction to these events, we study trendy response prediction to automatically generate top-liked user replies to social media events. While previous works focus on generating responses without factoring in popularity, we propose Popularity-Aligned Language Models (PopALM) to distinguish responses liked by a larger audience through reinforcement learning. Recognizing the noisy labels from user “likes”, we tailor-make curriculum learning in proximal policy optimization (PPO) to help models capture the essential samples for easy-to-hard training. In experiments, we build a large-scale Weibo dataset for trendy response prediction, and its results show that PopALM can help boost the performance of advanced language models.",anonymous,"[备注]该论文在会议上没有doi，使用的是arxiv版的doi【经典微调+RL范式】噪声指的是受各种因素影响，点赞数的具体值难以公平对比<br>[引用文]
In the pursuit of simulating collective social behaviors rather than merely generating coherent text, aligning models with mainstream public sentiment becomes critical. However, social feedback signals, such as ""like"" counts, are often fraught with noise stemming from non-content factors like posting time or author influence. To address this, PopALM (Yu et al., 2024) proposes a PPO algorithm enhanced by curriculum learning. This approach operates on the premise that models should prioritize high-confidence samples―where popularity strongly correlates with content quality―to establish a robust foundation. By adopting a self-paced sampling strategy that transitions from easy-to-learn instances to noisier ones, PopALM effectively mitigates the significant noise inherent in using ""like"" counts as popularity indicators.
[翻译]
在追求模拟群体社会行为而非仅仅生成连贯文本的过程中，将模型与主流公众情绪对齐变得至关重要。然而，诸如“点赞数”之类的社会反馈信号往往充满了源自非内容因素（如发布时间或作者影响力）的噪声。针对这一问题，PopALM (Yu et al., 2024) 提出了一种增强了课程学习的PPO算法。该方法基于这样一个前提：模型应优先学习那些置信度高（即流行度与内容质量强相关）的样本，从而打下坚实的基础。通过采用一种从易学样本到噪声样本过渡的自步采样策略，PopALM 有效缓解了点赞数作为热度指标存在大量噪声的问题。",TRUE,,2026-01-21 13:27:05,FALSE,,FALSE
10.1609/icwsm.v19i1.35813,Susceptibility of Communities Against Low-Credibility Content in Social News Websites,"Yigit Ege Bayiz, Arash Amini, Radu Marculescu, Ufuk Topcu",2025-06-07,Community Detection;Misinformation Analysis,"The proliferation of low-credibility and highly biased content on social news platforms like Reddit necessitates moving beyond individual fake-news detection to understanding systemic vulnerabilities at the community level. This study is motivated by the need to identify ideological communities that are particularly susceptible to such content.
[翻译]
Reddit等社交新闻平台上低可信度和高偏见内容的泛滥，要求研究超越个体假新闻检测，转向理解社区层面的系统性脆弱性。本研究旨在识别对此类内容特别易感的意识形态社区。","Its primary innovation lies in a novel framework that detects ideological communities based on user stance-aware embeddings, rather than platform-defined groups. It uniquely combines fine-tuned LLM-based stance detection, a learned affine transformation for contrary opinions, and spectral clustering to map communities onto a credibility-bias space for susceptibility analysis.
[翻译]
其主要创新在于一个新颖的框架，该框架基于用户立场感知嵌入而非平台定义的群组来检测意识形态社区。它独特地结合了基于微调LLM的立场检测、用于相反观点的仿射变换学习以及谱聚类，将社区映射到可信度-偏见空间以进行易感性分析。","The methodology first embeds post titles via SBERT. It then employs a LoRA-tuned LLM to detect user stances (favor/against/neutral) in comments relative to parent posts. Comment embeddings are assigned based on these stances, using the post embedding or its learned affine-transformed negation. User embeddings are derived by averaging their comment embeddings. User-level credibility and bias scores are similarly aggregated from stance-adjusted scores of news sources (per Ad Fontes Media). Finally, spectral clustering on user embeddings reveals communities, whose susceptibility is profiled via the aggregated scores.
[翻译]
该方法首先通过SBERT嵌入帖子标题，然后使用经LoRA微调的大语言模型检测评论中用户相对于父帖的立场（支持/反对/中立）。根据这些立场，使用帖子嵌入或其学习到的仿射变换否定结果为评论分配嵌入向量。通过对用户的评论嵌入取平均得到用户嵌入。用户级的可信度与偏见分数以类似方式，根据立场调整后的新闻源分数进行聚合。最后，对用户嵌入进行谱聚类以揭示社区，并通过聚合分数分析其易感性。","The study demonstrates significant variance in susceptibility across the identified ideological clusters. For instance, the proportion of users prone to low-credibility content differed by 34 percentage points between the most and least susceptible clusters. A correlation was observed between the constructed user embedding space and the credibility-bias space, indicating that latent representations capture susceptibility-related features.
[翻译]
研究表明，所识别的不同意识形态聚类之间的易感性存在显著差异。例如，对低可信度内容易感的用户比例在最具易感性和最不具易感性的聚类间相差34个百分点。研究观察到构建的用户嵌入空间与可信度-偏见空间之间存在相关性，表明潜在表征捕捉到了与易感性相关的特征。","Limitations include reliance on a single external source for news credibility/bias labels, potential platform-specific biases in the Reddit dataset, and the inherent assumption equating opposition to high-credibility content with low-credibility preference. Future work suggests incorporating comment semantics and user interaction graphs for richer embeddings.
[翻译]
局限性包括依赖单一外部来源进行新闻可信度/偏见标注、Reddit数据集中可能存在的平台特定偏见，以及将反对高可信度内容等同于偏好低可信度内容的内在假设。未来工作建议融入评论语义和用户交互图以获得更丰富的嵌入表征。",https://ojs.aaai.org/index.php/ICWSM/article/view/35813,,ICWSM,"[AI generated] **中文标题：社交新闻网站中社区对低可信度内容的易感性研究**

**说明：**
此翻译力求准确传达原标题的学术内涵，同时符合中文表达习惯：
1.  **“Susceptibility”** 译为“易感性”，在信息传播和公共卫生等领域是常用术语，能准确表达“易受影响程度”的含义。
2.  **“Communities”** 译为“社区”，直接对应原文在社交网络语境下的指代。
3","This work presents a computational framework for identifying and profiling ideological communities on social news platforms based on their susceptibility to low-credibility and biased content, using stance-derived user embeddings.
[翻译]
本研究提出了一个计算框架，利用立场导出的用户嵌入，来识别社交新闻平台上的意识形态社区并刻画其对于低可信度和偏见内容的易感性特征。",figures/SC-LCC.png,"Social news websites, such as Reddit, have evolved into prominent platforms for sharing and discussing news. A key issue on social news websites is the formation of low-credibility communities, which often lead to the spread of highly biased or uncredible news. We develop a method to identify communities prone to uncredible or highly biased news within a social news website. We employ a user embedding pipeline that detects user communities based on their stances toward posts and news sources. We then project each community onto a credibility-bias space and analyze the distributional characteristics of each projected community to identify those that have a high risk of adopting beliefs with low credibility or high bias. This approach also enables the prediction of individual users' susceptibility to low-credibility content based on their community affiliation. Our results show that latent space clusters effectively indicate the credibility and bias levels of their users, with significant variance observed across clusters---a 34% difference in the users' susceptibility to low-credibility content and a 8.3% difference in the users' susceptibility to high political bias.",anonymous,"【使用**立场检测**得到用户嵌入、然后**谱聚类用于社区分析**】[方法概括]
1.帖子进行embedding获得特征向量，帖子的所有回复进行相对于帖子的立场检测。2.为评论分配特征向量（相同同帖子，相反为仿射，中立为均值）。3.对每个用户的所有评论进行特征聚合得到用户特征向量（特征向量只用于聚类）。4.通过比较源媒体数据为帖子内容分配可信度和偏见分数，根据对应评论的立场为其分配两个值，同样的聚合得到用户两值。5.根据用户特征向量进行聚类，结合用户两值获得聚类的两值，进行分析[引用文]Situated within the evolving scholarly focus that bridges pattern recognition and the simulation of collective social dynamics, Bayiz et al. (2025) shift the unit of analysis from individual users or sources to ideological communities to study their susceptibility to misinformation. This is achieved by constructing stance-aware user embeddings―where the stance of comments towards posts, identified via stance detection, is used to infer latent representations―followed by the application of spectral clustering to discover communities based on ideological alignment. They examine these communities within a credibility-bias space, revealing significant inter-community differences in susceptibility to misinformation
[翻译]
置于连接模式识别与集体社会动态仿真的学术演进焦点中，Bayiz等人（2025）将分析单元从个体用户或信源转向意识形态社区，以研究其对错误信息的易感性。这是通过构建立场感知的用户嵌入来实现的――其中，通过立场检测识别出的评论对帖子的立场被用于推断潜在表征――随后应用谱聚类来发现基于意识形态一致性的社区。他们在可信度-偏见空间中研究这些社区，揭示了对错误信息易感性的显著社群间差异。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
10.1007/s42979-024-03055-1,Behavior Based Group Recommendation from Social Media Dataset by Using Deep Learning and Topic Modeling,"Md. Saddam Hossain Mukta, Jubaer Ahmed, Mohaimenul Azam Khan Raiaan, Nur Mohammad Fahad, Muhammad Nazrul Islam, Nafiz Imtiaz, ...",2024-07-16,Community Detection;User Profiling,"This research addresses the underexplored task of identifying user groups based on shared psychological attributes, proposing that similarity in Basic Human Values, derived from social media, can predict aligned real-world behaviors.

[翻译]
本研究旨在解决一个未被充分探索的任务：基于共享的心理属性识别用户群体，并提出从社交媒体衍生的基本人类价值观的相似性可以预测一致的真实世界行为。","Its novelty lies in fusing graph neural networks with psycholinguistic analysis to model user values (e.g., hedonism) for group recommendation, introducing both graph-based (GHV) and context-psychological (CPHV) clustering methods.

[翻译]
其创新点在于融合图神经网络与心理语言分析，为用户价值观（如快乐主义）建模以进行群体推荐，并引入了基于图的（GHV）和上下文-心理的（CPHV）两种聚类方法。","The methodology employs two parallel tracks: GHV uses GNNs and spectral clustering on user value scores, while CPHV further integrates topic modeling (LSA/BERT) and psychological lexicon (LIWC) analysis to refine group identification.

[翻译]
该方法采用双轨并行：GHV在用户价值分数上应用GNN和谱聚类，而CPHV进一步整合主题建模（LSA/BERT）和心理词典（LIWC）分析以优化群体识别。","The proposed CPHV method achieved superior clustering performance (SCC: 76%, ICC: 60%), validating that users grouped by high hedonism scores share common interests in areas like movies and technology.

[翻译]
所提出的CPHV方法取得了优越的聚类性能（SCC：76%，ICC：60%），验证了按高快乐主义分数分组的用户在电影、技术等领域具有共同的兴趣。","Limitations include reliance on sufficient digital footprints and a static view of values. Future work suggests dynamic modeling and extension to other value dimensions and platforms.

[翻译]
局限性包括对足够数字足迹的依赖和对价值观的静态审视。未来工作建议进行动态建模，并将方法扩展到其他价值维度与平台。",https://link.springer.com/10.1007/s42979-024-03055-1,,Sn Comput. Sci.,"[AI generated] **中文标题：** 基于深度学习与主题建模的社交媒体数据集行为驱动群体推荐研究

**说明：** 该翻译准确传达了原标题的学术内涵与技术要点：
- “Behavior Based” 译为“行为驱动”，突出研究以用户行为数据为基础；
- “Group Recommendation” 译为“群体推荐”，符合推荐系统领域术语；
- “Social Media Dataset” 译为“社交媒体数据集”，体现数据来源；
- “Deep Learning and Topic Modeling” 译为“深度学习","TLDR: A graph dataset is compiled using the strongest correlation among the features and then a graph clustering technique is applied to identify a suitable hedonist group (i.e., one dimension of values) for users’ recommendations, which is validated in real life by introducing two hypotheses.",figures/BBGR.png;figures/BBGR-GHV.png;figures/BBGR-CPHV.png,"Abstract
            
              In this digital era, users frequently share their thoughts, preferences, and ideas through social media, which reflect their Basic Human Values. Basic Human Values (aka values) are the fundamental aspects of human behavior, which define what we consider important, and worth having and pursue them. Existing studies identify the values of individuals from different social network usages such as Facebook and Reddit. However, discovering the similarity (or diversity) of value priorities among the members in a group is important since we can reveal many interesting insights such as finding a set of target customers, identifying the chain of misdeed groups, searching for similar acquaintances in workplaces, etc. In this paper, a graph dataset is compiled using the strongest correlation among the features and then we apply a graph clustering technique to identify a suitable hedonist group (i.e., one dimension of values) for users’ recommendations. Then, we also propose a behavior based (i.e., value ) group recommendation technique by analyzing users’ contextual and psychological attributes. Finally, we validate those group members in real life by introducing two hypotheses. In particular, we analyze the tweets of a total of 1140 users collected from Twitter. We obtain a substantial
              intra-cluster correlation coefficient (ICC)
              and
              silhouette clustering coefficient (SCC)
              scores of 65% and 76%, respectively, among the members in our discovered group.",anonymous,"[引用文]Mukta et al. (2024) advance beyond surface-level analytics by modeling the latent psychological attributes of users, specifically their Basic Human Values, from social media traces. Their fusion of GNNs with psychometric analysis exemplifies a shift towards cognitive-level understanding of user collectives, forming a crucial bridge between pattern recognition and the simulation of motivation-driven group behaviors.
[翻译]
Mukta等人（2024）通过从社交媒体痕迹中建模用户的潜在心理属性（特别是其基本人类价值观），推进了超越表层分析的研究。他们将GNN与心理测量分析相融合，例证了向认知层面理解用户集体的转变，这在模式识别与动机驱动的群体行为仿真之间构成了关键的桥梁。",TRUE,unread,2026-01-29 10:07:59,FALSE,,FALSE
10.1007/s11280-022-01116-0,A text and GNN based controversy detection method on social media,"Samy Benslimane, Jér?me Azé, Sandra Bringay, Maximilien Servajean, Caroline Mollevi",2023-03-01,Controversy Analysis,"Existing controversy detection approaches often treat structural patterns and semantic content in isolation or rely solely on post-reply trees, neglecting the critical role of user entities and their interaction dynamics in driving social polarization.
[翻译] 现有的争议检测方法通常将结构模式和语义内容割裂处理，或单纯依赖帖子回复树结构，忽视了用户实体及其交互动态在驱动社会极化中的关键作用。","The study shifts focus from message-level dependencies to user-centric interaction graphs. A key innovation lies in aggregating individual comments into unified user features, which allows the model to encode network-level information and actor stances simultaneously within the graph structure.
[翻译] 该研究将焦点从消息级依赖关系转移到了以用户为中心的交互图上。其主要创新在于将分散的评论聚合为统一的用户特征，这使得模型能够在图结构中同时编码网络层面的信息和行动者的立场。","The framework constructs a user graph where node features are initialized with BERT-encoded textual features aggregated from user historical comments. Subsequently, two GNN methods―Hierarchical Representation Learning via differentiable pooling (HRL-GCN) or Attention-based Representation Learning (ARL-GAT)―are employed to capture structural patterns, ultimately performing graph-level binary classification.
[翻译] 该框架构建了一个用户图，其中节点特征初始化为从用户历史评论中聚合的BERT编码文本特征。随后，利用通过可微池化实现的分层表示学习（HRL-GCN）或基于注意力的表示学习（ARL-GAT）两种GNN方法来捕捉结构模式，最终完成图级二分类。","Empirical evaluations on Reddit and Twitter datasets demonstrate that the hierarchical pooling strategy (HRL-GCN) achieves superior performance by effectively capturing community-level structures, validating that combining aggregated user semantics with interaction topology significantly outperforms structure-only baselines.
[翻译] 在Reddit和Twitter数据集上的实证评估表明，分层池化策略（HRL-GCN）通过有效捕捉社区级结构实现了更优的性能，证实了结合聚合的用户语义与交互拓扑结构显著优于仅依赖基线的结构。","Standard pre-trained language models perform suboptimally on noisy Twitter data without domain-specific fine-tuning. Additionally, the approach is currently limited to homogeneous graphs, suggesting that future work could explore heterogeneous graph modeling to integrate multiple interaction types.
[翻译] 标准预训练语言模型在未经领域微调的情况下在噪声较大的Twitter数据上表现欠佳，以及仅限于同构图，未来可以探索异构图建模以整合多种交互类型。",https://doi.org/10.1007/s11280-022-01116-0,https://github.com/gvrkiran/controversy-detection,World Wide Web,[AI generated] **中文标题：** 一种基于文本与图神经网络的社交媒体争议检测方法,"To identify controversial topics from discussion inputs, the method aggregates historical comments into user node features to encode intrinsic user and network attributes, and subsequently applies GNN methods on the user-centric social network to achieve binary classification.
[翻译] 在争议话题识别中，输入是一段讨论，为了编码用户本身特征和用户网络特征，将用户历史评论聚合为用户节点特征，在以用户为节点的社交网络上，进行GNN方法，实现二分类。",figures/HRL-GCN.png,"Expressed opinions on social media frequently cause a controversy. Controversial content refers to content that attracts different opinions and interrogations, implying interaction between communities. Its automatic identification remains a challenging task. Most of the existing approaches rely on the graph structure of discussion and/or the content of messages but did not deeply explore the recent advances on Graph Neural Network (gnn) to predict if a discussion is controversial or not. This paper aims to combine both user interactions present in the graph structure of a discussion and the discussion text features to detect controversy. We rely on sampling techniques to reduce the size of large graphs and augment the graph training set if needed. Our proposed approach relies then on gnn techniques to encode the initial (or sampled) graph in an embedding vector before performing a graph classification task. We propose two controversy detection strategies. The first one is based on a hierarchical graph representation learning to take advantage of hierarchical relationships that could exist between users. The second one is based on the attention mechanism, which allows each user node to give more or less importance to its neighbors when computing node embeddings. We present different experiments conducted with data sources collected from both Reddit and Twitter to show the applicability of our approach to different social networks. Conducted experiments show the positive impact of combining textual features and structural information in terms of performance and accuracy.",anonymous,"[引用文]To better capture the dynamics of social polarization in the field of controversial content identification, Benslimane et al. (2023) shift from content-based analysis to a user-centric perspective. They argue that the structural relationships between users and the users' inherent attributes are pivotal for understanding controversy. Unlike traditional methods that treat posts as isolated nodes, their approach constructs a user interaction graph where node representations are derived by aggregating the semantic content of each user’s historical comments. This design encodes complex network information and individual stances into a unified feature space. By employing GNN methods such as Hierarchical Graph Representation Learning (HRL-GCN), the model performs multi-layer aggregation on the graph to capture high-level community structures, demonstrating that the fusion of user features with social interaction patterns provides an effective mechanism for controversy identification in social media.
[翻译] 为了更好地在争议内容识别领域捕捉社会极化的动态，Benslimane等人 (2023) 的方法从基于内容的分析转变为以用户为中心视角。他们认为，用户之间的结构关系以及用户本身的属性对于理解争议至关重要。与将帖子视为孤立节点的传统方法不同，他们的方法构建了一个用户交互图，其中节点表示通过聚合每个用户历史评论的语义内容得到。这种设计将复杂的网络信息和个人立场编码到了统一的特征空间中。通过采用分层图表示学习（HRL-GCN）等GNN的方法，该模型对图进行多层聚合以捕捉高层级的社区结构，证明了用户特征与社交交互模式的融合为识别社交媒体中的争议识别提供了一种有效的机制。",TRUE,unread,2026-01-29 10:07:59,FALSE,,FALSE
10.18653/v1/2023.emnlp-main.420,Event causality extraction via implicit cause-effect interactions,"Jintao Liu,Zequn Zhang,Kaiwen Wei,Zhi Guo,Xian Sun,Li Jin,Xiaoyu Li",2023,Event Extraction,现有ECE（事件因果关系抽取）方式没有充分利用原因事件和结果事件之间的相互作用。这本可以为因果关系推理提供关键线索,论文解耦ECE的两个任务（论元抽取、结果事件预测），并使用OT进行教师模型和学生模型的细粒度对齐，增强了因果事件之间的隐式联系,基于模板的条件生成（输入基于模板附有特定特权信息的prompt，使预训练模型BART（基于transformer）输出基于模板的结构化的文本，用于后续微调）->教师-学生知识蒸馏（微调了两个教师模型负责不同任务：事件论元抽取、结果事件预测）->因果最优传输CEOT（相关损失并入蒸馏损失，参与蒸馏训练，学生模型与教师模型细粒度对齐）,ECE任务中显著提升了性能，ECE-CCKS数据集上比此前最优方法F1值提高了8.39%,多教师蒸馏机制和复杂的OT计算显著增加了模型训练阶段的成本,https://aclanthology.org/2023.emnlp-main.420,,Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,"[AI generated] 中文标题：基于隐式因果交互的事件因果关系抽取

（该翻译准确传达了原标题“Event causality extraction via implicit cause-effect interactions”的核心含义，即通过捕捉原因与结果事件之间隐性的相互作用来实现因果关系抽取。“隐式因果交互”的表述符合计算机科学与自然语言处理领域的学术用语习惯，且与摘要中“Implicit Cause-Effect interaction (ICE) framework”的命名直接对应，保持了术语一致性。）",通过OT强制学生模型与教师模型对齐,figures/ICE.png,"Event Causality Extraction (ECE) aims to extract the cause-effect event pairs from the given  text, which requires the model to possess a  strong reasoning ability to capture event causalities. However, existing works have not adequately exploited the interactions between the  cause and effect event that could provide crucial clues for causality reasoning. To this end,  we propose an Implicit Cause-Effect interaction  (ICE) framework, which formulates ECE as  a template-based conditional generation problem. The proposed method captures the implicit intra- and inter-event interactions by incorporating the privileged information (ground  truth event types and arguments) for reasoning, and a knowledge distillation mechanism  is introduced to alleviate the unavailability of  privileged information in the test stage. Furthermore, to facilitate knowledge transfer from  teacher to student, we design an event-level  alignment strategy named Cause-Effect Optimal Transport (CEOT) to strengthen the semantic interactions of cause-effect event types and  arguments. Experimental results indicate that  ICE achieves state-of-the-art performance on  the ECE-CCKS dataset.",anonymous,"?这个方法为什么可以解决问题？
    核心方法是使用优秀的专家模型对小模型进行微调，结合了5个小损失函数（两个来源于OT），以尽可能保证知识迁移效果

?有什么值得注意的细节吗？
    ??论文为什么选择训练两个承担不同任务的教师模型，一起蒸馏出目标模型的方法
        这几乎是进行微调特化用于该下游任务的必然选择
        因为需要训练两个能力（子任务）：文本论元抽取能力（事件内交互）和事件结果联系能力（事件间）
        两个子任务需要分别调整数据集的输入，为他们分配不同的特权信息，从而避免混淆和出现“作弊”（看到这个子任务不应看到的特权信息）",TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1609/icwsm.v19i1.35818,Identifying and Investigating Global News Coverage of Critical Events Such as Disasters and Terrorist Attacks,"Erica Cai1,Xi Chen1,Reagan Grey Keeney1,Ethan Zuckerman1,Brendan O'Connor1,Przemyslaw A.Grabowicz",2025-06-07,Event Extraction,"Traditional computational studies of news coverage bias are hindered by the inability to efficiently and accurately identify articles discussing the same real-world event across massive, multilingual corpora without costly, language-specific training data.
[翻译] 传统的新闻覆盖偏见计算研究面临一个瓶颈：难以在不依赖昂贵且语言特定的训练数据前提下，高效、精确地从大规模多语言语料库中识别出讨论同一现实事件的报道。","It introduces FAME, a scalable, zero-shot framework that utilizes minimalist “event fingerprints” (time, location, class) to match news articles across languages via a two-stage screening pipeline, eliminating the need for annotated training data.
[翻译] 其提出了FAME框架，这是一个可扩展的零样本方法。它利用极简的“事件指纹”（时间、地点、类别），通过一个两级筛选流程实现跨语言新闻文章匹配，从而无需标注训练数据。","The method employs a two-stage pipeline: 1) Heuristic keyword filtering to recall candidate articles within a time window, followed by 2) a semantic filter using a large language model (LLM) for question-answering to achieve high-precision event-article matching.
[翻译] 该方法采用一个两级处理流程：1）基于关键词的启发式过滤，用于在时间窗口内召回候选文章；2）利用大语言模型进行问答的语义过滤器，以实现高精度的事件-文章匹配。","FAME achieved state-of-the-art performance (average F1 > 94% across English, Spanish, and French), and its application revealed that media attention to disasters and terrorist attacks is strongly correlated with death tolls, the GDP of the affected country, and bilateral trade volume.
[翻译] FAME取得了先进的性能（在英、西、法语上平均F1>94%）。应用该方法发现，媒体对灾害和恐怖袭击的关注度，与死亡人数、受影响国家的GDP以及双边贸易额高度相关。","The reliance on a two-stage screening pipeline depends on the quality of external event databases (e.g., GTD), and the minimalist fingerprint design, while enabling scalability, can lead to ambiguities for events with similar metadata.
[翻译] 两级筛选流程依赖于外部事件数据库（如GTD）的质量，且极简的指纹设计虽然保证了可扩展性，但可能导致具有相似元数据的事件产生匹配歧义。",https://ojs.aaai.org/index.php/ICWSM/article/view/35818,https://github.com/social-info-lab/disaster_event_analysis,ICWSM,"[AI generated] **中文标题：** 灾害与恐怖袭击等重大事件的全球新闻报道识别与调查分析

**说明：** 该翻译准确传达了原标题的核心信息，即“识别”与“调查/分析”全球新闻报道。采用“重大事件”概括“Critical Events”，并使用“灾害与恐怖袭击”具体化其范畴，符合中文论文标题简洁、专业的学术风格。",两级匹配筛选要求新闻，关键词匹配初步筛选（关键词通过启发式方法获得）->事件抽取,figures/FAME.png;figures/FAME2.png,"Comparative studies of news coverage are challenging to conduct because methods to identify news articles about the same event in different languages require expertise that is difficult to scale. We introduce an AI-powered method for identifying news articles based on an event fingerprint, which is a minimal set of metadata required to identify critical events. Our event coverage identification method, FINGERPRINT TO ARTICLE MATCHING FOR EVENTS (FAME), efficiently identifies news articles about critical world events, specifically terrorist attacks and several types of natural disasters. FAME does not require training data and is able to automatically and efficiently identify news articles that discuss an event given its fingerprint: time, location, and class (such as storm or flood). The method achieves state-of-the-art performance and scales to massive databases of tens of millions of news articles and hundreds of events happening globally. We use FAME to identify 27,441 articles that cover 470 natural disaster and terrorist attack events that happened in 2020. To this end, we use a massive database of news articles in three languages from MediaCloud, and three widely used, expert-curated databases of critical events: EM-DAT, USGS, and GTD. Our case study reveals patterns consistent with prior literature: coverage of disasters and terrorist attacks correlates to death counts, to the GDP of a country where the event occurs, and to trade volume between the reporting country and the country where the event occurred. We share our NLP annotations and cross-country media attention data to support the efforts of researchers and media monitoring organizations.",anonymous,"[引用文]Cai et al. (2025) propose the FAME framework, aiming to efficiently and accurately identify news reports on specific events from massive, multilingual news streams. Its innovation lies in a two-stage, zero-shot methodology. The framework first applies heuristic filtering using event “fingerprints” (time, location, category) to retrieve candidate articles, followed by a refinement step leveraging an LLM for precise event-article matching. This approach enables scalable, training-free analysis, successfully linking over 27,000 articles to 470 global events.
[翻译]
Cai等人(2025)提出的FAME框架，旨在从海量、多语言的新闻流中高效、精确地识别出关于特定事件的报道，其创新在于一种两级、零样本的方法。它首先使用事件“指纹”（时间、地点、类别）进行启发式过滤以获取候选文章，随后通过基于LLM进行事件匹配。这实现了可扩展的、免训练的分析，成功将超过2.7万篇文章与470个全球事件关联起来。",TRUE,,2026-01-15 20:03:34,FALSE,,FALSE
10.1609/aaai.v38i16.29730,Is a Large Language Model a Good Annotator for Event Extraction?,"Ruirui Chen1,Chengwei Qin,Weifeng Jiang,Dongkyu Choi",2024-03-24,Event Extraction,在提示中使用上下文示例来引导大语言模型生成与目标基准数据集分布和标注模式对齐的新样本，从而直接解决数据不平衡问题。,"[AI generated] Employing LLMs as expert annotators with in-context examples to generate distribution-aligned data, directly addressing data scarcity and imbalance.
[翻译]
利用大语言模型作为专家标注器，结合上下文示例生成分布对齐的数据，直接解决数据稀缺与不平衡问题。",针对“训练样本稀少的（长尾）事件类型，使用合适的prompt模板（包含真实例子）要求LLM生成标注，进行质量筛选，合并到原始数据集，最终通过实验与合并前的效果比较,"Fine-tuning models like BERT-CRF on the GPT-4-augmented ACE 2005 data led to consistent F1-score improvements in both Event Detection and Argument Extraction tasks, proving the high utility of LLM-generated annotations as a training resource.
[翻译]
在GPT-4增强的ACE 2005数据上微调BERT-CRF等模型，在事件检测和论元抽取任务中均带来了F1分数的持续提升，证明了LLM生成的标注作为训练资源的高效用。",高度依赖LLM自身能力,https://ojs.aaai.org/index.php/AAAI/article/view/29730,https://github.com/shiqinghuayi19/LLMforEvent,AAAI,"[AI generated] **中文标题：大语言模型是事件抽取的优秀标注工具吗？**

**翻译说明：**
1.  **准确性**：标题直译核心问题，明确点明研究焦点――评估大语言模型在事件抽取任务中作为“标注工具”的潜力与效能。
2.  **专业性**：采用“事件抽取”、“标注工具”等标准领域术语，符合自然语言处理领域的学术表达习惯。
3.  **学术风格**：以疑问句式呈现","[AI generated] This method uses LLMs as expert annotators to generate high-quality training data, akin to employing a master chef to prepare ingredients for a specialized dish. [翻译]该方法利用大语言模型作为专家标注员生成高质量训练数据，如同聘请主厨为特色菜肴准备食材。",figures/Annotator for Event Extraction.png,"Event extraction is an important task in natural language processing that focuses on mining event-related information from unstructured text. Despite considerable advancements, it is still challenging to achieve satisfactory performance in this task, and issues like data scarcity and imbalance obstruct progress. In this paper, we introduce an innovative approach where we employ Large Language Models (LLMs) as expert annotators for event extraction. We strategically include sample data from the training dataset in the prompt as a reference, ensuring alignment between the data distribution of LLM-generated samples and that of the benchmark dataset. This enables us to craft an augmented dataset that complements existing benchmarks, alleviating the challenges of data imbalance and scarcity and thereby enhancing the performance of fine-tuned models. We conducted extensive experiments to validate the efficacy of our proposed method, and we believe that this approach holds great potential for propelling the development and application of more advanced and reliable event extraction systems in real-world scenarios.",anonymous,"[引用文]To overcome data scarcity in specialized tasks within event extraction, large language models (LLMs) can be utilized as data augmentation tools. The work by Chen et al. (2024) exemplifies this by employing LLMs as structured annotators: using few-shot prompting with models such as GPT-4, they generate synthetic training data aligned with target schemas. This augmentation strategy effectively alleviates long-tail data imbalance and delivers measurable performance improvements for downstream extraction models.
[翻译]
为克服事件抽取领域专业任务中的数据稀缺问题，可以将大语言模型作为数据增强工具。Chen等人(2024)的研究通过将大语言模型用作结构化标注器来展示这一点：他们使用少量示例提示GPT-4等模型，生成与目标模式对齐的合成训练数据。这种增强策略有效缓解了长尾数据不平衡问题，为下游抽取模型带来了可观的性能提升。",TRUE,,2026-01-15 20:03:34,FALSE,,FALSE
10.1109/TPAMI.2022.3144993,"Reinforced, Incremental and Cross-Lingual Event Detection From Social Messages","Hao Peng,Ruitong Zhang,Shaoning Li,Yuwei Cao,Shirui Pan,Philip S. Yu",2023-01-01,Event Extraction,"Event detection in social media streams is challenged by ambiguous event features, dispersed text content, multilingualism, and long-tail distribution, where traditional methods struggle in dynamic, incremental, and cross-lingual scenarios.
[翻译]
社交媒体流中的事件检测面临事件特征模糊、文本内容分散、多语言和长尾分布等挑战，传统方法在动态、增量和跨语言场景中表现不佳。","Its core advancement lies in enabling continuous, cross-lingual social event detection through a life-cycle mechanism that dynamically updates both the message graph and model without full retraining.
[翻译]
其核心进步在于，通过一个能动态更新消息图与模型而无需全量重训练的生命周期机制，实现了持续的、跨语言的社交事件检测。","The pipeline includes: (1) constructing a weighted multi-relational graph from social messages; (2) using multi-agent reinforcement learning to learn relation-specific thresholds for neighbor selection and aggregation; (3) training with balanced sampling-based contrastive learning; (4) clustering via DRL-optimized DBSCAN; and (5) enabling incremental updates and cross-lingual transfer via parameter preservation.
[翻译]
流程包括：(1) 从社交消息构建加权多关系图；(2) 使用多智能体强化学习学习关系特定的阈值以进行邻居选择和聚合；(3) 通过基于平衡采样的对比学习训练；(4) 使用DRL优化的DBSCAN聚类；(5) 通过参数保留支持增量更新和跨语言迁移。","On Twitter streams, FinEvent significantly outperforms baselines in offline, online, and cross-lingual detection tasks, with improvements of 14%-118% in NMI, 8%-170% in AMI, and 2%-21% in ARI, demonstrating robust performance across diverse settings.
[翻译]
在Twitter流数据上，FinEvent在离线、在线和跨语言检测任务中显著优于基线，NMI提升14%-118%，AMI提升8%-170%，ARI提升2%-21%，展现了在不同设置下的鲁棒性能。","Limitations include high computational complexity, dependence on external translation for low-resource languages, potential knowledge forgetting during incremental updates, and limited generalization due to evaluation primarily on Twitter data.
[翻译]
局限性包括计算复杂度高、对低资源语言依赖外部翻译、增量更新中可能遗忘早期知识，以及由于主要基于Twitter数据评估导致的泛化性有限。",https://ieeexplore.ieee.org/document/9693189/,https://github.com/RingBDStack/FinEvent,IEEE Transactions on Pattern Analysis and Machine Intelligence,"[AI generated] **中文标题：** 基于强化、增量与跨语言学习的社交媒体消息事件检测

**说明：** 该翻译准确传达了原标题“Reinforced, Incremental and Cross-Lingual Event Detection From Social Messages”的核心要素：
*   **“Reinforced”** 译为“强化”，对应论文中使用的强化学习方法。
*   **“Incremental”** 译为“增量”，体现了模型对流式数据的持续学习能力。
*   **“Cross","[AI generated] FinEvent is like a multilingual, self-optimizing news curator that continuously learns and adapts from live social media streams. [翻译] FinEvent 如同一个多语言的、自优化的新闻策展人，能从实时社交媒体流中持续学习与适应。",figures/FinEvent.png,"Detecting hot social events (e.g., political scandal, momentous meetings, natural hazards, etc.) from social messages is crucial as it highlights significant happenings to help people understand the real world. On account of the streaming nature of social messages, incremental social event detection models in acquiring, preserving, and updating messages over time have attracted great attention. However, the challenge is that the existing event detection methods towards streaming social messages are generally confronted with ambiguous events features, dispersive text contents, and multiple languages, and hence result in low accuracy and generalization ability. In this paper, we present a novel reinForced, incremental and cross-lingual social Event detection architecture, namely FinEvent, from streaming social messages. Concretely, we first model social messages into heterogeneous graphs integrating both rich meta-semantics and diverse meta-relations, and convert them to weighted multi-relational message graphs. Second, we propose a new reinforced weighted multi-relational graph neural network framework by using a Multi-agent Reinforcement Learning algorithm to select optimal aggregation thresholds across different relations/edges to learn social message embeddings. To solve the long-tail problem in social event detection, a balanced sampling strategy guided Contrastive Learning mechanism is designed for incremental social message representation learning. Third, a new Deep Reinforcement Learning guided density-based spatial clustering model is designed to select the optimal minimum number of samples required to form a cluster and optimal minimum distance between two clusters in social event detection tasks. Finally, we implement incremental social message representation learning based on knowledge preservation on the graph neural network and achieve the transferring cross-lingual social event detection. We conduct extensive experiments to evaluate the FinEvent on Twitter streams, demonstrating a significant and consistent improvement in model quality with 14%C118%, 8%C170%, and 2%C21% increases in performance on offline, online, and cross-lingual social event detection tasks.",anonymous,"[引用文]Peng et al. (2023) proposed FinEvent, a reinforced, incremental, and cross-lingual detection architecture. Its core innovation lies in a life-cycle learning mechanism that supports incremental adaptation: the system dynamically updates a multi-relational message graph, employs multi-agent reinforcement learning to continuously optimize aggregation strategies, and utilizes a DRL-optimized clustering module to self-adjust parameters for each data block―enabling the model to co-evolve with the social data stream.

[翻译]
Peng等人（2023）提出了FinEvent，一个强化的增量与跨语言检测架构。其核心创新在于一个支持增量适应的生命周期学习机制：系统动态更新多关系消息图，并采用多智能体强化学习持续优化聚合策略，同时通过DRL优化的聚类模块实现每个数据块的自调参，使模型能随社交数据流共同演化。[notes]根据消息间的多种语义关系构建异构消息网络网络->通过多智能体强化学习得到每个关系的保留阈值（多智能体强化指的是每个智能体负责一个关系），对于每个消息节点的每个关系图，通过保留阈值剪除掉对聚合作用低的邻居节点->先图内聚合，再图间聚合得到每个节点的特征向量->使用Triplet Loss（拉近同类消息、推远异类消息）和Global-Local Loss（保持图结构的全局一致性）两个损失函数进行GNN训练，得到不同事件区分能力->使用DRL-DBSCAN进行自适应聚类，得到事件分类输出->支持增量更新与跨语言迁移",TRUE,,2026-01-15 20:03:34,FALSE,,FALSE
10.1609/aaai.v39i12.33430,"Towards Effective, Efficient and Unsupervised Social Event Detection in the Hyperbolic Space","Xiaoyan Yu,Yifan Wei,Shuaishuai Zhou,Zhiwei Yang,Li Sun,Hao Peng,Liehuang Zhu*,Philip S. Yu",2025-04-11,Event Extraction,"Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures.
[翻译]：由于用户生成内容规模庞大、动态性强且关系结构复杂，社交媒体平台上的社交事件检测面临显著挑战。现有方法在处理海量消息流时常效率低下，且在捕捉层次化事件结构方面表达能力有限。","The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanism―semantic-based anchor construction and graph sparsification―and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts.
[翻译]：本文提出HyperSED，一种新颖的无监督框架，通过基于语义的锚点构建与图稀疏化两阶段压缩机制降低计算开销，并利用在双曲空间中学习的可微划分树表示事件聚类。该方法无需预设聚类数量，即可有效捕捉层次化与嵌套的事件结构。","The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters.
[翻译]：该框架首先构建语义锚点图以压缩消息节点并简化关系边，随后将锚点图映射至双曲空间，采用双曲图自编码器学习结构感知表示，最终通过可微结构信息最小化构建并优化划分树，得到层次化事件簇","Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines.
[翻译]：在真实Twitter数据集上的实验表明，HyperSED在归一化互信息、调整互信息与调整兰德指数上均取得具有竞争力的性能，同时相比前沿无监督基线，计算效率提升最高达37倍。","The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control.
[翻译]：由于锚点构建中可能出现语义不同消息被错误分组的情况，该模型在部分消息块上的性能可能略有下降。此外，效率提升在一定程度上以聚类粒度控制的精细度为代价。",https://ojs.aaai.org/index.php/AAAI/article/view/33430,,AAAI,"[AI generated] 中文标题：面向双曲空间中高效、有效且无监督的社交事件检测

（说明：该翻译遵循以下原则：
1. 专业术语准确对应：""Hyperbolic Space""译为""双曲空间""，""Unsupervised""译为""无监督""
2. 学术风格保持：采用""面向...的...""句式体现研究导向性
3. 逻辑结构清晰：通过顿号连接""高效、有效""突出框架的多重优势
4. 领域",通过两层压缩减少开销（简化边、节点聚合为锚点），通过划分树表示事件聚类,figures/HyperSED.png,"The vast, complex, and dynamic nature of social message data has posed challenges to social event detection (SED). Despite considerable effort, these challenges persist, often resulting in inadequately expressive message representations (ineffective) and prolonged learning durations (inefficient). In response to the challenges, this work introduces an unsupervised framework, HyperSED (Hyperbolic SED). Specifically, the proposed framework first models social messages into semantic-based message anchors, and then leverages the structure of the anchor graph and the expressiveness of the hyperbolic space to acquire structure- and geometry-aware anchor representations. Finally, HyperSED builds the partitioning tree of the anchor message graph by incorporating differentiable structural information as the reflection of the detected events. Extensive experiments on public datasets demonstrate HyperSED's competitive performance, along with a substantial improvement in efficiency compared to the current state-of-the-art unsupervised paradigm. Statistically, HyperSED boosts incremental SED by an average of 2%, 2%, and 25% in NMI, AMI, and ARI, respectively; enhancing efficiency by up to 37.41 times and at least 12.10 times, illustrating the advancement of the proposed framework.",anonymous,"[notes]为什么用双曲空间？ 现实世界的事件和话题往往具有层次结构（如“体育 -> 足球 -> 世界杯”）。双曲空间的几何特性（指数级增长的空间）能更自然、更紧凑地嵌入这种树状或层次化数据。<br>[通俗核心]通过消息各属性的相同性（用户、标签）构建网络；通过方法精简网络边【压缩1】；根据相关性将相似信息聚类为锚点，锚点之间有节点相连的构建边，得到锚点图【压缩2】；映射到双曲空间进行自监督重建训练（图自编码器GAE）获得聚合模型；模型输出根据特征向量距离自底向上聚合形成划分树，该树即表示消息各层级聚类关系。每个聚类节点都代表了一个某层级事件（如体育、世界杯、新冠）[引用文]HyperSED demonstrates how structural and geometric inductive biases can be integrated into scalable unsupervised learning (Yu et al., 2025). By compressing the message graph into semantic anchors and learning a partitioning tree in hyperbolic space―where internal nodes formed through bottom?up aggregation represent concrete event categories―the framework not only enhances detection efficiency but also captures the multi?scale organization of social events.

[翻译]HyperSED展示了如何将结构与几何归纳偏置融入可扩展的无监督学习（Yu et al., 2025）。该框架通过将消息图压缩为语义锚点，并在双曲空间中学习划分树――其中通过自底向上聚合形成的内部节点代表具体的事件类别――不仅提升了检测效率，还捕捉了社交事件的多尺度组织特征。",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.1007/978-981-99-8181-6_33,A Three-Stage Framework for Event-Event Relation Extraction with Large Language Model,"Feng Huang,Qiang Huang,YueTong Zhao,ZhiXiao Qi,BingKun Wang,YongFeng Huang,SongBin Li",2024,Event Extraction,"Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks.
[翻译]
传统事件关系提取方法严重依赖标注数据，成本高且难以扩展。大语言模型在时序与因果关系任务中的零样本能力尚未充分挖掘。","A three-stage framework (ThreeEERE) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training.
[翻译]
提出三阶段框架ThreeEERE，融合改进的Auto-CoT提示策略与本地知识检索，实现无需任务特定训练的零样本事件-关系提取。",构建示范样例（包含cot部分）->检索本地知识->取高于阈值的答案,"ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets.
[翻译]
在多个数据集上的事件、时序与因果关系提取任务中，ThreeEERE优于标准提示方法，并达到或超越若干监督基线。","Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base.
[翻译]
示范中生成的推理链与标准答案之间可能存在不一致，可能引入噪声并影响模型稳定性。且依赖于本地知识库构建",https://link.springer.com/10.1007/978-981-99-8181-6_33,,Neural Information Processing,"[AI generated] **中文标题：** 基于大语言模型的事件-事件关系提取三阶段框架

**说明：** 此翻译准确传达了原标题的核心信息：
1.  **“A Three-Stage Framework”** 译为 **“三阶段框架”**，清晰直接。
2.  **“for Event-Event Relation Extraction”** 译为 **“事件-事件关系提取”**，符合计算机科学和自然语言处理领域的专业术语习惯（“关系抽取”或“",通过结构化prompt构建的，无训练零样本的，依赖于本地知识库的，事件抽取方法,figures/ThreeEERE.png,"Expanding the parameter count of a large language model (LLM) alone is insufficient to achieve satisfactory outcomes in natural language processing tasks, specifically event extraction (EE), event temporal relation extraction (ETRE), and event causal relation extraction (ECRE). To tackle these challenges, we propose a novel three-stage extraction framework (ThreeEERE) that integrates an improved automatic chain of thought prompting (Auto-CoT) with LLM and is tailored based on a golden rule to maximize event and relation extraction precision. The three stages include constructing examples in each category, federating local knowledge to extract relationships between events, and selecting the best answer. By following these stages, we can achieve our objective. Although supervised models dominate for these tasks, our experiments on three types of extraction tasks demonstrate that utilizing these three stages approach yields significant results in event extraction and event relation extraction, even surpassing some supervised model methods in the extraction task.",anonymous,"[notes]聚类只是为了选择最接近聚类中心的测试样本，作为示范样例（因为接近中心意味着更能代表该聚类语义特征），之后的操作就是输入测试样例和这些示范样例（答案部分替换为标准答案）以及检索得到的本地知识，最终取超过阈值的结果<br>[引用文]The three-stage framework proposed by Huang et al. (2024) integrates chain-of-thought reasoning with localized knowledge, demonstrating the feasibility of eliciting zero-shot inference of complex event relations from large language models through meticulously designed prompts, without the need for supervised fine-tuning.
[翻译]
Huang等人（2024）提出的三阶段框架，将思维链推理与本地化知识相结合，证明了通过精心设计的提示词，无需监督微调即可从大语言模型中激发出对复杂事件关系的零样本推断能力。",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.1609/aaai.v37i4.25614,TOT: Topology-Aware Optimal Transport for Multimodal Hate Detection,"Linhao Zhang，Li Jin，Xian Sun，Guangluan Xu，Zequn Zhang,Xiaoyu Li,Nayu Liu,Qing Liu,Shiyao Yan",2023-06-26,Hate Speech Analysis,为了解决多模态仇恨检测中因” 隐式对齐” 和” 模态鸿沟” 导致的图像和文本跨模态语义对齐难题,将OT用于特征对齐，将句子级对齐细粒化至向量级，为后续工作提供了“显式对齐+结构推理”的范式,最优传输 + 拓扑结构推理方法 TOT：CLIP 方法统一表征映射->最优传输optimal transport (OT)将隐式联系细粒化为向量级（这是一个数学计算过程，不涉及需要学习的参数）->类GNN迭代捕捉自身语义联系（类自注意力）（因为向量间距离意义明确）->残差连接,"达成了在两个有害 Meme 检测数据集（Harm-C, Harm-P）上的最先进性能；",对齐和推理仍局限于特征层面，未上升到语义单元（如事件、概念）层面，OT过程为冻结无法训练的，可以训练其参数以实现更好的对齐；对于幽默等类似隐式表达容易误判,https://ojs.aaai.org/index.php/AAAI/article/view/25614,,Proceedings of the AAAI Conference on Artificial Intelligence,[AI generated] **中文标题：** TOT：面向多模态仇恨检测的拓扑感知最优传输方法,强化恶意Meme的图像与文本之间的语义对齐，使用OT方法建立特征向量间的可解释联系,figures/TOT.png,"Multimodal hate detection, which aims to identify the harmful content online such as memes, is crucial for building a wholesome internet environment. Previous work has made enlightening exploration in detecting explicit hate remarks. However, most of their approaches neglect the analysis of implicit harm, which is particularly challenging as explicit text markers and demographic visual cues are often twisted or missing. The leveraged cross-modal attention mechanisms also suffer from the distributional modality gap and lack logical interpretability. To address these 
semantic gap issues, we propose TOT: a topology-aware optimal transport framework to decipher the implicit harm in memes scenario, which formulates the cross-modal aligning problem as solutions for optimal transportation plans. Specifically, we leverage an optimal transport kernel method to capture complementary information from multiple modalities. The kernel embedding provides a non-linear transformation ability to reproduce a kernel Hilbert space (RKHS), which reflects significance for eliminating the distributional modality gap. Moreover, we perceive the topology information based on aligned representations to conduct bipartite graph path reasoning. The newly achieved state-of-the-art performance on two publicly available benchmark datasets, together with  further visual analysis, demonstrate the superiority of TOT in capturing implicit cross-modal alignment.",anonymous,最优传输OT负责回答“图片的哪个部分和文本的哪个词相关？”（实现统一且对齐的表示，从而建立跨模态的显式联系，OT方法是可解释的）。【即将CLIP生成的特征矩阵级别的对齐，细化为特征向量间的对齐，两个特征矩阵会更相像。这种显式对齐能力本质上来源于CLIP实现的隐对齐】；拓扑建模负责回答“这些相关的部分组合在一起，表达了什么更深层的含义？”（捕捉文本（图片）中互相有联系的token（patch），进行模态内的深度推理）。【这种类似GNN的方法本质上是更有层次性的自注意力机制，天然适用于处理关系型数据（图结构）】；本质上是将CLIP建立的隐式对齐细粒化为向量层级的显式对齐，进而得以使用图推理进一步学习内部联系,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1109/TMM.2025.3581795,Flexible optimal transport with contrastive graphical modeling for multimodal hate detection,"Linhao Zhang，Li Jin，Xiaoyu Li,Xian Sun,Senior Member,IEEE,Xin Wang,Zequn Zhang,Jian Liu，Zhicong Lu，Graduate Student Member,IEEE,and Guangluan Xu",2025,Hate Speech Analysis,社媒中隐含仇恨内容检测困难，传统方法难以实现跨模态隐式对齐。,相对于同团队的TOT是改进,相对于同团队的TOT:1.OT的目标域不再是另一模态的特征，而是可学习的统一嵌入（OT引入可学习的参数，它们是两个模态各自对应的目标特征矩阵 $T_v$ 和 $T_t$）；2.引入了图对比学习损失，显式约束一致性（比较两个图的相似程度作为一个损失，之后才进行类GNN聚合（动态拓扑推理））,在Harm-C、Harm-P、MET-Meme三个数据集上取得SOTA，显著提升准确率与F1,对于幽默等类似隐式表达容易误判,https://ieeexplore.ieee.org/abstract/document/11045556,,IEEE Transactions on Multimedia,"[AI generated] **中文标题：** 基于对比图建模与灵活最优传输的多模态仇恨内容检测

**说明：**  
此翻译在准确传达原文技术核心（Flexible Optimal Transport、contrastive graphical modeling）的同时，兼顾了学术表达的简洁性与专业性。采用“灵活最优传输”以突出方法对非显式跨模态关联的适应性，并通过“对比图建模”明确其结构化表征优化机制，整体符合计算机视觉与自然语言处理交叉领域的术语规范。","[AI generated] This method bridges multimodal gaps like a flexible translator, aligning implicit hateful memes through optimal transport and contrastive graphs. [翻译]该方法通过最优传输和图对比学习，像灵活的翻译官一样弥合模态鸿沟，对齐隐含仇恨表情包。",figures/FLOT1.png;figures/FLOT.png,"Multimodal hate detection plays a crucial role in maintaining harmonious online environments by identifying harmful content, such as hateful memes. Although previous research has made significant progress in detecting explicit hate speech, there remains a critical gap in analyzing implicit hate, which is particularly challenging due to the absence of explicit harmful text claims or demographic visual cues. Despite the promising results based on cross-modal attention, previous methods may suffer from the distributional modality gap caused by the non-literal associations between multimodal elements, which lacks apparent alignment in implicit hateful contents. In this work, we propose a novel framework: Flexible Optimal Transport (FLOT) to capture the non-literal cross-modal alignment for multimodal hate in the context of memes. FLOT formulates the problem of cross-modal alignment as finding optimal transportation plans, which leverages a kernel method to capture complementary information from multiple modalities. The kernel embeddings reproduce a kernel Hilbert space (RKHS) to serve as a non-linear transformation of alignment, which effectively reduces the distributional modality gap with more interpretability. Moreover, we established topological structures with contrastive modeling for the aligned representations, which are optimized to achieve comprehensive alignment between different modalities, and facilitate local reasoning based on multimodal elements. Experimental results have demonstrated that our FLOT achieved state-of-the-art performance on three publicly available benchmark datasets. Furthermore, extensive qualitative analysis confirms the superior ability of FLOT in capturing implicit cross-modal alignment.",anonymous,,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.18653/v1/2024.acl-long.291,Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning,"Jingbiao Mei,Jinghong Chen,Weizhe Lin,Bill Byrne,Maarcus Tomalin",2024,Hate Speech Analysis,现有CLIP等模型对仇恨表情包的图像-文本的细微差异（如“混淆样本”）敏感度不足，导致的误判。,对于易混淆的难例（与当前样本相似度最高但标签相反的），使用**动态检索**方式单拉出来，与**伪黄金正样本**（和当前样本相似度最高的标签相同的）成对，作为正反例进行对比学习。从而解决问题,"1. 使用冻结的CLIP编码器提取图文特征；
2. 通过Faiss检索动态获取同类相似样本（伪黄金正样本）与异类相似样本（困难负样本）作为正反例；
3. 结合正反例对比损失（RGCLL）与交叉熵损失训练MLP；
4. 实现逻辑分类与KNN检索分类两种分类器，后者通过相似度加权投票进行预测。",在HatefulMemes数据集上达到 AUROC 87.0%（SOTA），超越Flamingo-80B等大型多模态模型,仇恨言论的定义具有争议性与文化依赖性；系统对 细微面部表情 识别能力有限；依赖数据标注质量，可能存在标注偏差。,https://aclanthology.org/2024.acl-long.291,,ACL 2024,"[AI generated] **中文标题：** 通过检索引导的对比学习提升仇恨表情包检测性能

**说明：** 该翻译准确传达了原标题的技术核心（检索引导的对比学习方法）与研究目标（提升仇恨表情包检测），符合计算机科学领域，特别是多模态内容分析与仇恨言论检测方向的学术表达规范，风格专业、简洁。",专题强化：难学样本单拉出来与正例进行对比学习，从而提高识别能力,figures/RGCL.png,"Hateful memes have emerged as a significant concern on the Internet. Detecting hateful memes requires the system to jointly understand the visual and textual modalities. Our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in memes that are vital for correct hatefulness classification. We propose constructing a hatefulness-aware embedding space through retrieval-guided contrastive training. Our approach achieves state-of-the-art performance on the HatefulMemes dataset with an AUROC of 87.0, outperforming much larger fine-tuned large multimodal models. We demonstrate a retrieval-based hateful memes detection system, which is capable of identifying hatefulness based on data unseen in training. This allows developers to update the hateful memes detection system by simply adding new examples without retraining ― a desirable feature for real services in the constantly evolving landscape of hateful memes on the Internet.",anonymous,,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1609/icwsm.v19i1.35837,Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets,"Tommaso Giorgi*,Lorenzo Cima*,Tiziano Fagni,Marco Avvenuti,Stefano Cresci",2025-06-07,Hate Speech Analysis,该领域需要大量人工标注，存在固有的主观性bias问题，需要系统性的研究,"The authors introduce a novel methodological framework on the Measuring Hate Speech corpus that quantifies bias through ""Intensity"" and ""Prevalence"" metrics without relying on ground truth, uniquely isolating the interplay between specific annotator profiles and target groups.
[翻译] 指标设计：提出了偏差强度（Intensity, ??）和偏差普遍性（Prevalence, ??），无需Ground Truth即可衡量相对偏差（将**其余所有标注者（Reference Group）**的共识作为基准）。<br>LLM对齐分析：评估了角色扮演LLM在“复现标注偏差”任务上的能力","Leveraging a large-scale dataset with rich demographic attributes, the methodology employs a comparative analysis using confusion matrices to measure relative labeling discrepancies between demographic groups, subsequently evaluating open-source LLMs via role-playing prompts to assess their alignment with human bias patterns.
[翻译]通过**混淆矩阵**（行代表不具备该属性，列代表具备该属性）对比特定属性群体在评价特定属性受害者时的标签差异。计算偏差强度和普遍性\n使用**prompt**引导LLM进行相同任务以对比","Quantitative analysis reveals that while human annotators exhibit significant ""in-group"" hypersensitivity and demographic-specific labeling variations, persona-based LLMs demonstrate a limited correlation with these human biases, failing to accurately mirror the complex social prejudices inherent in human data.
[翻译] 人类偏差：存在显著的“组内高敏度”（即倾向于高估针对自身群体的仇恨），受人口统计学交互影响严重（如年轻人倾向低估仇恨，老年人倾向高估）。<br>LLM表现：M表现出自身偏差，但未能有效复现人类的特定偏差（相关性极低），**欠缺对齐能力**（高估代表更敏感）","The study's limitations include data scarcity for specific minority groups which constrains statistical significance, and a reliance solely on prompting strategies without fine-tuning, which may restrict the models' capacity for deep behavioral mimicry.
[翻译] 该研究的局限性包括特定少数群体的数据稀缺限制了统计显著性，以及仅仅依赖提示策略而没有进行微调，这可能限制了模型的深度行为模仿能力。",https://ojs.aaai.org/index.php/ICWSM/article/view/35837,,ICWSM,"[AI generated] **中文标题：仇恨言论标注中的人类与大型语言模型偏见：标注者与目标群体的社会人口学分析**

**说明：**
- 该翻译准确传达了原标题的核心要素：“Human and LLM Biases”（人类与LLM偏见）、“Hate Speech Annotations”（仇恨言论标注）以及“Socio-Demographic Analysis of Annotators and Targets”（针对标注者与目标群体的社会人口学分析）。
- 采用“大型语言模型”这一通用学术",仇恨言论分析中的数据集标注如何受主观偏见影响，提示词引导的角色扮演LLM能否复刻这种偏见,figures/HateAnaBias.png,"The rise of online platforms exacerbated the spread of hate speech, demanding scalable and effective detection. However, the accuracy of hate speech detection systems heavily relies on human-labeled data, which is inherently susceptible to biases. While previous work has examined the issue, the interplay between the characteristics of the annotator and those of the target of the hate are still unexplored. We fill this gap by leveraging an extensive dataset with rich socio-demographic information of both annotators and targets, uncovering how human biases manifest in relation to the target's attributes. Our analysis surfaces the presence of widespread biases, which we quantitatively describe and characterize based on their intensity and prevalence, revealing marked differences. Furthermore, we compare human biases with those exhibited by persona-based LLMs. Our findings indicate that while persona-based LLMs do exhibit biases, these differ significantly from those of human annotators. Overall, our work offers new and nuanced results on human biases in hate speech annotations, as well as fresh insights into the design of AI-driven hate speech detection systems.",anonymous,"[引用句]Serving as a foundational critique within the transition from static classification to dynamic social simulation, Giorgi et al. (2025) demonstrate that although human perception of hate speech is fundamentally shaped by the interplay between annotator and target demographics, current persona-based LLMs fail to faithfully emulate these emergent sociological biases, highlighting a critical gap in the development of realistic AI agents.
[翻译] 作为从静态分类向动态社会仿真过渡过程中的一项基础性批判研究，Giorgi等人（2025）证明，尽管人类对仇恨言论的感知从根本上受标注者与目标人口统计特征交互作用的影响，但当前的基于角色的LLM无法忠实地模拟这些涌现的社会学偏差，突显了构建逼真AI智能体方面的一个关键差距。",TRUE,,2026-01-15 20:03:34,FALSE,,FALSE
10.1609/aaai.v39i27.35032,Pre-trained Behavioral Model for Malicious User Prediction on Social Platform,"Meng Jiang, Wenjie Wang, Shaofeng Hu, Kaishen Ou, Zhenjing Zheng, Fuli Feng",2025-04-11,Malicious User Detection,"Current supervised methods heavily rely on scarce labeled data, while existing self-supervised approaches often fail to capture complex repetitive and sporadic camouflaged patterns in user behavior sequences.
[翻译] 现有的监督学习方法严重依赖稀缺的标注数据，而现有的自监督方法往往难以捕捉用户行为序列中复杂的重复性模式和零星的伪装模式。","Distinct from content-based approaches, this work focuses exclusively on user behavior sequences, introducing behavior consistency and local disruption augmentations to specifically target repetitive and sporadic malicious patterns.
[翻译] 与基于内容的方法不同，该工作专注于用户行为序列，引入了行为一致性增强和局部破坏增强策略，专门针对重复性和零星的恶意行为模式。","The framework employs a three-stage self-supervised pre-training pipeline based on BERT, integrating masked behavior reconstruction, contrastive learning for pattern recognition, and a pseudo-malicious user sampling strategy to refine representations.
[翻译] 该框架采用基于BERT的三阶段自监督预训练流程，集成了掩码行为重建、用于模式识别的对比学习以及伪恶意用户采样策略以优化特征表示。","Evaluated on a billion-scale industrial dataset from Weixin, the model demonstrates superior performance in both malicious user detection and classification tasks compared to graph-based and sequence-based baselines, particularly in cold-start scenarios.
[翻译] 在微信的十亿级工业数据集上进行的评估显示，该模型在恶意用户检测和分类任务中均表现出优于基于图和基于序列的基线模型的性能，尤其是在冷启动场景下。","The current iteration relies solely on behavior ID sequences, neglecting potential semantic information from generated content and structural signals from social interaction graphs.
[翻译] 当前版本仅依赖于行为ID序列，忽略了生成内容中潜在的语义信息以及社交互动图中的结构性信号。",https://ojs.aaai.org/index.php/AAAI/article/view/35032,,AAAI,"[AI generated] **中文标题：** 面向社交平台恶意用户预测的预训练行为模型

**说明：** 此翻译力求准确、专业，符合学术论文标题的规范。它清晰传达了原文的核心要素：“预训练”（Pre-trained）、“行为模型”（Behavioral Model）、“恶意用户预测”（Malicious User Prediction）和“社交平台”（Social Platform），保持了术语的一致性。","MaP is a self-supervised pre-training framework designed to extract robust representations of malicious users by modeling repetitive and sporadic anomalies in behavior sequences without relying on content analysis.
[翻译] MaP是一个自监督预训练框架，旨在通过对行为序列中的重复性和零星异常进行建模来提取鲁棒的恶意用户表示，而不依赖于内容分析。",figures/MaP.png,"The proliferation of malicious users on social platforms poses significant financial and psychological threats, with activities ranging from scams to the dissemination of illicit content. Existing malicious user prediction comprises supervised and self-supervised learning methods. However, the former relies on extensive labeled malicious users for training, while the latter typically focuses on one form of malicious activity and depends heavily on manually crafted rules and features during pre-training. Moreover, existing pre-training methods fail to effectively capture the crucial repetitive and sporadic behavior patterns of malicious users. To address these limitations, we propose a Malicious User Behavior Pre-training framework (MaP) to build pre-trained behavior models. MaP integrates malicious pattern recognition with behavior consistency augmentation and local disruption augmentation strategies for contrastive learning to capture repetitive and sporadic malicious patterns, respectively. We instantiate MaP on a billion-level behavior pre-training scenario within an industry context. Both online and offline evaluations validate the superior performance of MaP in malicious user detection and classification.",anonymous,"【恶意用户分析（基于行为模式）】[引用文]To address the limitations of content reliance and the scarcity of labeled data in anomaly detection, Jiang et al. (2025) proposed the Malicious User Behavior Pre-training framework (MaP). Instead of modeling user-generated content, this approach focuses exclusively on discerning patterns within user behavior sequences. The authors introduced a three-stage self-supervised learning pipeline that incorporates specific augmentation strategies―namely behavior consistency and local disruption―to capture two distinct categories of malicious activities: repetitive automated behaviors and sporadic, camouflaged actions. By leveraging a pseudo-malicious user sampling strategy, the model effectively generates discriminative user representations from billion-scale unlabeled data, significantly enhancing detection performance in downstream tasks compared to traditional sequence modeling approaches.[翻译]
为了解决异常检测中对内容的依赖以及标注数据稀缺的局限性，Jiang等人 (2025) 提出了恶意用户行为预训练框架 (MaP)。该方法不单纯对用户生成的内容进行建模，而是专注于识别用户行为序列中的模式。作者引入了一个三阶段的自监督学习流程，结合了特定的增强策略――即行为一致性和局部破坏――以捕捉两类截然不同的恶意活动：重复的自动化行为和零星的、经过伪装的行动。通过利用伪恶意用户采样策略，该模型有效地从十亿级无标签数据中生成了具有判别力的用户表示，与传统的序列建模方法相比，显著提升了下游任务中的检测性能。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
10.1145/3581783.3612569,Multi-modal social bot detection: Learning homophilic and heterophilic connections adaptively,"Shilong Li, Boyu Qiao, Kun Li, Qianqian Lu, Meng Lin, Wei Zhou",2023-10-26,Malicious User Detection,"Existing graph-based detection methods largely rely on the homophily assumption, often failing to address relation camouflage, where bots establish heterophilic connections with humans to evade detection through feature smoothing.
[翻译] 现有的基于图的检测方法很大程度上依赖于同质性假设，往往无法解决关系伪装问题，即机器人通过与人类建立异质连接，利用特征平滑来逃避检测。","The study introduces an adaptive mechanism to distinguish between homophilic and heterophilic edges and constructs a node similarity graph to mitigate the isolation of bots within human-dominated neighborhoods.
[翻译] 该研究引入了一种自适应机制来区分同质和异质边，并构建了一个节点相似性图，以缓解机器人在以人类为主的邻域中的孤立问题。","BothH initializes multi-modal user representations using LMs and MLPs, constructs a composite graph supplemented by feature similarity, and employs an end-to-end framework that dynamically classifies edges to apply differentiated attention weights during neighbor aggregation.
[翻译] BothH 利用语言模型和多层感知机初始化多模态用户表示，构建了由特征相似性补充的组合图，并采用端到端框架动态分类边缘，以便在邻居聚合过程中应用差异化的注意力权重。","The model achieves state-of-the-art performance across Cresci-15, MGTAB, and Twibot-20 datasets, notably attaining an F1-score of 91.27% on the highly heterophilic Twibot-20 benchmark.
[翻译] 该模型在 Cresci-15、MGTAB 和 Twibot-20 数据集上均取得了最先进的性能，特别是在高度异质的 Twibot-20 基准测试中达到了 91.27% 的 F1 分数。","Future work is suggested to explore the distinct connection preferences of various social bot types to further refine the heterophily-aware aggregation.
[翻译] 未来的工作建议探索不同类型社交机器人的独特连接偏好，以进一步完善异质性感知聚合。",https://dl.acm.org/doi/10.1145/3581783.3612569,,Proceedings of the 31st ACM International Conference on Multimedia,"[AI generated] **中文标题：** 多模态社交机器人检测：自适应学习同质与异质连接

**翻译说明：**
1.  **Multi-modal** 译为“多模态”，准确对应原文中融合多种用户信息（如文本、图像、拓扑结构）的技术内涵。
2.  **social bot detection** 译为“社交机器人检测”，是信息安全与社交网络分析领域的标准术语。
3.  **Learning homophilic and heterophilic connections adaptively** 译为",【争对包含机器人网络的异质性】使用节点特征相似度补充转发图中的边，确保bot的特征不会被包围他的正常用户平滑掉,figures/BothH.png,"The detection of social bots has become a critical task in maintaining the integrity of social media. With social bots evolving continually, they primarily evade detection by imitating human features and engaging in interactions with humans. To reduce the impact of social bots imitating human features, also known as feature camouflage, existing methods mainly utilize multi-modal user information for detection, especially GNN-based methods that utilize additional topological structure information. However, these methods ignore relation camouflage, which involves disguising through interactions with humans. We find that relation camouflage results in both homophilic connections formed by nodes of the same type and heterophilic connections formed by nodes of different types in social networks. The existing GNN-based detection methods assume all connections are homophilic while ignoring the difference among neighbors in heterophilic connections, which leads to a poor detection performance for bots with relation camouflage. To address this, we propose a multi-modal social bot detection method with learning homophilic and heterophilic connections adaptively (BothH for short). Specifically, firstly we determine whether each connection is homophilic or heterophilic with the connection classifier, and then we design a novel message propagating strategy that can learn the homophilic and heterophilic connections adaptively. We conduct experiments on the mainstream datasets and the results show that our model is superior to state-of-the-art methods.",anonymous,"[方法概括]1.初始化用户节点表示，meta info经过MLP，语义信息经过LM和MLP，分别编码后拼接。2.构建关注图。为防止bot特征被平滑，使用相似度补充图的边。3.经过一个分类模型将图的边进行分类，区分同质和异质边。4.进行GNN的邻居聚合，同质和异质视为不同的边，分别计算权重。5.残差后进行节点分类，损失为节点分类Loss + 边分类Loss[引用文]Addressing the limitation of homophily assumptions in graph-based detection, Li et al. [?] proposed BothH to counter relation camouflage where bots mix with human neighbors. The method fuses semantic and metadata features to initialize node representations and augments the original topology with a node similarity graph to connect isolated bots. It incorporates an auxiliary edge classifier to distinguish homophilic and heterophilic connections, subsequently splitting relations to apply distinct aggregation strategies. This approach effectively prevents feature smoothing in heterophilic environments and demonstrates superior performance on benchmarks like Twibot-20.
[翻译] 中文文本：
针对基于图的检测中同质性假设的局限性，Li 等人 [?] 提出了 BothH 以应对机器人混迹于人类邻居中的关系伪装问题。该方法融合语义和元数据特征来初始化节点表示，并利用节点相似性图增强原始拓扑结构以连接孤立的机器人。它结合了一个辅助边缘分类器来区分同质和异质连接，随后拆分关系以应用不同的聚合策略。这种方法有效地防止了异质环境中的特征平滑，并在 Twibot-20 等基准测试中表现出优越的性能。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
10.1145/2783258.2783294,RSC: Mining and modeling temporal activity in social media,"Alceu Ferraz Costa, Yuto Yamaguchi, Agma Juci Machado Traina, Caetano Traina, Christos Faloutsos",2015-08-10,Malicious User Detection,"Existing stochastic models for human dynamics, such as Poisson processes, fail to simultaneously capture the complex temporal patterns―specifically burstiness, circadian rhythms, and heavy-tailed distributions―observed in large-scale social media data.
[翻译] 现有的针对人类动力学的随机模型（如泊松过程）无法同时捕捉在大规模社交媒体数据中观察到的复杂时间模式，具体包括阵发性、昼夜节律和重尾分布。","The paper proposes RSC, a generative model that introduces a Self-Correlated Process (SCorr) to incorporate memory effects into event generation, effectively modeling the positive correlation of inter-arrival times (IAT) that memoryless baselines ignore.
[翻译] 该论文提出了RSC，这是一种生成模型，它引入了自相关过程（SCorr）将记忆效应纳入事件生成中，有效建模了无记忆基线模型所忽略的事件间隔时间（IAT）的正相关性","The approach mines four statistical patterns from raw timestamps (positive correlation, heavy tails, periodic spikes, bimodal distribution) and employs a three-state stochastic machine (Active, Rest, Sleep) to generate synthetic timelines for anomaly detection.
[翻译] 该方法从原始时间戳中挖掘出四种统计模式（正相关性、重尾、周期性峰值、双峰分布），并采用三状态随机机（活跃、休息、睡眠）来生成用于异常检测的合成时间线。","Experiments on 35 million postings demonstrate that RSC fits empirical data distributions more accurately than Self-Feeding Processes (SFP) and achieves over 94% precision in bot detection using solely temporal features.
[翻译] 对3500万条帖子的实验表明，RSC在拟合经验数据分布方面比自反馈过程（SFP）更准确，并且仅使用时间特征即可实现超过94%的机器人检测精度。","The model assumes a single, stable physiological rhythm, which may lead to false positives for accounts operated by multiple users, those employing scheduling tools, or users with extremely fragmented activity patterns lacking distinct sleep cycles.
[翻译] 该模型假设存在单一且稳定的生理节律，对于由多人操作的账户、使用调度工具的账户，或缺乏明显睡眠周期的极度碎片化活跃用户，可能会导致误报。",https://dl.acm.org/doi/10.1145/2783258.2783294,https://github.com/alceufc/rsc_model,KDD '15: The 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,[AI generated] 中文标题：RSC：社交媒体中时序活动的挖掘与建模,构建了一个正常人类发帖时间特征的数学模型（时间间隔正相关性、重尾分布、24h周期性、双峰分布）。相对于传统的泊松分布更符合现实，相异度较高的用户判定为机器人。是一个**只依赖时间特征**的模型,figures/RSC.png,"Can we identify patterns of temporal activities caused by human communications in social media? Is it possible to model these patterns and tell if a user is a human or a bot based only on the timing of their postings? Social media services allow users to make postings, generating large datasets of human activity time-stamps. In this paper we analyze time-stamp data from social media services and find that the distribution of postings inter-arrival times (IAT) is characterized by four patterns: (i) positive correlation between consecutive IATs, (ii) heavy tails, (iii) periodic spikes and (iv) bimodal distribution. Based on our findings, we propose Rest-Sleep-andComment (RSC), a generative model that is able to match all four discovered patterns. We demonstrate the utility of RSC by showing that it can accurately fit real time-stamp data from Reddit and Twitter. We also show that RSC can be used to spot outliers and detect users with non-human behavior, such as bots. We validate RSC using real data consisting of over 35 million postings from Twitter and Reddit. RSC consistently provides a better fit to real data and clearly outperform existing models for human dynamics. RSC was also able to detect bots with a precision higher than 94%.",anonymous,"[引用文]In the transition from statistical pattern recognition to generative social simulation, Costa et al. [1] introduced the Rest-Sleep-and-Comment (RSC) model. Transcending traditional memoryless baselines like Poisson processes, RSC employs a Self-Correlated Process (SCorr) within a three-state stochastic machine (Active, Rest, Sleep) to mathematically formalize human physiological rhythms. This approach allows for the generative reproduction of complex temporal dynamics―specifically positive inter-arrival time correlations, heavy tails, circadian periodicities, and bimodal distributions. By establishing a simulation-based baseline of organic behavior, the model enables a lightweight, timestamp-only anomaly detection framework where non-human actors are identified through their distributional dissimilarity to the generated human patterns.
[翻译] 在从统计模式识别向生成式社会仿真过渡的过程中，Costa等人 [1] 引入了 Rest-Sleep-and-Comment (RSC) 模型。RSC 超越了像泊松过程这样的传统无记忆基线，在一个三状态随机机（活跃、休息、睡眠）中采用了自相关过程 (SCorr)，以此在数学上形式化人类的生理节律。这种方法允许对复杂的时间动力学进行生成式复现――具体包括正向间隔时间相关性、重尾、昼夜周期性和双峰分布。通过建立基于仿真的自然行为基线，该模型实现了一种轻量级、仅依赖时间戳的异常检测框架，非人类行动者通过其与生成的人类模式的分布相异度被识别出来。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
10.1109/TNNLS.2024.3396192,Dispelling the fake: Social bot detection based on edge confidence evaluation,"Boyu Qiao, Wei Zhou, Kun Li, Shilong Li, Songlin Hu",2025-04,Malicious User Detection,"Mainstream GNN-based detection methods often struggle when the homophily assumption is violated by camouflaged connections between bots and humans. These ""unreliable edges"" cause message passing mechanisms to aggregate noise, making it difficult to differentiate bot representations from genuine users.
[翻译] 主流基于GNN的检测方法常因机器人与人类之间的伪装连接破坏同质性假设而受挫。这些“不可靠边”导致消息传递机制聚合噪声，使得难以区分机器人与真实用户的表示。","The paper proposes the BECE framework, which introduces an edge confidence evaluation mechanism to dynamically identify and pr
[翻译] 该论文提出了BECE框架，引入边置信度评估机制以动态识别并剪枝不可靠边。其核心创新在于利用参数化高斯分布将边嵌入映射到随机潜在空间，通过正则化增强了模型对特征扰动的鲁棒性。","The method first fuses multi-modal user features using multi-head attention mechanisms. It then constructs edge representations and reconstructs them via a parameterized Gaussian distribution to predict confidence scores. Finally, unreliable edges are removed based on Bernoulli sampling before performing node classification with standard GNN encoders.
[翻译] 该方法首先利用多头注意力机制融合多模态用户特征。随后构建边表示，并通过参数化高斯分布对其进行重构以预测置信度分数。最后，在利用标准GNN编码器进行节点分类前，基于伯努利采样移除不可靠边。","Experiments on Cresci-15, Twibot-20, and MGTAB datasets demonstrate that BECE consistently outperforms state-of-the-art baselines like BotRGCN and RGT. Additionally, the edge confidence module proves effective as a plug-in across six different GNN architectures, maintaining high performance even with limited training data (30-50%).
[翻译] 在Cresci-15、Twibot-20和MGTAB数据集上的实验表明，BECE在性能上持续优于BotRGCN和RGT等先进基线方法。此外，边置信度模块作为插件在六种不同的GNN架构中均表现有效，即使在训练数据有限（30-50%）的情况下仍保持高性能。","The model exhibits limitations in discerning heterogeneous edges when the representations of connected node pairs are highly similar, as observed in parts of the MGTAB dataset. Future work intends to leverage richer structural information to refine edge embeddings and optimization strategies.
[翻译] 当相连节点对的表示高度相似时（如在MGTAB数据集的部分样本中），模型在识别异质边方面表现出局限性。未来工作计划利用更丰富的结构信息来优化边嵌入和策略。",https://ieeexplore.ieee.org/document/10530431/,,IEEE Trans. Neural Netw. Learn. Syst.,"[AI generated] **中文标题：** 去伪存真：基于边置信度评估的社交机器人检测

**说明：** 该翻译准确传达了原标题“Dispelling the fake: Social bot detection based on edge confidence evaluation”的核心含义与技术要点：
1.  **“去伪存真”**：对应“Dispelling the fake”，采用成语形式，凝练地体现了检测并清除虚假（机器人）账户的研究目的，兼具学术性与文采。
2.","【争对包含机器人网络的异质性】BECE is a GNN-based framework that restores graph homophily by dynamically pruning unreliable human-bot connections through a Gaussian-regularized edge confidence evaluation mechanism.
[翻译] BECE是一个基于GNN的框架，它通过高斯正则化的边置信度评估机制动态剪枝不可靠的人-机连接，从而恢复图的同质性。",figures/BECE.png,"Social bot detection is essential for maintaining the safety and integrity of online social networks (OSNs). Graph neural networks (GNNs) have emerged as a promising solution. Mainstream GNN-based social bot detection methods learn rich user representations by recursively performing message passing along userCuser interaction edges, where users are treated as nodes and their relationships as edges. However, these methods face challenges when detecting advanced bots interacting with genuine accounts. Interaction with real accounts results in the graph structure containing camouflaged and unreliable edges. These unreliable edges interfere with the differentiation between bot and human representations, and the iterative graph encoding process amplifies this unreliability. In this article, we propose a social Bot detection method based on Edge Confidence Evaluation (BECE). Our model incorporates an edge confidence evaluation module that assesses the reliability of the edges and identifies the unreliable edges. Specifically, we design features for edges based on the representation of user nodes and introduce parameterized Gaussian distributions to map the edge embeddings into a latent semantic space. We optimize these embeddings by minimizing KullbackCLeibler (KL) divergence from the standard distribution and evaluate their confidence based on edge representation. Experimental results on three real-world datasets demonstrate that BECE is effective and superior in social bot detection. Additionally, experimental results on six widely used GNN architectures demonstrate that our proposed edge confidence evaluation module can be used as a plug-in to improve detection performance.",anonymous,"相对于论文BothH（Multi-modal social bot detection: Learning homophilic and heterophilic connections adaptively）对异质关系进行显性的建模，该文则选择排除异质关系以防止干扰[引用文]Unlike BothH [Citation] which explicitly models heterophilic connections to adaptively extract high-pass information, Qiao et al. [Year] propose a subtractive strategy in their BECE model to mitigate interference. Arguing that camouflaged edges between bots and humans violate the GNN homophily assumption, they introduce an Edge Confidence Evaluation module to filter out these unreliable connections. To address the noise inherent in edge features, BECE maps edge embeddings into a parameterized Gaussian distribution, ensuring that minor feature perturbations do not compromise detection accuracy. This stochastic reconstruction allows the model to robustly identify and prune heterophilic edges via Bernoulli sampling, thereby purifying the graph structure for subsequent message passing.
[翻译] 与 BothH [引文] 显式建模异质连接以自适应提取高频信息的做法不同，Qiao等人 [年份] 在其 BECE 模型中提出了一种减法策略以减少干扰。他们认为机器人与人类之间的伪装连接破坏了GNN的同质性假设，因此引入了边置信度评估模块来过滤这些不可靠连接。为了解决边特征中固有的噪声问题，BECE将边嵌入映射为参数化高斯分布，确保微小的特征扰动不会损害检测精度。这种随机重构使得模型能够通过伯努利采样鲁棒地识别并剪枝异质边，从而为随后的消息传递净化图结构。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
10.1609/aaai.v39i13.33575,BotSim: LLM-Powered Malicious Social Botnet Simulation,"Boyu Qiao, Kun Li*, Wei Zhou, Shilong Li, Qianqian Lu, Songlin Hu",2025-04-11,Malicious User Detection,"[AI generated] To simulate and study the threat of LLM-powered malicious social botnets for improved detection.
[翻译]
模拟和研究由大语言模型驱动的恶意社交僵尸网络的威胁，以改进检测。","[AI generated] Proposes BotSim, an LLM-powered framework for simulating intelligent malicious botnets and generating realistic datasets for detection benchmarking.
[翻译]
提出了BotSim，一个利用大语言模型模拟智能恶意僵尸网络并生成用于检测基准测试的真实数据集的框架。","[AI generated] Proposes BotSim, an LLM-powered simulation framework that creates a virtual social network of intelligent agent bots and human users to model malicious botnet behavior and information dissemination patterns.
[翻译]
提出了BotSim，一个由大语言模型驱动的仿真框架，它创建一个由智能代理机器人和真实用户组成的虚拟社交网络，以模拟恶意僵尸网络的行为和信息传播模式。","[AI generated] BotSim-24, a highly human-like bot dataset, reveals that traditional bot detection methods underperform against advanced LLM-powered bots, underscoring the need for new detection strategies.
[翻译]
BotSim-24是一个高度类人的机器人数据集，它表明传统的机器人检测方法在面对先进的LLM驱动的机器人时表现不佳，凸显了对新检测策略的需求。",[AI generated] The simulation relies on LLM capabilities and lacks real-world deployment validation. [翻译] 整个模拟依赖LLM能力，缺乏真实世界部署验证。,https://ojs.aaai.org/index.php/AAAI/article/view/33575,,AAAI,"[AI generated] 中文标题：BotSim：基于大语言模型的恶意社交僵尸网络仿真

论文分类（供参考）：恶意机器人检测

论文摘要（供参考）：
X（原Twitter）和Reddit等社交媒体平台对全球信息交流至关重要。然而，大语言模型技术的进步催生了具有前所未有智能水平的社交媒体机器人。这些机器人能够娴熟地模拟用户画像、对话与互动行为，大规模传播虚假信息，对平台治理构成严峻挑战。为深入理解并应对此类",[AI generated] BotSim is like a digital petri dish for cultivating and studying intelligent malicious bots. [翻译] BotSim如同一个数字培养皿，用于培育和研究智能恶意机器人。,,"Social media platforms like X(Twitter) and Reddit are vital to global communication. However, advancements in Large Language Model (LLM) technology give rise to social media bots with unprecedented intelligence. These bots adeptly simulate human profiles, conversations, and interactions, disseminating large amounts of false information and posing significant challenges to platform regulation. To better understand and counter these threats, we innovatively design BotSim, a malicious social botnet simulation powered by LLM. BotSim mimics the information dissemination patterns of real-world social networks, creating a virtual environment composed of intelligent agent bots and real human users. In the temporal simulation constructed by BotSim, these advanced agent bots autonomously engage in social interactions such as posting and commenting, effectively modeling scenarios of information flow and user interaction. Building on the BotSim framework, we construct a highly human-like, LLM-driven bot dataset called BotSim-24 and benchmark multiple bot detection strategies against it. The experimental results indicate that detection methods effective on traditional bot datasets perform worse on BotSim-24, highlighting the urgent need for new detection strategies to address the cybersecurity threats posed by these advanced bots.",anonymous,,TRUE,,2026-01-22 22:11:57,FALSE,,FALSE
10.1609/aaai.v38i1.27788,GAMC: An Unsupervised Method for Fake News Detection Using Graph Autoencoder with Masking,"Shu Yin,Peican Zhu,Lianwei Wu,Chao Gao,Zhen Wang",2024-03-24,Misinformation Analysis,现有方法多依赖新闻内容或需大量标注数据，难以有效利用传播上下文信息。,首个结合图自编码器、掩码与对比学习的无监督假新闻检测方法，同时利用传播结构与内容信息，无需标注数据,"1. 将新闻传播建模为图（新闻节点和用户节点，边表示转发关系，节点特征来自新闻内容和用户历史贴文）；
2. 数据增强（节点特征掩码+边丢弃）（随机选取节点将其特征替换为掩码标记，随机删除部分边）构造自监督特性；
3. 图编码器（GIN）生成潜在表示；
4. 图解码器重建特征；
5. 损失函数组成（**重建损失**（使重建特征接近原始特征）+**对比损失**（来自同一个原始图的两个增强图重建后应尽量相似））训练。",在 FakeNewsNet 数据集上，GAMC 在无监督方法中表现最佳（如 GossipCop 准确率 0.946），甚至接近或超越部分监督方法,需要新闻具有一定的传播量才能建模为图；早期传播阶段检测能力受限,https://ojs.aaai.org/index.php/AAAI/article/view/27788,,Proceedings of the AAAI Conference on Artificial Intelligence,"[AI generated] **中文标题：** GAMC：一种基于掩码图自编码器的无监督假新闻检测方法

**说明：**
- **GAMC** 作为方法名称保留不译，符合学术惯例。
- **Graph Autoencoder with Masking** 译为“基于掩码的图自编码器”或“掩码图自编码器”，准确传达了核心方法（图自编码器）及其关键技术（掩码操作）。
- **Unsupervised Method for",自编码器方法处理类社交网络图结构,figures/GAMC.png,"With the rise of social media, the spread of fake news has become a significant concern, potentially misleading public perceptions and impacting social stability. Although deep learning methods like CNNs, RNNs, and Transformer-based models like BERT have enhanced fake news detection. However, they primarily focus on content and do not consider social context during news propagation. Graph-based techniques have incorporated the social context but are limited by the need for large labeled datasets. To address these challenges, this paper introduces GAMC, an unsupervised fake news detection technique using the Graph Autoencoder with Masking and Contrastive learning. By leveraging both the context and content of news propagation as self-supervised signals, our method reduces the dependency on labeled datasets. Specifically, GAMC begins by applying data augmentation to the original news propagation graphs. Subsequently, these augmented graphs are encoded using a graph encoder and subsequently reconstructed via a graph decoder. Finally, a composite loss function that encompasses both reconstruction error and contrastive loss is designed. Firstly, it ensures the model can effectively capture the latent features, based on minimizing the discrepancy between reconstructed and original graph representations. Secondly, it aligns the representations of augmented graphs that originate from the same source. Experiments on the real-world dataset validate the effectiveness of our method.",anonymous,,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1145/3442442.3452328,How does truth evolve into fake news? An empirical study of fake news evolution,Mingfei Guo，Xiuying Chen，Juntao Li，Dongyan Zhao，Rui Yan,2021-06-03,Misinformation Analysis,而现有数据集多关注静态标注，缺乏对其假新闻演化过程的研究,给出了关注假新闻演化的数据集FNE，包含“真相-虚假新闻-演化虚假新闻”三元组,"1. 从 Snopes.com(一个辟谣网站) 抓取truth文章；
2. 通过其引文收集虚假新闻；
3. 利用网页存档平台（如 Archive Today）获取演化后版本；
4. 分析虚假信息技术分类（捏造、否认、混淆、歪曲四类、文本相似度、关键词、词性、情感等属性。",演化后虚假新闻与原始虚假新闻相似度更高，情感更客观积极，更难以被现有分类模型检测；虚假信息技术中以“捏造”为主；词性和关键词在演化中保持稳定。,数据来源依赖单一事实核查网站（Snopes），可能引入偏见；仅关注文本新闻，未涵盖图像、视频等多模态演变；,https://dl.acm.org/doi/10.1145/3442442.3452328,,Companion Proceedings of the Web Conference 2021,[AI generated] **中文标题：** 真相如何演变为虚假新闻？一项关于虚假新闻演化的实证研究,一个包含[原始新闻、假新闻、演化后的假新闻]三元组的数据集,figures/FNE.png,"Automatically identifying fake news from the Internet is a challenging problem in deception detection tasks. Online news is modified constantly during its propagation, e.g., malicious users distort the original truth and make up fake news. However, the continuous evolution process would generate unprecedented fake news and cheat the original model. We present the Fake News Evolution (FNE) dataset: a new dataset tracking the fake news evolution process. Our dataset is composed of 950 paired data, each of which consists of articles representing the three significant phases of the evolution process, which are the truth, the fake news, and the evolved fake news. We observe the features during the evolution and they are the disinformation techniques, text similarity, top 10 keywords, classification accuracy, parts of speech, and sentiment properties.",anonymous,,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1609/aaai.v39i1.32022,Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference,"Mingxin Li,Yuchen Zhang,Haowei Xu,Xianghua Li*,Chao Gao,Zhen Wang",2025-04-11,Misinformation Analysis,社交平台多元化导致新闻传播复杂、多模态，传统假新闻检测方法依赖显式传播关系（如转发），在抖音等平台难以直接获取，检测难度大。,提出“社交潜在网络推断Latent Network Inference”策略，无需真实传播关系，即可构建新闻间的潜在联系,"1. 社交潜在网络推断：基于Hawkes Process建模新闻影响力随时间变化，得到事件内部与事件间的影响强度，推断出潜在传播网络。
2. 异质图构建：节点均为新闻，边类型基于各种相同或相似属性（如作者、标题、时间等）构建。使用**注意力机制**动态融合不同边类型，生成统一的异质图表示（每个类型的边看做一个“头”，利用多头注意力方法）
3. 自监督多模态内容学习：损失函数：单模态增强（对同一模态进行掩码与重构）、跨模态对比学习（对齐不同模态（如文本与视频）的特征，通过对比学习拉近正样本、推开负样本）
4. 个性化图表示与分类：使用图Transformer Encoder融合图结构与模态特征，进行分类。",FakeSV和FVC数据集上准确率均超89%，较SOTA提升0.12%~4.39%；在Twitter/微博作为插件也提升明显（最高+10.71% F1）,依赖事件定义与时间序列假设，对实时性要求高；计算复杂度较高,https://ojs.aaai.org/index.php/AAAI/article/view/32022,,Proceedings of the AAAI Conference on Artificial Intelligence,"[AI generated] **中文标题：** 基于社交潜在网络推断的复杂异质多模态假新闻学习

**说明：** 此翻译力求准确、专业，符合中文科技论文的表达习惯：
1.  **核心术语处理**：
    *   ""Complex Heterogeneous Multimodal"" 译为“复杂异质多模态”，是领域内对数据/信息特性的标准表述。
    *   ""Social Latent Network Inference"" 译为“社交潜在网络推断”，其中“",通过社交潜在网络推断与自监督多模态学习检测复杂异质多模态假新闻的GNN方法,figures/HML.png,"With the diversification of online social platforms, news dissemination has become increasingly complex, heterogeneous, and multimodal, making the fake news detection task more challenging and crucial.
Previous works mainly focus on obtaining social relationships of news via retweets, limiting the accurate detection when real cascades are inaccessible. Given the proven assessment of the spreading influence of events, this paper proposes a method called HML (Complex Heterogeneous Multimodal Fake News Detection method via Latent Network Inference). Specifically, an improved social latent network inference strategy is designed to estimate the maximum likelihood of news influences under the same event. Meanwhile, a novel heterogeneous graph is built based on social attributes for multimodal news under different events. Further, to better aggregate the relationships among heterogeneous multimodal features, this paper proposes a self-supervised-based multimodal content learning strategy, to enhance, align, fuse and compare heterogeneous modal contents. Based above, a personalized heterogeneous graph representation learning is designed to classify fake news. Extensive experiments demonstrate that the proposed method outperforms the SOTA in real social media news datasets.",anonymous,,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1609/aaai.v38i20.30252,Harnessing Network Effect for Fake News Mitigation: Selecting Debunkers via Self-Imitation Learning,"Xiaofei Xu, Ke Deng, Michael Dann, Xiuzhen Zhang",2024-03-24,Misinformation Analysis,"Current approaches to multi-stage fake news mitigation often fail to address the episodic reward problem, where the effect of selecting an individual debunker cannot be measured until the campaign concludes. This sparse and delayed feedback limits the applicability of standard Reinforcement Learning (RL) in real-world social networks.
[翻译]
现有的多阶段假新闻治理方法往往未能解决片段式奖励问题，即选择单个辟谣者的效果只有在活动结束时才能衡量。这种稀疏且延迟的反馈限制了标准强化学习在现实社交网络中的适用性。","The authors propose NAGASIL, introducing two key enhancements to Self-Imitation Learning: 1) Negative Sampling, which leverages low-reward historical episodes to explicitly penalize poor debunker selections, and 2) State Augmentation, which enriches the observed state by integrating historical state-action sequences from the same campaign to address partial observability.
[翻译]
作者提出了NAGASIL，为自模仿学习引入了两个关键增强：1) 负采样，利用历史低奖励片段显式惩罚不良的辟谣者选择；2) 状态增强，通过融合同一活动中的历史状态-动作序列来丰富观测状态，以应对部分可观测性问题。","The debunker selection is formulated as a sequential decision-making problem under a budget constraint. A generative adversarial framework is employed, where a generator selects debunkers and a discriminator distinguishes between state-action pairs from high-reward historical episodes and those generated by the current policy. The generator is trained by integrating signals from the discriminator, an entropy regularizer for exploration, and a novel regularizer derived from a negative sampling model trained on low-reward episodes. This process yields an optimal generator capable of outputting an effective debunker selection policy.
[翻译]
辟谣者选择被建模为预算约束下的序列决策问题。采用生成对抗框架，其中生成器选择辟谣者，判别器区分来自高奖励历史片段的状态-动作对与当前策略生成的对。生成器的训练整合了来自判别器的信号、用于探索的熵正则项，以及一个从低奖励片段训练得到的负采样模型所衍生的新正则项。该过程最终产生一个能输出有效辟谣者选择策略的最优生成器。","Experiments conducted on both real-world (Facebook) and synthetic (Twitter) networks demonstrate that NAGASIL outperforms state-of-the-art fake news mitigation baselines and standard self-imitation learning methods across various budgets, stage lengths, and network densities.
[翻译]
在真实世界（Facebook）和合成（Twitter）网络上的实验表明，NAGASIL在各种预算、阶段长度和网络密度设置下，均优于先进的假新闻治理基线方法和标准自模仿学习方法。","The proposed method operates under the assumption that the veracity of news is pre-determined, necessitating integration with an external fake news detection system. Future research could explore adaptive propagation models and the dynamic nature of user behavior.
[翻译]
所提方法基于新闻真伪已知的假设运行，因此需要与外部假新闻检测系统结合。未来研究可探索自适应的传播模型和用户行为的动态特性。",https://ojs.aaai.org/index.php/AAAI/article/view/30252,https://github.com/xxfwin/NAGASIL,AAAI,"[AI generated] 中文标题：**利用网络效应抑制虚假新闻：基于自模仿学习的辟谣者选择策略**

（说明：该翻译在保持学术严谨性的同时，通过“抑制虚假新闻”准确传达“mitigation”的主动干预含义；“辟谣者选择策略”清晰体现了“selecting debunkers”的研究核心；副标题结构符合中文论文标题常见格式。）",一个辟谣者选择策略（MDP风格）的生成器,figures/NAGASIL.png,"This study aims to minimize the influence of fake news on social networks by deploying debunkers to propagate true news. This is framed as a reinforcement learning problem, where, at each stage, one user is selected to propagate true news. A challenging issue is episodic reward where the ""net"" effect of selecting individual debunkers cannot be discerned from the interleaving information propagation on social networks, and only the collective effect from mitigation efforts can be observed. Existing Self-Imitation Learning (SIL) methods have shown promise in learning from episodic rewards, but are ill-suited to the real-world application of fake news mitigation because of their poor sample efficiency. To learn a more effective debunker selection policy for fake news mitigation, this study proposes NAGASIL - Negative sampling and state Augmented Generative Adversarial Self-Imitation Learning, which consists of two improvements geared towards fake news mitigation: learning from negative samples, and an augmented state representation to capture the ""real"" environment state by integrating the current observed state with the previous state-action pairs from the same campaign. Experiments on two social networks show that NAGASIL yields superior performance to standard GASIL and state-of-the-art fake news mitigation models.",anonymous,"[引用文]The work by Xu et al. (2024) marks a pivotal transition from merely recognizing patterns of disinformation to actively intervening to curtail its spread. By harnessing network effects within a reinforcement learning framework enhanced by self-imitative adversarial learning, their NAGASIL model transcends static pattern recognition. It implements a dynamic, goal-oriented policy learning process that provides actionable guidance for debunker selection strategies.
[翻译]
Xu等人（2024）的研究标志着一个关键的转变：从仅仅识别虚假信息模式，转向主动干预以遏制其传播。通过在一个由自模仿对抗学习增强的强化学习框架内利用网络效应，他们的NAGASIL模型超越了静态模式识别。它实现了一个动态的、目标导向的策略学习过程，为辟谣者选择策略提供了可行的指导。<br>[notes]1.这是一个对抗性学习框架，判别器希望好序列的置信度高，其他序列的置信度低，通过损失函数训练优化。生成器依据目标函数进行训练优化，目标函数包含三部分：判别器传来的对抗信号（置信度）、鼓励多样性的熵正则、负采样正则项（来自坏序列的距离（训练另一个模型以输出该值））。好经验和坏经验每轮通过奖励值V(τ) = -log(感染用户比例)获得。
2.每**轮**中每个**阶段**选择一个用户恢复并作为辟谣者，预算减去其成本，进行w个**时间步**的辟谣。每个阶段的预算用完后，进行每轮一次的梯度更新和好坏序列评选，然后进入下一轮",TRUE,,2026-01-15 20:03:34,FALSE,,FALSE
10.1609/icwsm.v19i1.35804,News Source Credibility Assessment: A Reddit Case Study,"Arash Amini, Yigit Ege Bayiz, Ashwin Ram, Radu Marculescu, and Ufuk Topcu",2025-06-07,Misinformation Analysis,"Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin.
[翻译]
本研究受社交媒体虚假信息泛滥的驱动，将重点从核查单一新闻的真实性，转向评估新闻来源的系统性可信度，以应对从源头治理信息污染这一关键问题。","Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network (GCN) to enhance the binary classification of source credibility.
[翻译]
其核心创新在于基于用户评论的语义相似性构建了一个加权帖子间网络。该网络建模了帖子间潜在的社会语境关联，并通过图卷积网络（GCN）整合这些关联，以提升对新闻来源可信度的二分类性能。","The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification.
[翻译]
该框架（CREDiBERT）首先在描述同一事件的成对帖子上训练一个双编码器，以学习具有可信度感知的文本嵌入。随后，它构建了一个新颖的图结构，其中边的权重通过评论编码了用户反应的相似性。最后，一个图卷积网络（GCN）融合了这些文本与社会信号以完成最终分类。","The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems.
[翻译]
该模型在可信度评估任务上的F1分数比基于BERT的基线模型高出3%。融入用户交互图后，性能进一步提升了8%，这证明了基于社交的感知信号在评估信息生态系统中的重要价值。","The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities.
[翻译]
该方法评估的是来源声誉而非文章真实性，因此无法识别那些来自通常可信媒体的偶然性虚假信息。同时，其性能受限于来自特定网络社区的训练数据中存在的固有偏差。",https://ojs.aaai.org/index.php/ICWSM/article/view/35804,,ICWSM,[AI generated] 新闻来源可信度评估：一项基于Reddit的案例研究,通过帖子间的评论区相似性构建加权铁子网络，以求找到水军蛛丝马迹，进而确定新闻来源是否可信,figures/CREDiBERT.png,"We present a transformer-based model for credibility assessment, CREDiBERT (CREDibility assessment using  Bi-directional Encoder Representations from Transformers), fine-tuned for Reddit submissions focusing on political discourse. We adopt a semi-supervised training approach for CREDiBERT, leveraging the community structure of Reddit. By encoding submission content using CREDiBERT and integrating it with a classification neural network, we improve the credibility assessment for Reddit submission by 3% in F1 score compared to existing methods. Additionally, we introduce a new version of the post-to-post network in Reddit that efficiently encodes user interactions to enhance the credibility assessment task by 8%  in the F1 score. We demonstrate CREDiBERT's applicability by evaluating the susceptibility of Reddit communities to different topics and assessing the credibility score of unseen sources.",anonymous,"[notes]关键设计在于通过评论区的评论相似性建模不同帖子间的潜在联系（加权帖子网络的边权重），在GCN中利用该联系来进行帖子的来源新闻的可信性二分类<br>[引用文]Amini et al. (2025) move beyond purely content-based pattern recognition, attempting instead to establish connections between posts and the credibility of news sources. Their CREDiBERT framework innovatively constructs a weighted post-to-post network from user comment similarities. This graph structure captures community-specific reaction patterns, which, when processed through a Graph Convolutional Network, significantly enhance the classification of news source credibility. This work underscores a paradigm shift: credibility assessment is beginning to focus on the patterns of information dissemination, rather than solely analyzing the specific content.
[翻译]
Amini等人（2025）的研究超越了单纯的基于内容的模式识别，转而尝试建立帖子与新闻来源可信度的联系。他们的CREDiBERT框架创新性地从用户评论相似性中构建了一个加权帖子间网络。该图结构捕获了社区的特定反应模式，这些模式通过图卷积网络处理后，显著增强了对新闻来源可信度的分类能力。这项工作强调了一个范式转变：可信度评估开始关注消息的传播模式，而不仅仅是分析具体内容。",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.1145/3627673.3679519,Let silence speak: Enhancing fake news detection with generated comments from large language models,"Qiong Nan,Qiang Sheng?,Juan Cao,Beizhe Hu,Danding Wang,Jintao Li",2024-10-21,Misinformation Analysis,"Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments (e.g., in early stages or from “silent” users), leading to an incomplete and biased perception of public feedback.

[翻译]基于评论的虚假新闻检测受限于真实用户评论的稀缺性与分布偏差（例如在早期传播阶段或来自“沉默”用户），导致对公众反馈的感知不完整且存在偏差。",使用LLM补充评论特征，解决该领域评论数据不足和不全面的问题,"The GenFEND framework: (1) generates comments by prompting an LLM with 30 predefined user profiles (gender/age/education); (2) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; (3) aggregates intra-view and inter-view features adaptively for final classification.

[翻译]GenFEND框架：(1) 通过为LLM提供30个预定义用户画像（性别/年龄/教育）来生成评论；(2) 通过分组语义平均和跨人口统计视图的多样性度量对其进行分析；(3) 自适应地聚合视图内和视图间的特征以进行最终分类。","GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.

[翻译]GenFEND在多个数据集上持续提升了仅使用内容和使用评论的检测器性能。值得注意的是，LLM生成的评论为早期检测提供了有效信号，并且可以超越真实评论的效果，尤其在识别虚假新闻方面。","Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.

[翻译]局限性包括对LLM生成质量的依赖、所考虑用户属性的有限性以及较高的计算成本。未来工作可探索更细致的用户建模、动态画像生成以及与真实社交图谱的结合。",https://dl.acm.org/doi/10.1145/3627673.3679519,,CIKM '24,"[AI generated] **中文标题：** 让沉默发声：利用大语言模型生成评论增强虚假新闻检测

**说明：** 该翻译准确传达了原标题的核心思想，即通过生成“沉默用户”的评论来提升检测效果。“让沉默发声”这一表述生动且符合中文语境，整体风格专业、简洁，适用于学术论文标题。",“让沉默的用户发声――用LLM生成多样评论，补充评论特征，提升虚假新闻检测的覆盖力和早期性能。”,figures/GenFEND.png,"Fake news detection plays a crucial role in protecting social media users and maintaining a healthy news ecosystem. Among existing works, comment-based fake news detection methods are empirically shown as promising because comments could reflect users' opinions, stances, and emotions and deepen models' understanding of fake news. Unfortunately, due to exposure bias and users' different willingness to comment, it is not easy to obtain diverse comments in reality, especially for early detection scenarios. Without obtaining the comments from the ""silent'' users, the perceived opinions may be incomplete, subsequently affecting news veracity judgment. In this paper, we explore the possibility of finding an alternative source of comments to guarantee the availability of diverse comments, especially those from silent users. Specifically, we propose to adopt large language models (LLMs) as a user simulator and comment generator, and design GenFEND, a generated feedback-enhanced detection framework, which generates comments by prompting LLMs with diverse user profiles and aggregating generated comments from multiple subpopulation groups. Experiments demonstrate the effectiveness of GenFEND and further analysis shows that the generated comments cover more diverse users and could even be more effective than actual comments.",anonymous,"[引用文]Within the task of False Content Analysis, a key bottleneck is the scarcity of early-stage comments and the absence of opinions from silent users. The GenFEND framework (Nan et al., 2024) addresses this by using Large Language Models (LLMs) to supplement these missing comments. Instead of passively relying on sparse real comments, their approach actively generates a rich set of synthetic comments conditioned on diverse user profiles (e.g., gender, age, education level). This method effectively performs data augmentation in the social comment space, providing a stable and diverse informational supplement. This helps models establish a more complete perceptual foundation for veracity judgment and has proven to be highly effective for early fake news detection.
[翻译]
在虚假内容分析任务中，一个关键瓶颈是早期评论的稀缺性和沉默用户意见的缺失。GenFEND框架 (Nan et al., 2024) 通过使用大语言模型来补充这部分缺失的评论，从而解决了这一问题。该方法不再被动地依赖稀疏的真实评论，而是主动生成一组以多样化用户画像（如性别、年龄、教育程度）为条件的丰富合成评论。该方法有效地在社交评论空间进行了数据增强，提供了一个稳定且多样化的信息补充。这有助于模型为真实性判断建立更完整的感知基础，并被证明对早期虚假新闻检测非常有效。",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.1609/icwsm.v19i1.35815,Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity,"Tygo Bloem, Filip Ilievski",2025-06-07,Multimodal Analysis,"Existing approaches often rely on static, incomplete databases or single-modality features, failing to capture the dynamic evolution and multi-layered semantics of internet memes.
[翻译] 现有方法通常依赖静态、不完整的数据库或单一模态特征，难以捕捉互联网模因的动态演化及多层语义。","The study introduces a fine-grained multi-dimensional similarity framework and a two-stage strategy that filters weak connections to bootstrap high-purity template clusters, significantly enhancing the efficiency of community detection algorithms like Louvain.
[翻译] 该研究提出了一种细粒度的多维相似度框架，以及一种两阶段策略，通过过滤弱连接来自举生成高纯度的模版簇，显著提升了Louvain等社区发现算法的效率。","The method constructs adjacency matrices based on form, content, text, and identity features, applying a filtering threshold to simplify the graph structure for robust, low-noise template identification, followed by classifying the remaining samples via similarity matching.
[翻译] 该方法基于形式、内容、文本和身份特征构建邻接矩阵，应用过滤阈值简化图结构以实现稳健、低噪声的模版识别，随后通过相似度匹配对剩余样本进行分类。","Experimental results demonstrate that this template-based approach achieves superior cluster consistency (0.94) compared to standard baselines, effectively handling diverse meme variants while aligning with human semantic intuition.
[翻译] 实验结果表明，这种基于模版的方法实现了优于标准基线的聚类一致性（0.94），在有效处理多样化模因变体的同时，与人类的语义直觉保持一致。","The framework's performance is contingent on the quality of upstream feature extractors and currently lacks integration with external knowledge graphs to interpret complex cultural metaphors or irony.
[翻译] 该框架的性能取决于上游特征提取器的质量，且目前缺乏与外部知识图谱的整合以解释复杂的文化隐喻或反讽。",https://ojs.aaai.org/index.php/ICWSM/article/view/35815,https://github.com/tygobl/meme-clustering,ICWSM,"[AI generated] **中文标题：** 基于模板匹配与多维相似度的网络模因聚类

**说明：** 此翻译力求准确、专业，符合学术论文标题的规范。
*   **Clustering Internet Memes Through...** 译为“基于...的网络模因聚类”，清晰点明了方法（基于模板匹配与多维相似度）与核心任务（模因聚类）。
*   **Template Matching** 译为“模板匹配”，是计算机视觉和模式识别领域的标准术语","Utilizing the Louvain community detection algorithm for meme clustering, the study decomposes similarity into four dimensions (form, visual content, text, and identity) to construct adjacency matrices, and employs a strategy of filtering prior to clustering, followed by matching filtered samples, to enhance efficiency and purity by reducing noise.
[翻译] 为实现meme的聚类，使用社区发现算法louvain。首先将meme相似度分为4个维度（形式、图义、文本、身份），据其构建邻接矩阵。为提高聚类效率和纯度（降低噪声），采用先过滤，再聚类，最后匹配被过滤样本的方法。",figures/meme-clustering.png,"Meme clustering is critical for toxicity detection, virality modeling, and typing, but it has received little attention in previous research. Clustering similar Internet memes is challenging due to their multimodality, cultural context, and adaptability. Existing approaches rely on databases, overlook semantics, and struggle to handle diverse dimensions of similarity. This paper introduces a novel method that uses template-based matching with multi-dimensional similarity features, thus eliminating the need for predefined databases and supporting adaptive matching. Memes are clustered using local and global features across similarity categories such as form, visual content, text, and identity. Our combined approach outperforms existing clustering methods, producing more consistent and coherent clusters, while similarity-based feature sets enable adaptability and align with human intuition. We make all supporting code publicly available to support subsequent research.",anonymous,"【meme聚类】[引用文]To address the limitations of static database matching in capturing evolving digital content, Bloem and Ilievski (2025) proposed a template-based clustering framework that deconstructs meme similarity into four fine-grained dimensions: form, visual content, text, and identity. A key innovation is the introduction of a graph filtering mechanism prior to clustering with community detection algorithms. By pruning weak connections in the adjacency matrix, the method simplifies the graph structure to efficiently identify high-purity core templates using the Louvain algorithm. The remaining instances are subsequently re-associated through similarity matching, thereby effectively balancing computational complexity with semantic coherence in tracking meme propagation.
[翻译] 为了解决静态数据库匹配在捕捉演化数字内容方面的局限性，Bloem和Ilievski (2025) 提出了一种基于模版的聚类框架，将模因相似度解构为形式、视觉内容、文本和身份四个细粒度维度。关键创新是在使用社区发现算法进行聚类之前引入了图过滤机制。通过剪除邻接矩阵中的弱连接，该方法简化了图结构，从而利用Louvain算法高效地识别出高纯度的核心模版。剩余的实例随后通过相似度匹配被重新关联，从而在追踪模因传播时有效平衡了计算复杂度与语义连贯性。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
10.1145/3589334.3648151,MemeCraft: Contextual and stance-driven multimodal meme generation,"Han Wang, Roy Ka-Wei Lee",2024-05-13,Multimodal Analysis;Humor Generation,"While internet memes have evolved into potent vehicles for social and political discourse, existing generation tools often lack the capability to align content with specific ideological stances or ensure safety against hate speech.
[翻译] 虽然网络迷因已演变为社会和政治话语的有力载体，但现有的生成工具往往缺乏将内容与特定意识形态立场对齐的能力，也难以确保内容安全以防止仇恨言论。","This work proposes a novel framework utilizing off-the-shelf Large Language Models (LLMs) and Visual Language Models (VLMs) to generate advocacy-driven memes without fine-tuning, incorporating a dedicated safety mechanism to mitigate the production of hateful content.
[翻译] 该工作提出了一个利用现成的多模态大模型（LLMs和VLMs）生成宣传性迷因的新颖框架，无需进行微调，并内置了专门的安全机制以减少仇恨内容的产生。","The authors devise an inference-only pipeline that decouples visual processing from text generation: a VLM first converts meme templates into textual descriptions, which serve as context for an LLM conditioned on structured prompts (e.g., stance, persuasion technique) to synthesize humorous captions.
[翻译] 作者设计了一个仅推理（inference-only）的流水线，将视觉处理与文本生成解耦：首先由VLM将迷因模板转换为文本描述，随后将其作为上下文，结合结构化提示（如立场、说服技巧）引导LLM合成幽默配文。","Experimental evaluations focusing on UN Sustainable Development Goals demonstrate that the approach, particularly when leveraging ChatGPT, significantly outperforms state-of-the-art baselines in terms of hilarity and persuasiveness, achieving authenticity scores comparable to human-created content.
[翻译] 针对联合国可持续发展目标的实验评估表明，该方法（尤其是基于ChatGPT的版本）在幽默感和说服力方面显著优于最先进的基线模型，并达到了与人类创作内容相当的真实性评分。","A notable limitation lies in the information bottleneck introduced by converting visual data into text descriptions, which may fail to capture fine-grained visual nuances or pixel-level text-image interplay compared to end-to-end multimodal training.
[翻译] 一个显著的局限性在于将视觉数据转换为文本描述所引入的信息瓶颈，与端到端的多模态训练相比，这种方法可能难以捕捉细粒度的视觉细微差别或像素级的图文互动。",https://dl.acm.org/doi/10.1145/3589334.3648151,https://github.com/Social-AI-Studio/MemeCraft,Proceedings of the ACM Web Conference 2024（WWW '24),"[AI generated] **中文标题：** MemeCraft：基于上下文与立场驱动的多模态迷因生成

**说明：**
*   **MemeCraft：** 保留英文原名，作为专有工具/框架名称，符合学术惯例。
*   **Contextual：** 译为“基于上下文”，强调系统利用模板描述等上下文信息进行生成。
*   **Stance-driven：** 译为“立场驱动”，准确反映论文核心――根据特定意识形态或倡导立场","This work presents an end-to-end, training-free meme generator that operates through a sequence of template retrieval, visual description generation, text synthesis via structured prompting, meme composition, and final hate speech detection.
[翻译] 端到端无训练meme生成器：获得模板->生成模板描述->结构化prompt生成meme文本->组合为meme->仇恨检测。",figures/MemeCraft.png,"Online memes have emerged as powerful digital cultural artifacts in the age of social media, offering not only humor but also platforms for political discourse, social critique, and information dissemination. Their extensive reach and influence in shaping online communities' sentiments make them invaluable tools for campaigning and promoting ideologies. Despite the development of several meme generation tools, there remains a gap in their systematic evaluation and their ability to effectively communicate ideologies. Addressing this, we introduce MemeCraft, an innovative meme generator that leverages large language models (LLMs) and visual language models (VLMs) to produce memes advocating specific social movements. MemeCraft presents an end-to-end pipeline, transforming user prompts into compelling multimodal memes without manual intervention. Conscious of the misuse potential in creating divisive content, an intrinsic safety mechanism is embedded to curb hateful meme production. Our assessment, focusing on two UN Sustainable Development Goals-Climate Action and Gender Equality-shows MemeCraft's prowess in creating memes that are both funny and supportive of advocacy goals. This paper highlights how generative AI can promote social good and pioneers the use of LLMs and VLMs in meme generation.",anonymous,"[引用文]In the pursuit of deploying generative AI for specific social goals, Wang and Lee [1] introduce MemeCraft, a framework designed to fabricate memes advocating for UN Sustainable Development Goals (e.g., climate action). It functions as an end-to-end, inference-only generation framework where visual semantics are compressed into textual descriptions by a VLM to guide an LLM in generating stance-aligned captions. While this structured prompting approach ensures high controllability and safety in propagating social messages, the reliance on intermediate textual representations instead of joint multimodal embedding implies a potential granularity loss in capturing complex visual-semantic interplay.
[翻译] 在探索将生成式AI应用于特定社会目标的背景下，Wang和Lee [1] 推出了MemeCraft，这是一个旨在制作倡导联合国可持续发展目标（如气候行动）迷因的框架。这是一个端到端的、仅推理（inference-only）的生成框架，通过VLM将视觉语义压缩为文本描述，进而引导LLM生成与立场一致的配文。虽然这种结构化提示方法在传播社会信息时确保了高度的可控性和安全性，但依赖中间文本表示而非联合多模态嵌入的做法，也意味着在捕捉复杂的视觉-语义交互时可能存在细粒度信息的缺失。",TRUE,unread,2026-01-29 18:53:01,FALSE,,FALSE
10.1609/aaai.v38i8.28787,CAMEL: Capturing metaphorical alignment with context disentangling for multimodal emotion recognition,"Linhao Zhang,Li Jin*,Guangluan Xu,Xiaoyu Li,Cai Xu,Kaiwen Wei,Nayu Liu,Haonan Liu",2024-03-24,Sentiment Analysis,"为了解决多模态内容中因隐喻对齐导致**情感误判**的问题：之前的方法本质上无法理解隐喻,专注于直接的语义对齐，无法捕捉如文字“眼泪”与图片“河流”的这种隐式联系",将多模态间隐含联系的对齐思想应用于多模态情感识别领域,使用了基于条件生成与解耦上下文适应的CAMEL框架:隐喻对齐建模（条件生成）(强制模型按照模版输出（CMT和SPV两种技术）；使用图片、标题、文本的交叉注意力机制，使用一个[CLS] token聚合全局信息）->上下文语义适应（特征融合）（使用两个异构模型，分别输入字面特征（CAMEL-C，CMT）和隐喻特征（CAMEL-S，SPV）生成两个向量矩阵，通过隐喻查字面实现多头注意力）->解耦对比匹配（上下文正则化）（确保不偏离语境。采用解耦学习思想，隐喻特征中分离出代表“主导上下文类别”的离散分布，通过对比学习，使字面特征推出的分布与之对齐）,达成了对隐含情感更精准、鲁棒的识别效果,整个方法框架复杂，模型所需的所有能力：找字面特征、找隐喻特征、两者对齐、根据融合特征生成情感分析，都是一次训练完成的，是否难以收敛（虽然论文使用了课程学习策略），是否能够在训练层面进行一定的解耦？分别训练各能力,https://ojs.aaai.org/index.php/AAAI/article/view/28787,,Proceedings of the AAAI Conference on Artificial Intelligence,[AI generated] **中文标题：** CAMEL：基于上下文解耦的隐喻对齐捕捉用于多模态情感识别,"[AI generated] CAMEL disentangles metaphorical alignment like a prism separating light, then adaptively fuses context for emotion recognition. [翻译]CAMEL像棱镜分离光线般解耦隐喻对齐，再自适应融合上下文进行情感识别。",figures/CAMEL1.png;figures/CAMEL.png,"Understanding the emotional polarity of multimodal content with metaphorical characteristics, such as memes, poses a significant challenge in Multimodal Emotion Recognition (MER). Previous MER researches have overlooked the phenomenon of metaphorical alignment in multimedia content, which involves non-literal associations between concepts to convey implicit emotional tones.  Metaphor-agnostic MER methods may be misinformed by the isolated unimodal emotions, which are distinct from the real emotions blended in multimodal metaphors. Moreover, contextual semantics can further affect the emotions associated with similar metaphors, leading to the challenge of maintaining contextual compatibility. To address the issue of metaphorical alignment in MER, we propose to leverage a conditional generative approach for capturing metaphorical analogies. Our approach formulates schematic prompts and corresponding references based on theoretical foundations, which allows the model to better grasp metaphorical nuances. In order to maintain contextual sensitivity, we incorporate a disentangled contrastive matching mechanism, which undergoes curricular adjustment to regulate its intensity during the learning process. The automatic and human evaluation experiments on two benchmarks prove that, our model provides considerable and stable improvements in recognizing multimodal emotion with metaphor attributes.",anonymous,首先通过多头跨域注意力机制实现初步的对齐，然后让字面特征的分布与隐喻特征的分布对齐，进一步强化对齐；,TRUE,,2026-01-15 20:03:40,FALSE,,FALSE
10.1145/3581783.3612517,Multi-label emotion analysis in conversation via multimodal knowledge distillation,"Sidharth Anand?,Naresh Kumar Devulapally?,Sreyasee Das Bhattacharjee,Junsong Yuan",2023-10-27,Sentiment Analysis,"Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations.
[翻译] 针对现有多模态方法主要关注单一主导情感的局限性，该研究致力于解决情感标签共现的识别难题，并提升模型在不同社会人口统计学群体（特别是不同年龄段人群）中的泛化能力。",将多模态知识蒸馏与标签一致性校准损失（LCC）相结合，减轻了模型对简单标签的过拟合（保证置信度相近）；构建了一个利用蒸馏方法的整体框架，其目的是为了融合各模态能力,"Employing a Multimodal Transformer Network where mode-specific peer branches (visual, audio, textual) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.……
[翻译] 将三个特定模态的对等分支通过跨网络注意力和噪声对比估计，协同地将其学习到的概率蒸馏到融合分支中，构建了一个拥有四个分支的整体预测模型。[值得关注]视频使用Tubelet embedding技术，将视频切分为时空小块（Spatial-Temporal Tubes），保留时空信息","Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios.
[翻译] 在MOSEI、EmoReact和ElderReact数据集上最先进的性能，跨数据集评估有约17%的加权F1提升，在跨年龄场景下具有鲁棒性。","The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism.
[翻译] 为了保持跨数据集一致性，要将复杂情感类归约为基础子集，由于采用时空Tubelet嵌入机制，导致了显著的计算开销",https://dl.acm.org/doi/10.1145/3581783.3612517,https://github.com/neuralnaresh/multimodal-emotion-recognition,Proceedings of the 31st ACM International Conference on Multimedia,[AI generated] **中文标题：** 基于多模态知识蒸馏的对话多标签情感分析话多标签情感分析,三个专家分别处理一个模态，训练的同时将能力蒸馏给融合分支，最终形成一个整体模型，教师（分支专家）与学生（融合专家）一同处理多模态内容，得到情感分类,figures/SeMuL-PCD.png,"Evaluating speaker emotion in conversations is crucial for various applications requiring human-computer interaction. However, co-occurrences of multiple emotional states (e.g. 'anger' and 'frustration' may occur together or one may influence the occurrence of the other) and their dynamic evolution may vary dramatically due to the speaker's internal (e.g., influence of their personalized socio-cultural-educational and demographic backgrounds) and external contexts. Thus far, the previous focus has been on evaluating only the dominant emotion observed in a speaker at a given time, which is susceptible to producing misleading classification decisions for difficult multi-labels during testing. In this work, we present Self-supervised Multi- Label Peer Collaborative Distillation (SeMuL-PCD) Learning via an efficient Multimodal Transformer Network, in which complementary feedback from multiple mode-specific peer networks (e.g.transcript, audio, visual) are distilled into a single mode-ensembled fusion network for estimating multiple emotions simultaneously. The proposed Multimodal Distillation Loss calibrates the fusion network by minimizing the Kullback-Leibler divergence with the peer networks. Additionally, each peer network is conditioned using a self-supervised contrastive objective to improve the generalization across diverse socio-demographic speaker backgrounds. By enabling peer collaborative learning that allows each network to independently learn their mode-specific discriminative patterns,SeMUL-PCD is effective across different conversation environments. In particular, the model not only outperforms the current state-of-the-art models on several large-scale public datasets (e.g., MOSEI, EmoReact and ElderReact), but with around 17% improved weighted F1-score in the cross-dataset experimental settings. The model also demonstrates an impressive generalization ability across age and demography-diverse populations.",anonymous,"【面向结果模型训练】[引用句]""Transscending the traditional paradigm of identifying single dominant emotions, Anand et al. [2023] proposed SeMuL-PCD to enhance the granularity of affective perception in diverse social contexts; by leveraging a collaborative distillation mechanism that calibrates mode-specific feedback, their model robustly disentangles multi-label emotional co-occurrences across varying demographic backgrounds (e.g., children and the elderly), thereby providing a more nuanced foundation for socially adaptive agents.""
[翻译] “为了超越识别单一主导情感的传统范式，Anand等人[2023]提出了SeMuL-PCD，旨在增强不同社会语境下情感感知的粒度；通过利用一种校准模态特定反馈的协作蒸馏机制，该模型能够在不同的人口统计背景（如儿童和老人）下鲁棒地解耦多标签情感的共现关系，从而为具备社会适应能力的智能体提供了更精细的情感理解基础。”",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.1609/icwsm.v19i1.35801,Extracting affect aggregates from longitudinal social media data with temporal adapters for large language models,"Georg Ahnert, Max Pellert, David Garcia, Markus Strohmaier",2025-06-07,Sentiment Analysis,"Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries.
[翻译] 解决了基于提示词的in silico（计算机模拟）调查中固有的时间错位问题，以及传统情感计算严重依赖资源密集型标注数据集或静态词典的可扩展性瓶颈",利用LoRA作为模块化学习元件的“时间适配器”，以捕捉特定时期独有的时间与语言特征。通过将这些轻量级适配器与冻结基座模型的固有推理能力产生协同作用，该框架实现了高效且可扩展的纵向情感预测。,"Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions.
[翻译] 采用双阶段框架：首先，通过自监督的因果语言建模目标在纵向Twitter时间线上微调每周的LoRA适配器；其次，使用标准心理测量问卷探测适配后的模型，通过Token概率分布提取聚合情感<br>[通俗核心]在每周分别进行LoRA自监督微调，让模型的预测尽可能和原数据一样。使用专业问卷作为prompt，模拟模型回答问卷，最终得到一个情感概率随时间的分布，与公众真实分布对比","Demonstrates strong, significant correlations with representative polling data (YouGov) during the COVID-19 pandemic, achieving performance comparable to supervised baselines (e.g., TweetNLP) while offering superior flexibility in querying diverse and complex collective attitudes.
[翻译] 展示了在COVID-19大流行期间与代表性民调数据（YouGov）的强显著相关性，实现了与监督基线模型（如TweetNLP）相当的性能，同时在查询多样化且复杂的集体态度方面提供了更优越的灵活性。","Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora.
[翻译] 主要在纵向趋势分析而非绝对横截面校准方面有效，且涌现出的情感代表性受限于社交媒体训练语料库中固有的人口统计学偏差",https://ojs.aaai.org/index.php/ICWSM/article/view/35801,https://github.com/dess-mannheim/temporal-adapters,ICWSM,"[AI generated] **中文标题：** 利用面向大语言模型的时间适配器从纵向社交媒体数据中提取情感聚合指标

**说明：** 此翻译力求准确、专业，符合学术论文标题的规范。
*   **Extracting affect aggregates** 译为“提取情感聚合指标”，其中“affect”在心理学和情感计算领域常译为“情感”，“aggregates”译为“聚合指标”以体现其作为测量结果的属性。
*   **from longitudinal social media data**",对于每周，训练一个LoRA作为时间适配器，使模型获得了根据时间段预测情感的能力,figures/Temporal Adapters.png;figures/Temporal Adapters2.png,"This paper proposes temporally aligned Large Language Models (LLMs) as a tool for longitudinal analysis of social media data. We fine-tune Temporal Adapters for Llama 3 8B on full timelines from a panel of British Twitter users and extract longitudinal aggregates of emotions and attitudes with established questionnaires. We focus our analysis on the beginning of the COVID-19 pandemic that had a strong impact on public opinion and collective emotions. We validate our estimates against representative British survey data and find strong positive and significant correlations for several collective emotions. The estimates obtained are robust across multiple training seeds and prompt formulations, and in line with collective emotions extracted using a traditional classification model trained on labeled data. We demonstrate the flexibility of our method on questions of public opinion for which no pre-trained classifier is available. Our work extends the analysis of affect in LLMs to a longitudinal setting through Temporal Adapters. It enables flexible and new approaches to the longitudinal analysis of social media data.",anonymous,"【集体情感分析】通过LoRA自监督学到的是该特定时间段内公众的语言风格和关注点，结合基础模型的固有能力获得了预测特定时间内公众情感的能力，很神奇，这是一个通用方法
[引用文]Moving beyond traditional supervised classifiers, Ahnert et al. (2025) demonstrate a shift toward the social simulation paradigm by proposing Temporal Adapters. Instead of training models to explicitly recognize emotion patterns, they utilize self-supervised learning to train lightweight LoRA modules as learning components, aligning the frozen LLM with specific temporal and linguistic contexts derived from longitudinal social media data. This equips the model with the capability to predict public sentiment within specific timeframes. Their approach validates that scalable and accurate tracking of public opinion dynamic
[翻译]
超越了传统的监督分类器，Ahnert等人 (2025) 通过提出 “时间适配器” 展示了向社会仿真范式的转变。他们不再训练模型去显式地识别情感模式，而是通过自监督学习训练轻量级的LoRA模块作为学习元件，将冻结的大语言模型与源自纵向社交媒体数据的特定时间及语言语境相对齐。使模型获得了预测特定时间内公众情感的能力。他们的方法证实，通过时间对齐而非标签监督，即可实现对民意动态的可扩展且准确的追踪。",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.1609/icwsm.v18i1.31304,The persuasive power of large language models,"Simon Martin Breum, Daniel V?dele Egdal, Victor Gram Mortensen, Anders Giovanni M?ller, Luca Maria Aiello",2024-05-28,Social Bots;Other,"[AI generated] Investigating whether LLM-generated arguments can persuade and if AI agents can simulate human-like opinion dynamics.
探究LLM生成的论点能否说服他人，以及AI智能体能否模拟类人的观点动态。[翻译]","[AI generated] Proposes a synthetic persuasion dialogue framework using LLM agents to study opinion dynamics and identifies effective persuasive argument types.
[翻译]
提出了一个使用LLM智能体进行合成说服对话的框架来研究观点动力学，并识别出有效的说服性论据类型。","[AI generated] Designed a synthetic persuasion dialogue on climate change, where an AI 'convincer' generates arguments for an AI 'skeptic' to evaluate opinion change, incorporating psycho-linguistic dimensions.
[翻译]
设计了一个关于气候变化的合成说服对话场景，其中一个AI“说服者”生成论点供AI“怀疑者”评估其内部观点是否改变，并融入了心理语言学维度。","[AI generated] The study found that arguments incorporating factual knowledge, trust markers, support expressions, and conveyed status were most persuasive to both AI agents and human judges, with humans showing a strong preference for knowledge-based arguments.
[翻译]
研究发现，包含事实知识、信任标记、支持表达和地位传达的论点对AI智能体和人类评判者最具说服力，人类尤其偏好基于知识的论点。","[AI generated] The study's in-silico framework and single-topic focus may not fully capture the complexity of real-world human persuasion dynamics.
[翻译]
该研究的计算机模拟框架和单一话题焦点可能无法完全捕捉现实世界人类说服动态的复杂性。",https://ojs.aaai.org/index.php/ICWSM/article/view/31304,,ICWSM,"[AI generated] **中文标题：大型语言模型的说服力**  

**论文分类参考：** 社交机器人；其他  

**摘要翻译：**  
大型语言模型日益具备类人社交代理的能力，这在舆论动力学领域引发了两个重要问题。首先，这些代理能否生成有效的论点，并将其注入在线讨论中以引导公众舆论；其次，人工代理能否通过相互互动，复现人类社交系统中典型的说服动态，从而为研究合成社交系统作为人类舆论动力学的可靠替代模型",TLDR: 显示了SIRS过程在具有大型扩展子图的图（例如社交网络模型）上的生存时间的阈值行为，显示了随机图的严格阈值。,figures/Persuasive-Power1.png;figures/Persuasive-Power2.png,"The increasing capability of Large Language Models to act as human-like social agents raises two important questions in the area of opinion dynamics. First, whether these agents can generate effective arguments that could be injected into the online discourse to steer the public opinion. Second, whether artificial agents can interact with each other to reproduce dynamics of persuasion typical of human social systems, opening up opportunities for studying synthetic social systems as faithful proxies for opinion dynamics in human populations. To address these questions, we designed a synthetic persuasion dialogue scenario on the topic of climate change, where a 'convincer' agent generates a persuasive argument for a 'skeptic' agent, who subsequently assesses whether the argument changed its internal opinion state. Different types of arguments were generated to incorporate different linguistic dimensions underpinning psycho-linguistic theories of opinion change. We then asked human judges to evaluate the persuasiveness of machine-generated arguments. Arguments that included factual knowledge, markers of trust, expressions of support, and conveyed status were deemed most effective according to both humans and agents, with humans reporting a marked preference for knowledge-based arguments. Our experimental framework lays the groundwork for future in-silico studies of opinion dynamics, and our findings suggest that artificial agents have the potential of playing an important role in collective processes of opinion formation in online social media.",anonymous,,TRUE,unread,2026-01-29 18:53:01,FALSE,,FALSE
10.1609/aaai.v39i25.34899,Temporal Triadic Closure: Finding Dense Substructures in Social Networks That Evolve over Time,"Tom Davot, Jessica Enright, Jayakrishnan Madathil, Kitty Meeks",2025-04-11,Social Network Simulation,"[AI generated] Introducing the concept of temporal c-closed graphs to model the evolving triadic closure property in real-world social networks.
[翻译]
引入时序c闭包图的概念，以建模现实世界社交网络中不断演化的三元闭包特性。","[AI generated] Introduces the concept of temporal c-closed graphs to model evolving social networks and provides efficient algorithms for enumerating dense substructures within them.
[翻译]
提出了时序c闭包图的概念来建模演化的社交网络，并为其稠密子结构的枚举提供了高效算法。","[AI generated] Introduces the concept of temporal c-closed graphs, where edges form if vertices share enough common neighbors within a short time window. Studies enumeration algorithms for maximal cliques and dense subgraphs in such slowly evolving temporal graphs.
[翻译]
提出了时序c-闭包图的概念，即若顶点在短时间内拥有足够多的共同邻居，则它们之间形成连接。研究了在此类缓慢演化的时序","[AI generated] Introduces temporal c-closed graphs and shows efficient enumeration of dense substructures in slowly evolving temporal networks.
[翻译]
提出了时序c-闭图概念，并证明了在缓慢演化的时序网络中能高效枚举稠密子结构。","[AI generated] The proposed temporal c-closure model and efficient algorithms rely on the assumption of slow network evolution, which may not hold for all real-world dynamic social networks.
[翻译]
所提出的时序c-闭包模型及高效算法依赖于网络缓慢演化的假设，这一假设可能不适用于所有现实世界的动态社交网络。",https://ojs.aaai.org/index.php/AAAI/article/view/34899,,AAAI,[AI generated] 中文标题：时序三元闭包：在随时间演化的社交网络中寻找稠密子结构,[AI generated] This method tracks evolving social clusters like watching shifting constellations in a night sky. [翻译]该方法追踪演化的社交集群，如同观测夜空中移动的星群。,,"A graph G is c-closed if every two vertices with at least c common neighbors are adjacent to each other. This definition is an abstraction of the triadic closure property exhibited by many real-world social networks, namely, friends of friends tend to be friends themselves. Social networks, however, are often temporal rather than static---the connections  change over a period of time. And hence temporal graphs, rather than static graphs, are often better suited to model social networks. Motivated by this, we introduce a definition of temporal c-closed graphs, in which if two vertices u and v have at least c common neighbors during a short interval of time, then u and v are adjacent to each other around that time. Our pilot experiments show that several real-world temporal networks are c-closed for rather small values of c. We also study the computational problems of enumerating maximal cliques and other dense subgraphs in temporal c-closed  graphs. A clique in a temporal graph is a subgraph that lasts for a certain period of time, during which every possible edge in the subgraph becomes active often enough; other dense subgraphs are defined similarly. We bound the number of such maximal dense subgraphs  in a temporal c-closed graph that evolves slowly, and thus show that the corresponding enumeration problems admit efficient algorithms; by slow evolution, we mean that between consecutive time-steps, the local change in adjacencies remains small. Our work also adds to a growing body of literature on defining suitable structural parameters for temporal graphs that can be leveraged to design efficient algorithms.",anonymous,,TRUE,,2026-01-23 19:15:29,FALSE,,FALSE
10.1609/icwsm.v19i1.35842,LIN: Latent Influence Network for Discovering Hidden Directed Influence Links on Social Media,"Chenhao Gu, Zainab Razia Zaidi, Ling Luo, Shanika Karunasekera",2025-06-07,Social Network Simulation,"[AI generated] To discover hidden and complex pathways of influence beyond apparent user interactions on social media.
[翻译]
旨在发现社交媒体上超越显性用户交互的、隐藏且复杂的影响路径。","[AI generated] Proposes a Latent Influence Network (LIN) within the LIDET framework to discover hidden directed influence links from user behavior, significantly outperforming traditional models.
[翻译]
提出了潜在影响网络（LIN）及LIDET框架，通过用户行为发现隐藏的有向影响链路，性能显著优于传统模型。","[AI generated] Proposes the Latent Influence Network (LIN) within the LIDET framework, which identifies optimal network configurations based on user behavior labels to reveal hidden influence pathways.
[翻译]
提出了潜在影响网络（LIN）及其检测框架LIDET，该框架基于用户行为标签识别最优网络配置，以揭示隐藏的影响路径。","[AI generated] LIN significantly outperforms traditional models in revealing hidden influence pathways, achieving 99% accuracy in a COVID-19 case study.
[翻译]
LIN在揭示隐藏影响路径方面显著优于传统模型，在COVID-19案例研究中实现了99%的分类准确率。","[AI generated] The framework's performance heavily depends on the quality and granularity of user behavior labels, which may not always be available or reliable.
[翻译]
该框架的性能严重依赖于用户行为标签的质量和粒度，而这些标签可能并非总是可用或可靠。",https://ojs.aaai.org/index.php/ICWSM/article/view/35842,,ICWSM,"[AI generated] 中文标题：LIN：社交媒体潜在影响力网络――用于发现隐藏有向影响力链接

（注：该翻译在保持学术严谨性的同时，兼顾中文表达习惯，将原标题的核心概念“Latent Influence Network”译为“潜在影响力网络”，并补充说明其功能“用于发现隐藏有向影响力链接”，使标题含义更完整清晰，符合中文论文标题常见表述方式。）","[AI generated] LIN acts like a social X-ray, revealing hidden influence pathways by analyzing user behavior patterns.  
[翻译]  
LIN如同社交X光，通过分析用户行为模式揭示隐藏的影响力路径。",,"In the current social media landscape, the study of influence propagation and consensus formation has gained prominence. While user interactions like retweeting are apparent, the underlying pathways of influence often remain hidden and complex. This study proposes a novel network called Latent Influence Network (LIN), which advances the analysis of influence on social media. LIN's architecture and the process of parameter selection are meticulously discussed within the comprehensive Latent Influence Detection Framework (LIDET). Based on the user's behavior label, LIN identifies the optimal network configuration, revealing more accurate influence patterns. We applied the LIDET framework to four diverse datasets, each demonstrating substantial improvements in influence pattern recognition over traditional network models. Specifically, in a case study on a COVID-19 dataset, LIN achieved a classification accuracy of 99%, significantly outperforming conventional methods. These findings underscore the utility of LIN in capturing the dynamics of influence and enhancing our understanding of opinion formation on social media.",anonymous,【之前的精读论文】,TRUE,,2026-01-22 22:11:57,FALSE,,FALSE
10.48550/arXiv.2509.04823,Evaluating cognitive-behavioral fixation via multimodal user viewing patterns on social media,"Yujie Wang, Yunwei Zhao, Jing Yang, Han Han, Shiguang Shan, Jie Zhang",2025-09-05,Social Psychological Phenomena Analysis,"It addresses the risk of cognitive-behavioral fixation (e.g., echo chambers, compulsive engagement) shaped by algorithmic curation on social media, which lacks scalable computational assessment methods.
它旨在解决由社交媒体算法策展所引发的认知行为固化（如信息茧房、强迫性参与）风险，该领域此前缺乏可扩展的计算评估方法。","It proposes the first computational framework to quantify attention fixation by hierarchically modeling user interests from multimodal data (text and video) and integrating diversity, dominance, and recurrence metrics.
它首次提出了一个计算框架，通过对多模态数据（文本和视频）进行用户兴趣的层次化建模，并综合多样性、主导性和复现性指标，以量化注意力固化。","The framework first extracts fine-grained topic phrases from multimodal content, then clusters them into higher-level thematic categories to model user attention history. Fixation is quantified by a composite score fusing entropy (diversity), HHI (dominance), and burstiness (recurrence).
该框架首先从多模态内容中提取细粒度主题短语，随后将其聚类为高层主题类别以建模用户注意力历史。固化程度通过一个融合了熵（多样性）、HHI指数（主导性）和突发性（复现性）的复合分数进行量化。","The method outperforms baselines in topic modeling on multimodal datasets. On a real-world browsing dataset (XUB), it identified 8.59% of users with strong fixation tendencies, validated by human annotations (F1 ≈ 0.857).
该方法在多模态数据集的主题建模上优于基线。在一个真实浏览数据集(XUB)上，它识别出8.59%的用户具有强固化倾向，并得到了人工标注的验证（F1 ≈ 0.857）。Limitations include modality constraints (lacking audio/interaction data), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization.
局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。","Limitations include modality constraints (lacking audio/interaction data), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization.
局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。",http://arxiv.org/abs/2509.04823,https://github.com/Liskie/cognitive-fixation-evaluation,EMNLP 2025（arxiv版本）,"[AI generated] 基于多模态用户浏览模式的社交媒体认知行为固化评估

**说明：**
1.  **核心术语处理**：将“cognitive-behavioral fixation”译为“认知行为固化”，该译法在心理学和计算社会科学领域已形成共识，能准确传达“认知与行为层面陷入僵化、重复模式”的核心含义。
2.  **方法描述清晰**：“via multimodal user viewing patterns”译为“基于多模态用户浏览模式”，明确了评估所依赖的数据类型",固化检测，评估用户注意力是否集中于狭窄领域，因此主要先对用户关注历史主题建模，然后聚类,figures/CBF-Eval.png,"Digital social media platforms frequently contribute to cognitive-behavioral fixation, a phenomenon in which users exhibit sustained and repetitive engagement with narrow content domains. While cognitive-behavioral fixation has been extensively studied in psychology, methods for computationally detecting and evaluating such fixation remain underexplored. To address this gap, we propose a novel framework for assessing cognitive-behavioral fixation by analyzing users' multimodal social media engagement patterns. Specifically, we introduce a multimodal topic extraction module and a cognitive-behavioral fixation quantification module that collaboratively enable adaptive, hierarchical, and interpretable assessment of user behavior. Experiments on existing benchmarks and a newly curated multimodal dataset demonstrate the effectiveness of our approach, laying the groundwork for scalable computational analysis of cognitive fixation. All code in this project is publicly available for research purposes at https://github.com/Liskie/cognitive-fixation-evaluation.",anonymous,"[引用文]To computationally assess how platform algorithms may narrow user attention, Wang et al. (2025) propose a novel framework for evaluating cognitive-behavioral fixation. They first employ multimodal hierarchical topic modeling to extract and cluster thematic interests from users' viewing histories. Then, they quantify fixation by integrating metrics of topical diversity, dominance, and temporal recurrence into a unified score. Validated on a dedicated dataset, this approach provides an interpretable measure for identifying users trapped in narrow engagement loops, offering a tool for individual-level behavioral modeling within larger social simulations.
[翻译]
为了从计算角度评估平台算法如何收窄用户注意力，Wang等人(2025)提出了一个评估认知行为固化的新框架。他们首先采用多模态分层主题建模，从用户的浏览历史中提取并聚类主题兴趣。然后，通过将主题多样性、主导性和时间复现性指标整合为一个统一分数来量化固化程度。该方法在专用数据集上得到验证，为识别陷入狭窄参与循环的用户提供了一个可解释的度量，为在更大规模社会仿真中进行个体层面的行为建模提供了工具。",TRUE,unread,2026-01-29 18:53:01,FALSE,,FALSE
10.48550/arXiv.2504.10157,SocioVerse: A world model for social simulation powered by LLM agents and a pool of 10 million real-world users,"Xinnong Zhang, Jiayu Lin, Xinyi Mou, Shiyue Yang, Xiawei Liu, Libo Sun, Hanjia Lyu, Yihang Yang, Weihong Qi, Yue Chen, Guanying Li, ...",2025-07-15,Social Simulation,"[AI generated] To address alignment challenges in environment, target users, interaction mechanisms, and behavioral patterns for social simulation.
[翻译]
旨在解决社会模拟中环境、目标用户、交互机制和行为模式的对齐挑战。","[AI generated] Proposes a world model with four alignment components and a 10-million-user pool for large-scale, credible social simulation.
[翻译]
提出了一个包含四个对齐组件和千万级用户池的世界模型，用于大规模、可信的社会模拟。",[AI generated] SocioVerse employs four alignment components and a pool of 10 million real users to drive LLM agents for social simulation. [翻译] SocioVerse采用四个对齐组件和一个包含1000万真实用户的池来驱动LLM智能体进行社会模拟。,"[AI generated] SocioVerse demonstrates the ability to reflect large-scale population dynamics with diversity, credibility, and representativeness across political, news, and economic domains.
[翻译]
SocioVerse在政治、新闻和经济领域展现出模拟大规模人口动态的能力，并确保了多样性、可信度和代表性。","[AI generated] The framework's reliance on LLMs' inherent capabilities and the static nature of its massive user pool may limit adaptability to novel, unforeseen social dynamics.
[翻译]
该框架对LLM固有能力及静态海量用户池的依赖，可能限制其对新颖、未预见社会动态的适应能力。",http://arxiv.org/abs/2504.10157,https://github.com/FudanDISC/SocioVerse,,[AI generated] 中文标题：SocioVerse：一个由大语言模型智能体与千万级真实用户池驱动的社会仿真世界模型,"TLDR: SocioVerse is introduced, an LLM-agent-driven world model for social simulation that can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.",figures/SocioVerse.png,"Social simulation is transforming traditional social science research by modeling human behavior through interactions between virtual individuals and their environments. With recent advances in large language models (LLMs), this approach has shown growing potential in capturing individual differences and predicting group behaviors. However, existing methods face alignment challenges related to the environment, target users, interaction mechanisms, and behavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven world model for social simulation. Our framework features four powerful alignment components and a user pool of 10 million real individuals. To validate its effectiveness, we conducted large-scale simulation experiments across three distinct domains: politics, news, and economics. Results demonstrate that SocioVerse can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.",anonymous,,TRUE,unread,2026-01-29 18:53:01,FALSE,,FALSE
10.1017/pan.2023.2,"Out of one, many: Using language models to simulate human samples","Lisa P. Argyle,Ethan C. Busby,Nancy Fulda2, Joshua R. Gubler,Christopher Rytting and David Wingate",2023-07,Social Simulation,"LLM's well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.

[翻译]模型复制社会偏见的倾向通常被视为缺陷，但本文将其重新视为一种潜在优势，认为这些偏见反映了内嵌于人类亚群体中复杂、细粒度的态度分布。","(i) proposing the novel concept of “algorithmic fidelity” and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; (ii) introducing “silicon sampling,” a method that conditions models on real demographic backstories to generate representative virtual samples
[翻译] (i) 提出“算法保真度”新概念及其四个标准，建立了量化LLM模拟人类群体效果的框架；(ii) 引入“硅采样”方法，基于真实人口背景故事对模型进行条件化，以生成有代表性的虚拟样本","(i) extracting sociodemographic profiles from large-scale human surveys; (ii) constructing first-person narrative backstories as conditioning prompts; (iii) feeding these prompts into GPT-3 to generate responses (“silicon samples”) to specific questions; (iv) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.

[翻译] (i) 从大规模人类调查中提取社会人口学特征；(ii) 构建第一人称叙事背景故事作为条件化提示；(iii) 将这些提示输入GPT-3，以生成针对特定问题的回答（“硅样本”）；(iv) 从多维度统计上比较生成数据与原始人类数据，以验证算法保真度。[通俗核心]方法很简单，使用提示词模版填入符合人口统计特征的受访者特征，让LLM输出指定回答，与人类样本做对齐","The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions (e.g., vote shares) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.

[翻译] 研究表明GPT-3表现出高算法保真度：人类评估者难以区分其输出与人类文本，其生成的数据不仅紧密复现了聚合意见分布（如投票份额），还复现了真实人类数据中人口特征、态度和行为之间复杂的相关性结构。",提示词中显示标明角色身份，会让LLM过度重视，有走捷径之嫌,https://www.cambridge.org/core/journals/political-analysis/article/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49,,Political Analysis,"[AI generated] **中文标题：** 一源多相：利用语言模型模拟人类样本

**翻译说明：**
1.  **“Out of one, many”** 译为“一源多相”，旨在传达“从一个（语言模型）中，可以产生出多种（不同人类亚群体的）样本”的核心思想。“多相”一词在学术语境中可指代多种形态或类型，契合原文的哲学意涵和模拟多样性。
2.  **主标题",让LLM模仿人类进行社会学实验，通过与真实情况对齐来判断LLM相关预测能力,"figures/Out of One, Many.png;figures/Out of One, Many2.png","We propose and explore the possibility that language models can be studied as effective proxies for specific human subpopulations in social science research. Practical and research applications of artificial intelligence tools have sometimes been limited by problematic biases (such as racism or sexism), which are often treated as uniform properties of the models. We show that the “algorithmic bias” within one such tool―the GPT-3 language model―is instead both fine-grained and demographically correlated, meaning that proper conditioning will cause it to accurately emulate response distributions from a wide variety of human subgroups. We term this property algorithmic fidelity and explore its extent in GPT-3. We create “silicon samples” by conditioning the model on thousands of sociodemographic backstories from real human participants in multiple large surveys conducted in the United States. We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and sociocultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines.",anonymous,"[引用文]Argyle et al. (2023) represent a pivotal shift from viewing LLMs as mere pattern recognition tools to employing them as tools for social simulation. Their work provides a paradigmatic methodology―centered on the concept of “algorithmic fidelity”―for experimentally testing whether and how the statistical predictions of an LLM align with nuanced human societal patterns. By conditioning GPT-3 on detailed demographic backstories within prompts (“silicon sampling”), they demonstrated that the model itself could generate attitudes and internal correlations that closely mirror those of real human subgroups. This marks a transition from goal-oriented text generation to the study of simulated social emergence.

[翻译]
Argyle等人(2023)的研究标志着一个关键转变：从将LLM视为单纯的模式识别工具，转向将其用作社会仿真的工具。他们的工作提供了一种范式方法――围绕“算法保真度”概念――来实验性地测试LLM的统计预测是否及如何与人类社会模式对齐。通过在提示词中为GPT-3施加详细的人口背景故事条件（“硅采样”），他们证明了该模型能够涌现出与真实人类亚群体高度吻合的态度及内部关联。标志着从目标导向的文本生成向模拟社会涌现研究的过渡",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.18653/v1/2024.findings-emnlp.153,Are Large Language Models (LLMs) Good Social Predictors?,"Kaiqi Yang*,Hang Li*,Hongzhi Wen,Tai-Quan Peng,Jiliang Tang,Hui Liu",2024,Social Simulation,"论文Out of one, many: Using language models to simulate human samples可能利用了捷径特性，且能力难以从宏观细化到个体","[AI generated] Proposes a novel social prediction benchmark (Soc-PRF) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts.
[翻译]：提出了一个按特征可变性分类的新颖社会预测基准（Soc-PRF），以严格评估LLMs，并揭示了其对输入捷径的依赖。","First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated “shortcut” inputs (e.g., party ID). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability (low: demographics; high: attitudes/behaviors). Three prediction settings are defined―low-to-high, high-to-low, and high-to-high―simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric.
[翻译]：首先，在ANES投票数据集上进行复制和消融研究，量化了移除高度相关的“捷径”输入（如党派身份）后的性能下降。其次，使用盖洛普世界民意调查数据构建了一个新基准。特征按可变性分类（低：人口统计学特征；高：态度/行为）。定义了三种预测设定――低推高、高推低和高推高――以模拟现实的数据收集场景。在零样本提示下评估了多种LLMs，以AUC为主要指标。","The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels (e.g., ~61% for GPT-3.5). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs (including GPT-4) perform no better than random guessing (AUC ~50). [翻译]： 先前投票预测中的高性能消失，准确率下降至接近随机水平（例如，GPT-3.5约为61%）。在排除捷径的严格Soc-PRF设定中，所有测试的LLMs（包括GPT-4）的表现均不优于随机猜测（AUC ~50）。","[AI generated] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. [翻译]：LLMs在社会预测中的优异表现严重依赖不现实的捷径特征，其使用普通输入泛化到真实场景的能力存疑。",https://aclanthology.org/2024.findings-emnlp.153,,EMNLP Findings,"[AI generated] **中文标题：** 大语言模型是优秀的社会预测器吗？

**翻译说明：**
1.  **准确性：** 直译核心疑问“Are ... Good Social Predictors?”，准确传达原文的探究性。
2.  **专业性：** 使用“大语言模型”、“社会预测器”等标准学术术语，符合计算机科学和社会科学交叉领域的表述习惯。
3.  **简洁性：** 标题简洁明了，直接点明论文的核心",消融了最能影响预测结果的“意识形态自我定位”和“党派认同”，发现预测能力接近于随机,"figures/anti-Out of One, Many.png","With the recent advancement of Large Language Models (LLMs), efforts have been made to leverage LLMs in crucial social science study methods, including predicting human features of social life such as presidential voting. Existing works suggest that LLMs are capable of generating human-like responses. Nevertheless, it is unclear how well LLMs work and where the plausible predictions derive from. This paper critically examines the performance of LLMs as social predictors, pointing out the source of correct predictions and limitations. Based on the notion of mutability that classifies social features, we design three realistic settings and a novel social prediction task, where the LLMs make predictions with input features of the same mutability and accessibility with the response feature. We find that the promising performance achieved by previous studies is because of input shortcut features to the response, which are hard to capture in reality; the performance degrades dramatically to near-random after removing the shortcuts. With the comprehensive investigations on various LLMs, we reveal that LLMs struggle to work as expected on social prediction when given ordinarily available input features without shortcuts. We further investigate possible reasons for this phenomenon and suggest potential ways to enhance LLMs for social prediction.",anonymous,"[引用文]As the field evolves from pattern recognition towards social simulation and emergent understanding, a critical reassessment of our tools is imperative. Yang et al. (2024) provide a pivotal corrective in this transition. Their work challenges the optimistic narrative that LLMs can serve as accurate social predictors. They demonstrate that previously reported successes in tasks like vote prediction critically depended on ""shortcut features"" (e.g., using party identification to predict vote choice) and, by introducing a novel shortcut-free benchmark (Soc-PRF), reveal a significant gap. In settings devoid of such shortcuts, even state-of-the-art LLMs perform at random levels. This finding underscores a fundamental limitation: while current LLMs are excellent pattern recognizers of surface correlations, they lack the deeper causal or contextual reasoning necessary for genuine social simulation and the emergence of robust socio-behavioral understanding. Their research suggests that achieving true social fidelity requires moving beyond exploiting statistical artifacts in data.

[翻译]

随着该领域从模式识别向社会仿真与涌现性理解演进，对我们的工具进行批判性重估势在必行。Yang等人（2024）在这一转变中提供了一个关键修正。他们的工作挑战了“LLMs能作为准确社会预测器”的乐观论述。他们证明，先前在投票预测等任务中报告的成功，关键依赖于“捷径特征”（例如，用党派身份预测投票选择），并通过引入一个新颖的、无捷径的基准（Soc-PRF），揭示了一个显著的差距。在缺少此类捷径的设定中，即使是最先进的LLMs表现也处于随机水平。这一发现强调了一个根本性局限：当前的LLMs虽然是优秀的表面相关性模式识别器，但缺乏真正的社会仿真以及涌现出稳健社会行为理解所必需的、更深层的因果或语境推理能力。他们的研究表明，要实现真正的社会拟真度，需要超越对数据中统计假象的利用。",TRUE,,2026-01-15 20:03:24,FALSE,,FALSE
10.1609/icwsm.v19i1.35826,Understanding Online Polarization Through Human-Agent Interaction in a Synthetic LLM-Based Social Network,"Tim Donkers, Jürgen Ziegler",2025-10-08,Social Simulation;Macrosocial Phenomena Analysis,"[AI generated] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction.
[翻译]
通过受控的人机交互，研究极化在线环境如何影响个体感知与行为。","[AI generated] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics.
[翻译]
提出了一种在基于LLM的合成社交网络中进行人机交互的新颖框架，用于实验性地研究极化动态。","[AI generated] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation.
[翻译]
一种新颖的实验框架，使人类参与者能够在受控的合成社交网络模拟中与基于大语言模型的人工智能体进行互动。","[AI generated] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation.
[翻译]
本研究利用基于大语言模型的社交模拟，提供了因果证据，表明极化的在线环境会增加情绪性和群体认同，同时减少不确定性。","[AI generated] The study's reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics.
[翻译]
该研究依赖基于LLM的合成模拟，其发现推广到真实世界社交媒体动态的普适性可能受限。",https://ojs.aaai.org/index.php/ICWSM/article/view/35826,,AAAI,"[AI generated] 中文标题：基于合成LLM社交网络中的人机交互理解在线极化现象

（注：该翻译准确传达了原标题的学术内涵，其中“Polarization”译为“极化现象”以符合社会科学领域术语习惯，“Synthetic LLM-Based Social Network”采用“基于合成LLM的社交网络”的译法，既保持技术准确性又符合中文表达规范，整体结构符合国内学术论文标题的简洁性要求。）",[AI generated] This study uses a digital petri dish of AI agents to observe how online echo chambers amplify human polarization. [翻译] 这项研究利用AI智能体构成的数字培养皿，观察网络回音室如何放大人类观点的极化。,,"The rise of social media has fundamentally transformed how people engage in public discourse and form opinions. While these platforms offer unprecedented opportunities for democratic engagement, they have been implicated in increasing social polarization and the formation of ideological echo chambers. Previous research has primarily relied on observational studies of social media data or theoretical modeling approaches, leaving a significant gap in our understanding of how individuals respond to and are influenced by polarized online environments. Here we present a novel experimental framework for investigating polarization dynamics that allows human users to interact with LLM-based artificial agents in a controlled social network simulation. Through a user study with 122 participants, we demonstrate that this approach can successfully reproduce key characteristics of polarized online discourse while enabling precise manipulation of environmental factors. Our results provide empirical validation of theoretical predictions about online polarization, showing that polarized environments significantly increase perceived emotionality and group identity salience while reducing expressed uncertainty. These findings extend previous observational and theoretical work by providing causal evidence for how specific features of online environments influence user perceptions and behaviors. More broadly, this research introduces a powerful new methodology for studying social media dynamics, offering researchers unprecedented control over experimental conditions while maintaining ecological validity.",anonymous,,TRUE,,2026-01-22 22:11:57,FALSE,,FALSE
10.1109/TNSE.2024.3523300,Predicting Participation Shift of Users at the Next Stage in Social Networks,"Yichao Zhang, Zejian Wang, Huangxin Zhuang, Lei Song, Guanghui Wen, Jihong Guan, Shuigeng Zhou",2025-03,User Behavior Prediction;Information Diffusion Analysis,"Addresses the granularity gap in diffusion analysis by shifting focus from macro-level popularity prediction to micro-level participation shift prediction (i.e., identifying specific users transitioning from listeners to spreaders at the next timestamp), particularly under data-sparse ""cold start"" conditions.
[翻译] 解决了传播分析中的粒度差距问题，将关注点从宏观流行度预测转移到微观层面的参与转变预测（即识别在下一时间戳从听众转变为传播者的具体用户），特别是在数据稀疏的“冷启动”条件下。","Proposes an unsupervised Triple Ranking (TR) framework that integrates physics-inspired Social Gravity with temporal and sequential features, interpreting information cascades not merely as similarity measures but as dynamic activation signals that exert ""gravitational forces"" on potential candidates.
[翻译] 提出了一种无监督的三重排名（TR）框架，该框架将受物理学启发的社会引力与时间和序列特征相结合，不仅将信息级联视为相似性度量，更将其视为对潜在候选人施加“引力”的动态激活信号。","Decomposes the diffusion lifecycle into discrete stages and calculates three rankings for candidates: Exposure Time Ranking (based on response latency distributions derived from cascade timestamps), Social Gravity Ranking (modeling influence as physical forces from active neighbors in the cascade subgraph), and Cascade Similarity Ranking (learning latent user correlations via Skip-gram embeddings), which are fused linearly or via Graph Neural Networks (T-GCN/T-GAT).
[翻译] 将传播生命周期分解为离散阶段，并为候选人计算三种排名：曝光时间排名（基于从级联时间戳导出的响应延迟分布）、社会引力排名（将影响力建模为级联子图中活跃邻居的物理作用力）和级联相似度排名（通过Skip-gram嵌入学习潜在的用户相关性），这些排名通过线性加权或图神经网络（T-GCN/T-GAT）进行融合。","Experimental evaluations on three Twitter datasets (Higgs, Munmun, Virality2013) demonstrate that the unsupervised TR model and its supervised variants consistently outperform probabilistic baselines (IC, DT, GT) and state-of-the-art GNNs (DeepInf) in Precision, Recall, and F1-Measure, with significantly reduced computational complexity.
[翻译] 在三个Twitter数据集（Higgs, Munmun, Virality2013）上的实验评估表明，无监督TR模型及其有监督变体在精确率、召回率和F1值上均优于概率基线（IC, DT, GT）和最先进的GNN模型（DeepInf），且计算复杂度显著降低。","The model currently relies exclusively on topological structure and temporal traces, neglecting semantic information (textual content) and assuming a static underlying network topology without accounting for structural evolution over time.
[翻译] 该模型目前仅依赖拓扑结构和时间轨迹，忽略了语义信息（文本内容），且假设底层网络拓扑是静态的，未考虑结构随时间的演化。",https://ieeexplore.ieee.org/document/10829773/,,IEEE Trans. Netw. Sci. Eng.,"[AI generated] **中文标题：** 社交网络中用户下一阶段参与转变的预测

**说明：** 此翻译力求准确、专业，符合学术论文标题的规范。它直接对应了原标题的核心要素：
*   **Predicting** -> **预测**：点明研究任务。
*   **Participation Shift of Users** -> **用户参与转变**：精准概括了研究对象和核心行为变化。
*   **at the Next Stage** -> **下一阶段**：明确了预测",一个参与可能性排序算法，综合曝光时间排名、社会引力排名（借用万有引力思想）、级联相似度排名（与历史级联中的其他用户特征对比）,figures/TR-1.png;figures/TR-2.png,"In online social networks, numerous studies have demonstrated the challenge of predicting who will eventually engage in an information cascade with its initial part. Take a step back. Can we predict who will engage in the cascade at the next stage if the lifetime of cascades is divided into a certain number of stages? Although numerous attempts have been made to solve this problem, how to extract useful information from the historical cascades spreading within a sub-network and the connections among users remains an open question. This paper proposes a simple but efficient unsupervised agent-based model, the triple ranking model, which integrates exposure time ranking, social gravity ranking, and cascade similarity ranking. The rankings, a key component of our model, have been successful in characterizing the social impact of shifted users, temporal information, and sequential cascade information, demonstrating the generalizability of our approach. To test the contributions of the features in supervised frameworks, we fuse them with two graph neural networks, the graph convolutional network (GCN) and graph attention network (GAT). Our experimental results on three Twitter networks unequivocally show that the proposed algorithm outperforms the tested state-of-art algorithms across a series of performance metrics. Notably, its time complexity is also lower than theirs, further underscoring its superiority. The observations demonstrate that the rankings effectively abstract the features hidden in the information cascades and in the topology of social networks, paving the way for further studies on posting engagement.",anonymous,"【用户参与行为预测（方法），下一阶段会有哪些用户成为传播者（应用）】【也是一个不关注内容的，只关注级联图结构（包含时间）】[引用文]To understand the micro-dynamics of propagation, Zhang et al. [2025] move beyond static topological analysis to predict participation shifts at specific cascade stages. Their Triple Ranking (TR) model treats information cascades as dynamic subgraphs that actively influence the underlying user network. By introducing a physics-inspired Social Gravity mechanism, the method quantifies the cumulative impact of active neighbors on candidates as a resultant force, integrated with Exposure Time distributions and Cascade Similarity embeddings. This approach effectively addresses the cold-start problem in behavior prediction by fusing these structural and temporal signals into a unified ranking system, demonstrating that agent-based heuristics can effectively capture diffusion probabilities without extensive supervised training.
[翻译] 为了理解传播的微观动态，Zhang等人 [2025] 超越了静态拓扑分析，转而预测特定级联阶段的参与转变。他们的三重排名（TR）模型将信息级联视为主动影响底层用户网络的动态子图。通过引入受物理学启发的社会引力机制，该方法将活跃邻居对候选人的累积影响量化为合力，并与曝光时间分布和级联相似度嵌入相结合。该方法通过将这些结构和时间信号融合到一个统一的排名系统中，有效解决了行为预测中的冷启动问题，证明了基于智能体的启发式方法无需大量监督训练即可有效捕捉传播概率。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
10.0000/placeholder-PASUM,PASUM: A pre-training architecture for social media user modeling based on text graph,"Kun Wu, Xinyi Mou, Lanqing Xue, Zhenzhe Ying, Weiqiang Wang, Qi Zhang, Xuanjing Huang, Zhongyu Wei",2024-05,User Profiling,"To overcome the limitations of existing methods that struggle with lengthy user texts and the unavailability of explicit social graphs, this work addresses the challenge of learning generalizable user representations without relying on complete social network data.

[翻译] 为克服现有方法在处理用户长文本和显式社交图谱缺失时的局限性，本工作旨在解决不依赖完整社交网络数据而学习可泛化用户表示的挑战。","Its core innovation lies in an inductive pre-training architecture that represents users solely via personal text graphs and injects social structural awareness through inter-user and intra-user contrastive learning, eliminating the need for explicit social network input during inference.

[翻译] 其核心创新在于一个归纳式预训练架构：仅通过个人文本图表征用户，并借助用户间与用户内对比学习注入社交结构感知，从而在推理时无需显式的社交网络输入。","The PASUM framework first constructs a text graph from each user's microblogs. It then employs a Graph Isomorphism Network (GIN) to encode the graph into a user representation. Finally, it pre-trains the encoder using contrastive loss functions defined over user pairs (based on follow relations) and subgraph pairs (based on community membership).

[翻译] PASUM框架首先从每位用户的微博构建文本图，随后使用图同构网络（GIN）将图表编码为用户表示，最后利用基于用户对（关注关系）和子图对（社区归属）定义的对比损失函数对编码器进行预训练。","Extensive experiments on user profiling tasks demonstrate that PASUM outperforms text-based and graph-based baselines, particularly showing robustness when social connections are sparse or absent, validating the effectiveness of its structure-infused pre-training.

[翻译] 在多个用户画像任务上的实验表明，PASUM优于基于文本和基于图的方法基线，尤其在社交连接稀疏或缺失时表现出鲁棒性，验证了其融入结构的预训练策略的有效性。","Limitations include mediocre few-shot performance and reliance solely on network-derived structural signals. Future work could integrate multimodal user behaviors and attributes to enrich the pre-training paradigm.

[翻译] 其局限性包括小样本学习性能一般，且仅依赖于网络衍生的结构信号。未来工作可整合多模态用户行为与属性，以丰富预训练范式。",https://aclanthology.org/2024.lrec-main.1107/,,LREC-COLING 2024,[AI generated] **中文标题：** PASUM：一种基于文本图的社交媒体用户建模预训练架构,利用关注图网络的结构进行自监督训练（不同用户间对比学习，同用户不同社群间对比学习），使用词图结构聚合为用户表征，尝试解决长文本问题,figures/PASUM.png,"Modeling social media users is the core of social governance in the digital society. Existing works have incorporated different digital traces to better learn the representations of social media users, including text information encoded by pre-trained language models and social network information encoded by graph models. However, limited by overloaded text information and hard-to-collect social network information, they cannot utilize global text information and cannot be generalized without social relationships. In this paper, we propose a Pre-training Architecture for Social Media User Modeling based on Text Graph(PASUM). We aggregate all microblogs to represent social media users based on the text graph model and learn the mapping from microblogs to user representation. We further design inter-user and intra-user contrastive learning tasks to inject general structural information into the mapping. In different scenarios, we can represent users based on text, even without social network information. Experimental results on various downstream tasks demonstrate the effectiveness and superiority of our framework.",anonymous,"[note]关注网络的网络关系只是实现了训练数据的标注，并不是将整个图输入模型，**这相当于将图拓扑信息蒸馏到了非GNN模型中**。预训练时用户的特征表示也是词图聚合得到的。[引用文]In a technical approach to user modeling that does not require a global social graph at inference time, PASUM (Wu et al., 2024) pre-trains a user encoder by leveraging social network data only to generate supervision signals. The model processes a user's aggregated microblogs as a local text graph, and during pre-training, it is optimized so that its output representations satisfy constraints derived from follow networks (homophily) and community memberships (multi-faceted roles). This approach achieved superior accuracy on several downstream profiling tasks compared to methods that directly input social adjacency matrices, demonstrating the efficacy of distilling structural information into the model parameters via contrastive learning.

[翻译] 作为一种在推理时无需全局社交图谱的用户建模技术方案，PASUM (Wu et al., 2024) 预训练用户编码器的方法仅利用社交网络数据来生成监督信号。该模型将用户聚合的微博处理为局部文本图，并在预训练期间进行优化，使其输出的表示满足源自关注网络（同质性）和社区归属（多面角色）的约束。与直接输入社交邻接矩阵的方法相比，该方法在多个下游画像任务上取得了更高的准确率，证明了通过对比学习将结构信息蒸馏到模型参数中的有效性。",TRUE,skimmed,2026-01-29 10:07:59,FALSE,,FALSE
10.18653/v1/2023.emnlp-main.972,Stance Detection on Social Media with Background Knowledge,"Ang Li, Bin Liang, Jingqian Zhao, Bowen Zhang, Min Yang, Ruifeng Xu",2023,User Stance Detection,"Stance detection often struggles with the brevity and implicit nature of social media texts, where conventional keyword-based retrieval methods frequently introduce noise or fail to capture the underlying sociopoli
[翻译] 立场检测常受限于社交媒体文本的短小和隐含性，而传统的基于关键词的检索方法往往引入噪声或未能捕捉潜在的社会政治语境。","Li et al. (2023) introduce the KASD framework, which categorizes background information into episodic (factual) and discourse (linguistic) knowledge, distinctively utilizing Large Language Models (LLMs) as active semantic filters and paraphrasers rather than mere predictive engines.
[翻译] Li等人（2023）引入了KASD框架，将背景信息分类为情景知识（事实）和语篇知识（语言），其独特之处在于利用大语言模型（LLM）作为主动的语义过滤器和改写器，而不仅仅是预测引擎。","The methodology operates at the discourse level by utilizing LLMs to expand slang and hashtags into explicit text, and at the episodic level by employing topic modeling with heuristic metrics to retrieve Wikipedia documents for LLM summarization, ultimately fusing both into a structured input for classifica
[翻译] 语篇层面利用LLM将俚语和标签扩展为明确文本，情景层面利用主题建模和启发式度量检索维基百科文档并由LLM进行总结，最后将两者融合为结构化输入以进行分类。","Experimental results across four benchmarks demonstrate that KASD achieves state-of-the-art performance, with knowledge-augmented fine-tuned models significantly outperforming standard LLMs in both in-target and zero-shot scenarios.
[翻译] 在四个基准测试上的实验结果表明，KASD取得了最先进的性能，经过知识增强的微调模型在目标内和零样本场景中均显著优于标准LLM。","A primary limitation lies in the reliance on pre-crawled Wikipedia dumps, which may inhibit the detection of stances regarding real-time events or breaking news not yet documented in static knowledge bases.
[翻译] 主要局限性在于依赖预先爬取的维基百科数据，这可能阻碍对静态知识库中尚未记录的实时事件或突发新闻的立场检测。",https://aclanthology.org/2023.emnlp-main.972,https://github.com/HITSZ-HLT/KA-Stance-Detection,EMNLP 2023,"[AI generated] 中文标题：**融合背景知识的社交媒体立场检测**

（说明：该翻译准确传达了原标题“Stance Detection on Social Media with Background Knowledge”的核心要素。“融合”一词体现了将背景知识整合进检测过程的动态性和方法创新性，符合原文强调利用知识增强检测性能的研究主旨。整体表述简洁、专业，符合中文计算机科学或信息科学领域的学术论文标题风格。）","A retrieval-augmented stance detection framework that synthesizes LLM-refined Wikipedia facts and linguistic expansions to address the issue of stance implicitness in social media posts.
[翻译] 检索增强的立场检测框架，通过综合经LLM提炼的维基百科事实和语言扩展信息，来解决社交媒体帖子的立场隐含性问题。",figures/KASD.png,"Identifying users' stances regarding specific targets/topics is a significant route to learning public opinion from social media platforms. Most existing studies of stance detection strive to learn stance information about specific targets from the context, in order to determine the user's stance on the target. However, in real-world scenarios, we usually have a certain understanding of a target when we express our stance on it. In this paper, we investigate stance detection from a novel perspective, where the background knowledge of the targets is taken into account for better stance detection. To be specific, we categorize background knowledge into two categories: episodic knowledge and discourse knowledge, and propose a novel Knowledge-Augmented Stance Detection (KASD) framework. For episodic knowledge, we devise a heuristic retrieval algorithm based on the topic to retrieve the Wikipedia documents relevant to the sample. Further, we construct a prompt for ChatGPT to filter the Wikipedia documents to derive episodic knowledge. For discourse knowledge, we construct a prompt for ChatGPT to paraphrase the hashtags, references, etc., in the sample, thereby injecting discourse knowledge into the sample. Experimental results on four benchmark datasets demonstrate that our KASD achieves state-of-the-art performance in in-target and zero-shot stance detection.",anonymous,"[方法总结]输入：评论和他的target->输入通过LLM将俚语简写标签扩展为完整内容->对输入进行主题建模，从维基百科中通过主题相似度和内容相似度（与评论）检索出相关知识->相关知识交由LLM进行过滤总结->生成结构化输出模板->使用输出模板进行微调或作为少样本进行立场分类[引用文]To bridge the gap between static text recognition and dynamic context understanding, Li et al. (2023) proposed the Knowledge-Augmented Stance Detection (KASD) framework to address the semantic scarcity of short texts. Their approach simulates a human-like reasoning process on two levels: at the discourse level, it utilizes LLMs to interpret and expand sociolinguistic cues, such as hashtags and slang, into explicit natural language; at the episodic level, it combines topic modeling with heuristic similarity metrics to retrieve relevant Wikipedia documents, which are filtered and summarized by an LLM to extract precise episodic knowledge. By fusing this refined external context with the original input for fine-tuning or few-shot inference, KASD demonstrates that guiding models with structured, retrieved knowledge yields superior performance compared to unguided generation, marking a shift towards more robust, context-aware social computing agents.
[翻译] 为了弥合静态文本识别与动态语境理解之间的鸿沟，Li等人（2023）提出了知识增强立场检测（KASD）框架，以解决短文本的语义稀缺问题。他们的方法从两个层面模拟了类人的推理过程：语篇层面，利用LLM解释并将标签、俚语等社会语言线索扩展为明确的自然语言；情景层面，结合主题建模与启发式相似度度量检索相关的维基百科文档，并通过LLM进行过滤和总结以提取精确的情景知识。通过将这种提炼后的外部语境与原始输入融合进行微调或少样本推理，KASD证明了利用结构化的检索知识引导模型比无引导的生成具有更优越的性能，这标志着向更鲁棒、具备语境感知能力的社会计算代理的转变。",TRUE,unread,2026-01-29 18:53:01,FALSE,,FALSE
10.1609/icwsm.v18i1.31360,Stance Detection with Collaborative Role-Infused LLM-Based Agents,"Xiaochong Lan, Chen Gao, Depeng Jin, Yong Li",2024-05-28,User Stance Detection,"In addressing the dual challenges of stance detection―the need for multi-faceted textual comprehension and complex reasoning over implicit stances―this study seeks to move beyond the data dependency of traditional methods and the suboptimal direct application of Large Language Models (LLMs).
[翻译]
为解决立场检测中的双重挑战――需要多层面的文本理解能力和对隐含立场的复杂推理――本研究旨在超越传统方法对数据的依赖以及直接应用大语言模型（LLM）的次优表现。","The key innovation is the design of a multi-agent system (COLA) that simulates a debate arena, where LLM-based agents advocate for different stances, thereby transforming stance inference into a structured process of adversarial reasoning and collaborative synthesis.
[翻译]
其核心创新在于设计了一个模拟辩论场的多智能体系统（COLA），其中基于LLM的智能体为不同立场进行辩护，从而将立场推断转化为一个对抗性推理与协作合成的结构化过程。","The COLA framework operates in three stages: a multi-dimensional analysis by role-specific agents (linguist, domain expert, social media veteran), a reasoning-enhanced debate where dedicated agents argue for ‘Favor’, ‘Against’, or ‘Neutral’ stances, and a final judgment stage that synthesizes all arguments.
[翻译]
COLA框架按三阶段运行：由角色化智能体（语言学家、领域专家、社交媒体资深用户）进行多维度分析；一个推理增强的辩论阶段，由专门智能体为“支持”、“反对”或“中立”立场进行论证；以及一个综合所有论点的最终裁决阶段。","Experimental results demonstrate that this zero-shot, training-free approach achieves state-of-the-art performance, matching or surpassing models trained on in-target labeled data across multiple benchmarks, while providing explainable outputs.
[翻译]
实验结果表明，这种零样本、无需训练的方法实现了最先进的性能，在多个基准测试中达到甚至超越了依赖靶向标注数据训练的模型，同时能提供可解释的输出。","A primary limitation is the potential inadequacy in handling real-time events due to static LLM knowledge. Future work aims to integrate real-time knowledge retrieval and extend the multi-agent debate paradigm to broader social reasoning tasks.
[翻译]
一个主要局限在于，由于LLM知识的静态性，其在处理实时事件时可能存在不足。未来工作旨在集成实时知识检索，并将多智能体辩论范式扩展到更广泛的社会推理任务中。",https://ojs.aaai.org/index.php/ICWSM/article/view/31360,https://github.com/tsinghua-fib-lab/COLA,ICWSM,"[AI generated] 中文标题：基于角色化大语言模型智能体协同的立场检测

（说明：此翻译力求准确传达原标题的学术内涵与技术要点。""Collaborative Role-Infused LLM-Based Agents"" 译为""基于角色化大语言模型智能体协同""，既保留了""角色化""（Role-Infused）这一方法核心特征，又通过""协同""体现多智能体协作机制，符合计算机领域对""Agents""的通行译法，整体表述简洁",AMB辩论场模拟（本质上类似高级cot）,figures/COLA.png,"Stance detection automatically detects the stance in a text towards a target, vital for content analysis in web and social media research. Despite their promising capabilities, LLMs encounter challenges when directly applied to stance detection. First, stance detection demands multi-aspect knowledge, from deciphering event-related terminologies to understanding the expression styles in social media platforms. Second, stance detection requires advanced reasoning to infer authors' implicit viewpoints, as stances are often subtly embedded rather than overtly stated in the text. To address these challenges, we design a three-stage framework COLA (short for Collaborative rOle-infused LLM-based Agents) in which LLMs are designated distinct roles, creating a collaborative system where each role contributes uniquely. Initially, in the multidimensional text analysis stage, we configure the LLMs to act as a linguistic expert, a domain specialist, and a social media veteran to get a multifaceted analysis of texts, thus overcoming the first challenge. Next, in the reasoning-enhanced debating stage, for each potential stance, we designate a specific LLM-based agent to advocate for it, guiding the LLM to detect logical connections between text features and stance, tackling the second challenge. Finally, in the stance conclusion stage, a final decision maker agent consolidates prior insights to determine the stance. Our approach avoids extra annotated data and model training and is highly usable. We achieve state-of-the-art performance across multiple datasets. Ablation studies validate the effectiveness of each role design in handling stance detection. Further experiments have demonstrated the explainability and the versatility of our approach. Our approach excels in usability, accuracy, effectiveness, explainability and versatility, highlighting its value.",anonymous,"【ABM方法】[引用文]Within the exploration of agent-based social interaction and emergent behavior, the work by Lan et al. (2024) constitutes an attempt to transition from static pattern recognition to dynamic, goal-oriented interaction simulation. Their proposed COLA framework transforms stance detection into a process of multi-agent collaborative and adversarial reasoning by constructing a “simulated debate arena” populated by role-infused LLM agents. The framework achieves excellent zero-shot performance without additional data training. Its “analyst-debater-summarizer” architecture mimics the social deliberation involved in opinion formation, serving as a prime example of how structured multi-agent interaction can be harnessed to elicit and regulate complex reasoning capabilities.
[翻译]
在探索基于智能体的社会性交互与涌现行为的背景下，Lan等人（2024）的工作进行了从静态模式识别向动态、目标导向交互仿真过渡的尝试。他们提出的COLA框架通过构建一个由角色化大语言模型智能体组成的“模拟辩论场”，将立场检测任务转化为一个多智能体协作推理与对抗辩论的过程。该框架在没有额外数据训练的情况下取得了优异的零样本检测性能。其“分析师-辩论家-总结者”的架构模拟了观点形成过程中的社会性思辨，是通过结构化多智能体交互来激发并规制复杂推理能力的典型例子。",TRUE,skimmed,2026-01-29 18:53:01,FALSE,,FALSE
