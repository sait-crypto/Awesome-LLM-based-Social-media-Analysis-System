{
  "papers": [
    {
      "doi": "10.48550/arXiv.2407.07061",
      "title": "Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence",
      "authors": "Weize Chen*, Ziming You*, Ran Li*, Yitong Guan*, Chen Qian, Chenyang Zhao Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun",
      "date": "2024-10-04",
      "category": "Base Techniques",
      "summary_motivation": "å…ˆå‰çš„multi-agentç³»ç»Ÿçš„å±€é™æ€§ï¼Œç³»ç»ŸåŒ–å¹³å°åŒ–ç¨‹åº¦ä¸è¶³ï¼ˆç¼ºä¹ç¬¬ä¸‰æ–¹é›†æˆæ”¯æŒï¼Œæ— æ³•åˆ†å¸ƒå¼ï¼Œé€šä¿¡åè®®å’ŒçŠ¶æ€è½¬æ¢ä¾èµ–äºç¡¬ç¼–ç ï¼‰",
      "summary_innovation": "å°†äº’è”ç½‘çš„å¼€æ”¾ã€åˆ†å¸ƒå¼ã€æœåŠ¡åŒ–æ€æƒ³å¼•å…¥ï¼Œæ„å»ºä¸€ç§æ ‡å‡†åŒ–ã€å¯æ‰©å±•çš„æ”¯æŒåˆ†å¸ƒå¼ã€å¼‚æ„çš„æ™ºèƒ½ä½“é›†æˆä¸é€šä¿¡åè®®ã€‚",
      "summary_method": "æœåŠ¡å™¨ï¼šæ™ºèƒ½ä½“æ³¨å†Œï¼ˆåˆ†å‘ç³»ç»Ÿæç¤ºè¯ï¼‰ã€ç®¡ç†å·²æ³¨å†Œæ™ºèƒ½ä½“ï¼ˆä¸“å®¶ï¼‰ã€ä¸“å®¶å‘ç°æœåŠ¡ã€ç¾¤èŠç®¡ç†å’Œæ¶ˆæ¯ä¼ é€’ï¼›å®¢æˆ·ç«¯ï¼šåŒ…è£…å…·ä½“æ™ºèƒ½ä½“ï¼Œæä¾›é€šä¿¡æ¥å£ï¼›ä¸‰å±‚ç»“æ„ï¼›é€šä¿¡å³å¯åµŒå¥—çµæ´»ç¾¤èŠï¼›ç¾¤èŠé‡‡ç”¨**æœ‰é™çŠ¶æ€æœº**ç®¡ç†æµç¨‹ï¼›å¹³å°åˆå§‹åŒ–ä¸æ³¨å†Œ->ä»»åŠ¡è§¦å‘å›¢é˜Ÿå½¢æˆ->å†…éƒ¨åµŒå¥—åä½œ",
      "summary_conclusion": "åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»…ä½¿ç”¨å››ä¸ªåŸºç¡€ ReAct æ™ºèƒ½ä½“å³è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼›åœ¨ RAG ä»»åŠ¡ä¸­ï¼ŒåŸºäº GPT-3.5 çš„ IoA è¾¾åˆ°æˆ–è¶…è¿‡ GPT-4 çš„æ€§èƒ½",
      "summary_limitation": "å®éªŒä¸­å­˜åœ¨å†—ä½™æ¶ˆæ¯ï¼Œé€šä¿¡ Token æ¶ˆè€—å¢åŠ è¿‘ä¸€å€ï¼Œè¿™è¯æ˜agentä½œä¸ºå¯¹è¯è€…è€Œéæ‰§è¡Œè€…çš„æœ¬è´¨èƒ½åŠ›åŒºåˆ«ï¼›å•ç‚¹æœåŠ¡å™¨å¯èƒ½å­˜åœ¨ç“¶é¢ˆï¼›æ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»é«˜åº¦ä¾èµ–äººå·¥å®éªŒè®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é ",
      "paper_url": "https://openreview.net/forum?id=o1Et3MogPw",
      "project_url": "https://github.com/OpenBMB/IoA",
      "conference": "The Thirteenth International Conference on Learning Representations",
      "title_translation": "[AI generated] **æ™ºèƒ½ä½“äº’è”ç½‘ï¼šæ„å»ºå¼‚æ„æ™ºèƒ½ä½“ç½‘ç»œä»¥å®ç°ååŒæ™ºèƒ½**\n\n**è¯´æ˜ï¼š**\n1.  **æ ¸å¿ƒæ¦‚å¿µç›´è¯‘**ï¼šå°† \"Internet of Agents\" ç›´è¯‘ä¸ºâ€œæ™ºèƒ½ä½“äº’è”ç½‘â€ï¼Œå‡†ç¡®å¯¹åº”å…¶å€Ÿé‰´äº’è”ç½‘ç†å¿µçš„æ ¸å¿ƒåˆ›æ–°ï¼Œå¹¶ä¸ç‰©è”ç½‘ï¼ˆIoTï¼‰ç­‰æœ¯è¯­å½¢æˆæ¦‚å¿µç±»æ¯”ï¼Œç¬¦åˆå­¦æœ¯è¯­å¢ƒã€‚\n2.  **å‰¯æ ‡é¢˜æ„è¯‘ä¸ä¼˜åŒ–**ï¼šå°† \"Weaving a web of heterogeneous agents for collaborative intelligence\" æ„è¯‘ä¸ºâ€œæ„å»ºå¼‚æ„æ™ºèƒ½ä½“ç½‘ç»œ",
      "analogy_summary": "agentäº’è”ç½‘ï¼Œå‡çº§ç‰ˆABMç³»ç»Ÿï¼Œé‡‡ç”¨ç±»ä¼¼äº’è”ç½‘æ€æƒ³ï¼ŒC/Sæ¶æ„ï¼Œåˆ†å¸ƒåŒ–ã€æœåŠ¡åŒ–ã€å¹³å°åŒ–",
      "pipeline_image": "figures/IoA.png;figures/IoA2.png",
      "abstract": "The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. We will release our code to facilitate further research.",
      "contributor": "",
      "notes": "æ¯ä¸ªagentè¢«ä¸€ä¸ªå®¢æˆ·ç«¯åŒ…è£…ï¼›æœåŠ¡å™¨ä¸æ˜¯agentï¼Œå®ƒåªåšå››ä»¶äº‹ï¼šæ³¨å†Œã€å‘ç°ã€å»ºç¾¤ã€è·¯ç”±ï¼›ç›¸å¯¹äºä¼ ç»ŸABMï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´å¤§å‹çš„æœåŠ¡ç³»ç»Ÿï¼Œè¯¥æ–¹æ³•é€šè¿‡åŸºäºä»»åŠ¡çš„â€œç¾¤èŠâ€æ–¹å¼ç»„ç»‡é—®é¢˜è§£å†³ï¼Œç›¸å¯¹ä¼ ç»Ÿå›åˆåˆ¶æ–¹å¼æ›´åŠ è‡ªç”±ã€‚æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ªé«˜åº¦å¯æ‰©å±•ç³»ç»Ÿã€‚é—®é¢˜åœ¨äºæ™ºèƒ½ä½“é€šè¿‡æ³¨å†Œè·å–æç¤ºè¯æˆä¸ºä¸åŒä¸“å®¶ï¼Œä»ä¾èµ–æ‰‹å·¥è®¾è®¡ï¼Œä¸”è¿™ç§ä¸“å®¶çš„èƒ½åŠ›æ˜¯å¦å¯é ã€‚å¯¹äºç¤¾ä¼šæ¨¡æ‹Ÿä»»åŠ¡ç›¸å¯¹äºä¼ ç»Ÿæ–¹æ³•æœ‰ä½•å†³å®šæ€§ä¼˜åŠ¿ä»æœªå¯çŸ¥",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/aaai.v37i4.25614",
      "title": "TOT: Topology-Aware Optimal Transport for Multimodal Hate Detection",
      "authors": "Linhao Zhangï¼ŒLi Jinï¼ŒXian Sunï¼ŒGuangluan Xuï¼ŒZequn Zhang,Xiaoyu Li,Nayu Liu,Qing Liu,Shiyao Yan",
      "date": "2023-06-26",
      "category": "Hate Speech Analysis",
      "summary_motivation": "ä¸ºäº†è§£å†³å¤šæ¨¡æ€ä»‡æ¨æ£€æµ‹ä¸­å› â€ éšå¼å¯¹é½â€ å’Œâ€ æ¨¡æ€é¸¿æ²Ÿâ€ å¯¼è‡´çš„å›¾åƒå’Œæ–‡æœ¬è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½éš¾é¢˜",
      "summary_innovation": "å°†OTç”¨äºç‰¹å¾å¯¹é½ï¼Œå°†å¥å­çº§å¯¹é½ç»†ç²’åŒ–è‡³å‘é‡çº§ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†â€œæ˜¾å¼å¯¹é½+ç»“æ„æ¨ç†â€çš„èŒƒå¼",
      "summary_method": "æœ€ä¼˜ä¼ è¾“ + æ‹“æ‰‘ç»“æ„æ¨ç†æ–¹æ³• TOTï¼šCLIP æ–¹æ³•ç»Ÿä¸€è¡¨å¾æ˜ å°„->æœ€ä¼˜ä¼ è¾“optimal transport (OT)å°†éšå¼è”ç³»ç»†ç²’åŒ–ä¸ºå‘é‡çº§ï¼ˆè¿™æ˜¯ä¸€ä¸ªæ•°å­¦è®¡ç®—è¿‡ç¨‹ï¼Œä¸æ¶‰åŠéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼‰->ç±»GNNè¿­ä»£æ•æ‰è‡ªèº«è¯­ä¹‰è”ç³»ï¼ˆç±»è‡ªæ³¨æ„åŠ›ï¼‰ï¼ˆå› ä¸ºå‘é‡é—´è·ç¦»æ„ä¹‰æ˜ç¡®ï¼‰->æ®‹å·®è¿æ¥",
      "summary_conclusion": "è¾¾æˆäº†åœ¨ä¸¤ä¸ªæœ‰å®³ Meme æ£€æµ‹æ•°æ®é›†ï¼ˆHarm-C, Harm-Pï¼‰ä¸Šçš„æœ€å…ˆè¿›æ€§èƒ½ï¼›",
      "summary_limitation": "å¯¹é½å’Œæ¨ç†ä»å±€é™äºç‰¹å¾å±‚é¢ï¼Œæœªä¸Šå‡åˆ°è¯­ä¹‰å•å…ƒï¼ˆå¦‚äº‹ä»¶ã€æ¦‚å¿µï¼‰å±‚é¢ï¼ŒOTè¿‡ç¨‹ä¸ºå†»ç»“æ— æ³•è®­ç»ƒçš„ï¼Œå¯ä»¥è®­ç»ƒå…¶å‚æ•°ä»¥å®ç°æ›´å¥½çš„å¯¹é½ï¼›å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤",
      "paper_url": "https://ojs.aaai.org/index.php/AAAI/article/view/25614",
      "project_url": "",
      "conference": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "title_translation": "[AI generated] **ä¸­æ–‡æ ‡é¢˜ï¼š** TOTï¼šé¢å‘å¤šæ¨¡æ€ä»‡æ¨æ£€æµ‹çš„æ‹“æ‰‘æ„ŸçŸ¥æœ€ä¼˜ä¼ è¾“æ–¹æ³•",
      "analogy_summary": "å¼ºåŒ–æ¶æ„Memeçš„å›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œä½¿ç”¨OTæ–¹æ³•å»ºç«‹ç‰¹å¾å‘é‡é—´çš„å¯è§£é‡Šè”ç³»",
      "pipeline_image": "figures/TOT.png",
      "abstract": "Multimodal hate detection, which aims to identify the harmful content online such as memes, is crucial for building a wholesome internet environment. Previous work has made enlightening exploration in detecting explicit hate remarks. However, most of their approaches neglect the analysis of implicit harm, which is particularly challenging as explicit text markers and demographic visual cues are often twisted or missing. The leveraged cross-modal attention mechanisms also suffer from the distributional modality gap and lack logical interpretability. To address these \nsemantic gap issues, we propose TOT: a topology-aware optimal transport framework to decipher the implicit harm in memes scenario, which formulates the cross-modal aligning problem as solutions for optimal transportation plans. Specifically, we leverage an optimal transport kernel method to capture complementary information from multiple modalities. The kernel embedding provides a non-linear transformation ability to reproduce a kernel Hilbert space (RKHS), which reflects significance for eliminating the distributional modality gap. Moreover, we perceive the topology information based on aligned representations to conduct bipartite graph path reasoning. The newly achieved state-of-the-art performance on two publicly available benchmark datasets, together with  further visual analysis, demonstrate the superiority of TOT in capturing implicit cross-modal alignment.",
      "contributor": "",
      "notes": "æœ€ä¼˜ä¼ è¾“OTè´Ÿè´£å›ç­”â€œå›¾ç‰‡çš„å“ªä¸ªéƒ¨åˆ†å’Œæ–‡æœ¬çš„å“ªä¸ªè¯ç›¸å…³ï¼Ÿâ€ï¼ˆå®ç°ç»Ÿä¸€ä¸”å¯¹é½çš„è¡¨ç¤ºï¼Œä»è€Œå»ºç«‹è·¨æ¨¡æ€çš„æ˜¾å¼è”ç³»ï¼ŒOTæ–¹æ³•æ˜¯å¯è§£é‡Šçš„ï¼‰ã€‚ã€å³å°†CLIPç”Ÿæˆçš„ç‰¹å¾çŸ©é˜µçº§åˆ«çš„å¯¹é½ï¼Œç»†åŒ–ä¸ºç‰¹å¾å‘é‡é—´çš„å¯¹é½ï¼Œä¸¤ä¸ªç‰¹å¾çŸ©é˜µä¼šæ›´ç›¸åƒã€‚è¿™ç§æ˜¾å¼å¯¹é½èƒ½åŠ›æœ¬è´¨ä¸Šæ¥æºäºCLIPå®ç°çš„éšå¯¹é½ã€‘ï¼›æ‹“æ‰‘å»ºæ¨¡è´Ÿè´£å›ç­”â€œè¿™äº›ç›¸å…³çš„éƒ¨åˆ†ç»„åˆåœ¨ä¸€èµ·ï¼Œè¡¨è¾¾äº†ä»€ä¹ˆæ›´æ·±å±‚çš„å«ä¹‰ï¼Ÿâ€ï¼ˆæ•æ‰æ–‡æœ¬ï¼ˆå›¾ç‰‡ï¼‰ä¸­äº’ç›¸æœ‰è”ç³»çš„tokenï¼ˆpatchï¼‰ï¼Œè¿›è¡Œæ¨¡æ€å†…çš„æ·±åº¦æ¨ç†ï¼‰ã€‚ã€è¿™ç§ç±»ä¼¼GNNçš„æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯æ›´æœ‰å±‚æ¬¡æ€§çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¤©ç„¶é€‚ç”¨äºå¤„ç†å…³ç³»å‹æ•°æ®ï¼ˆå›¾ç»“æ„ï¼‰ã€‘ï¼›æœ¬è´¨ä¸Šæ˜¯å°†CLIPå»ºç«‹çš„éšå¼å¯¹é½ç»†ç²’åŒ–ä¸ºå‘é‡å±‚çº§çš„æ˜¾å¼å¯¹é½ï¼Œè¿›è€Œå¾—ä»¥ä½¿ç”¨å›¾æ¨ç†è¿›ä¸€æ­¥å­¦ä¹ å†…éƒ¨è”ç³»",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1109/TMM.2025.3581795",
      "title": "Flexible optimal transport with contrastive graphical modeling for multimodal hate detection",
      "authors": "Linhao Zhangï¼ŒLi Jinï¼ŒXiaoyu Li,Xian Sun,Senior Member,IEEE,Xin Wang,Zequn Zhang,Jian Liuï¼ŒZhicong Luï¼ŒGraduate Student Member,IEEE,and Guangluan Xu",
      "date": "2025",
      "category": "Hate Speech Analysis",
      "summary_motivation": "ç¤¾åª’ä¸­éšå«ä»‡æ¨å†…å®¹æ£€æµ‹å›°éš¾ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥å®ç°è·¨æ¨¡æ€éšå¼å¯¹é½ã€‚",
      "summary_innovation": "ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOTæ˜¯æ”¹è¿›",
      "summary_method": "ç›¸å¯¹äºåŒå›¢é˜Ÿçš„TOT:1.OTçš„ç›®æ ‡åŸŸä¸å†æ˜¯å¦ä¸€æ¨¡æ€çš„ç‰¹å¾ï¼Œè€Œæ˜¯å¯å­¦ä¹ çš„ç»Ÿä¸€åµŒå…¥ï¼ˆOTå¼•å…¥å¯å­¦ä¹ çš„å‚æ•°ï¼Œå®ƒä»¬æ˜¯ä¸¤ä¸ªæ¨¡æ€å„è‡ªå¯¹åº”çš„ç›®æ ‡ç‰¹å¾çŸ©é˜µ $T_v$ å’Œ $T_t$ï¼‰ï¼›2.å¼•å…¥äº†å›¾å¯¹æ¯”å­¦ä¹ æŸå¤±ï¼Œæ˜¾å¼çº¦æŸä¸€è‡´æ€§ï¼ˆæ¯”è¾ƒä¸¤ä¸ªå›¾çš„ç›¸ä¼¼ç¨‹åº¦ä½œä¸ºä¸€ä¸ªæŸå¤±ï¼Œä¹‹åæ‰è¿›è¡Œç±»GNNèšåˆï¼ˆåŠ¨æ€æ‹“æ‰‘æ¨ç†ï¼‰ï¼‰",
      "summary_conclusion": "åœ¨Harm-Cã€Harm-Pã€MET-Memeä¸‰ä¸ªæ•°æ®é›†ä¸Šå–å¾—SOTAï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡ä¸F1",
      "summary_limitation": "å¯¹äºå¹½é»˜ç­‰ç±»ä¼¼éšå¼è¡¨è¾¾å®¹æ˜“è¯¯åˆ¤",
      "paper_url": "https://ieeexplore.ieee.org/abstract/document/11045556",
      "project_url": "",
      "conference": "IEEE Transactions on Multimedia",
      "title_translation": "[AI generated] **ä¸­æ–‡æ ‡é¢˜ï¼š** åŸºäºå¯¹æ¯”å›¾å»ºæ¨¡ä¸çµæ´»æœ€ä¼˜ä¼ è¾“çš„å¤šæ¨¡æ€ä»‡æ¨å†…å®¹æ£€æµ‹\n\n**è¯´æ˜ï¼š**  \næ­¤ç¿»è¯‘åœ¨å‡†ç¡®ä¼ è¾¾åŸæ–‡æŠ€æœ¯æ ¸å¿ƒï¼ˆFlexible Optimal Transportã€contrastive graphical modelingï¼‰çš„åŒæ—¶ï¼Œå…¼é¡¾äº†å­¦æœ¯è¡¨è¾¾çš„ç®€æ´æ€§ä¸ä¸“ä¸šæ€§ã€‚é‡‡ç”¨â€œçµæ´»æœ€ä¼˜ä¼ è¾“â€ä»¥çªå‡ºæ–¹æ³•å¯¹éæ˜¾å¼è·¨æ¨¡æ€å…³è”çš„é€‚åº”æ€§ï¼Œå¹¶é€šè¿‡â€œå¯¹æ¯”å›¾å»ºæ¨¡â€æ˜ç¡®å…¶ç»“æ„åŒ–è¡¨å¾ä¼˜åŒ–æœºåˆ¶ï¼Œæ•´ä½“ç¬¦åˆè®¡ç®—æœºè§†è§‰ä¸è‡ªç„¶è¯­è¨€å¤„ç†äº¤å‰é¢†åŸŸçš„æœ¯è¯­è§„èŒƒã€‚",
      "analogy_summary": "[AI generated] This method bridges multimodal gaps like a flexible translator, aligning implicit hateful memes through optimal transport and contrastive graphs. [ç¿»è¯‘]è¯¥æ–¹æ³•é€šè¿‡æœ€ä¼˜ä¼ è¾“å’Œå›¾å¯¹æ¯”å­¦ä¹ ï¼Œåƒçµæ´»çš„ç¿»è¯‘å®˜ä¸€æ ·å¼¥åˆæ¨¡æ€é¸¿æ²Ÿï¼Œå¯¹é½éšå«ä»‡æ¨è¡¨æƒ…åŒ…ã€‚",
      "pipeline_image": "figures/FLOT1.png;figures/FLOT.png",
      "abstract": "Multimodal hate detection plays a crucial role in maintaining harmonious online environments by identifying harmful content, such as hateful memes. Although previous research has made significant progress in detecting explicit hate speech, there remains a critical gap in analyzing implicit hate, which is particularly challenging due to the absence of explicit harmful text claims or demographic visual cues. Despite the promising results based on cross-modal attention, previous methods may suffer from the distributional modality gap caused by the non-literal associations between multimodal elements, which lacks apparent alignment in implicit hateful contents. In this work, we propose a novel framework: Flexible Optimal Transport (FLOT) to capture the non-literal cross-modal alignment for multimodal hate in the context of memes. FLOT formulates the problem of cross-modal alignment as finding optimal transportation plans, which leverages a kernel method to capture complementary information from multiple modalities. The kernel embeddings reproduce a kernel Hilbert space (RKHS) to serve as a non-linear transformation of alignment, which effectively reduces the distributional modality gap with more interpretability. Moreover, we established topological structures with contrastive modeling for the aligned representations, which are optimized to achieve comprehensive alignment between different modalities, and facilitate local reasoning based on multimodal elements. Experimental results have demonstrated that our FLOT achieved state-of-the-art performance on three publicly available benchmark datasets. Furthermore, extensive qualitative analysis confirms the superior ability of FLOT in capturing implicit cross-modal alignment.",
      "contributor": "",
      "notes": "",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.18653/v1/2023.emnlp-main.420",
      "title": "Event causality extraction via implicit cause-effect interactions",
      "authors": "",
      "date": "2023",
      "category": "Event Extraction",
      "summary_motivation": "ç°æœ‰ECEï¼ˆäº‹ä»¶å› æœå…³ç³»æŠ½å–ï¼‰æ–¹å¼æ²¡æœ‰å……åˆ†åˆ©ç”¨åŸå› äº‹ä»¶å’Œç»“æœäº‹ä»¶ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™æœ¬å¯ä»¥ä¸ºå› æœå…³ç³»æ¨ç†æä¾›å…³é”®çº¿ç´¢",
      "summary_innovation": "è®ºæ–‡è§£è€¦ECEçš„ä¸¤ä¸ªä»»åŠ¡ï¼ˆè®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰ï¼Œå¹¶ä½¿ç”¨OTè¿›è¡Œæ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„ç»†ç²’åº¦å¯¹é½ï¼Œå¢å¼ºäº†å› æœäº‹ä»¶ä¹‹é—´çš„éšå¼è”ç³»",
      "summary_method": "åŸºäºæ¨¡æ¿çš„æ¡ä»¶ç”Ÿæˆï¼ˆè¾“å…¥åŸºäºæ¨¡æ¿é™„æœ‰ç‰¹å®šç‰¹æƒä¿¡æ¯çš„promptï¼Œä½¿é¢„è®­ç»ƒæ¨¡å‹BARTï¼ˆåŸºäºtransformerï¼‰è¾“å‡ºåŸºäºæ¨¡æ¿çš„ç»“æ„åŒ–çš„æ–‡æœ¬ï¼Œç”¨äºåç»­å¾®è°ƒï¼‰->æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦ï¼ˆå¾®è°ƒäº†ä¸¤ä¸ªæ•™å¸ˆæ¨¡å‹è´Ÿè´£ä¸åŒä»»åŠ¡ï¼šäº‹ä»¶è®ºå…ƒæŠ½å–ã€ç»“æœäº‹ä»¶é¢„æµ‹ï¼‰->å› æœæœ€ä¼˜ä¼ è¾“CEOTï¼ˆç›¸å…³æŸå¤±å¹¶å…¥è’¸é¦æŸå¤±ï¼Œå‚ä¸è’¸é¦è®­ç»ƒï¼Œå­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹ç»†ç²’åº¦å¯¹é½ï¼‰",
      "summary_conclusion": "ECEä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒECE-CCKSæ•°æ®é›†ä¸Šæ¯”æ­¤å‰æœ€ä¼˜æ–¹æ³•F1å€¼æé«˜äº†8.39%",
      "summary_limitation": "å¤šæ•™å¸ˆè’¸é¦æœºåˆ¶å’Œå¤æ‚çš„OTè®¡ç®—æ˜¾è‘—å¢åŠ äº†æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„æˆæœ¬",
      "paper_url": "https://aclanthology.org/2023.emnlp-main.420",
      "project_url": "",
      "conference": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
      "title_translation": "[AI generated] ä¸­æ–‡æ ‡é¢˜ï¼šåŸºäºéšå¼å› æœäº¤äº’çš„äº‹ä»¶å› æœå…³ç³»æŠ½å–\n\nï¼ˆè¯¥ç¿»è¯‘å‡†ç¡®ä¼ è¾¾äº†åŸæ ‡é¢˜â€œEvent causality extraction via implicit cause-effect interactionsâ€çš„æ ¸å¿ƒå«ä¹‰ï¼Œå³é€šè¿‡æ•æ‰åŸå› ä¸ç»“æœäº‹ä»¶ä¹‹é—´éšæ€§çš„ç›¸äº’ä½œç”¨æ¥å®ç°å› æœå…³ç³»æŠ½å–ã€‚â€œéšå¼å› æœäº¤äº’â€çš„è¡¨è¿°ç¬¦åˆè®¡ç®—æœºç§‘å­¦ä¸è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„å­¦æœ¯ç”¨è¯­ä¹ æƒ¯ï¼Œä¸”ä¸æ‘˜è¦ä¸­â€œImplicit Cause-Effect interaction (ICE) frameworkâ€çš„å‘½åç›´æ¥å¯¹åº”ï¼Œä¿æŒäº†æœ¯è¯­ä¸€è‡´æ€§ã€‚ï¼‰",
      "analogy_summary": "é€šè¿‡OTå¼ºåˆ¶å­¦ç”Ÿæ¨¡å‹ä¸æ•™å¸ˆæ¨¡å‹å¯¹é½",
      "pipeline_image": "figures/ICE.png",
      "abstract": "Event Causality Extraction (ECE) aims to extract the cause-effect event pairs from the given  text, which requires the model to possess a  strong reasoning ability to capture event causalities. However, existing works have not adequately exploited the interactions between the  cause and effect event that could provide crucial clues for causality reasoning. To this end,  we propose an Implicit Cause-Effect interaction  (ICE) framework, which formulates ECE as  a template-based conditional generation problem. The proposed method captures the implicit intra- and inter-event interactions by incorporating the privileged information (ground  truth event types and arguments) for reasoning, and a knowledge distillation mechanism  is introduced to alleviate the unavailability of  privileged information in the test stage. Furthermore, to facilitate knowledge transfer from  teacher to student, we design an event-level  alignment strategy named Cause-Effect Optimal Transport (CEOT) to strengthen the semantic interactions of cause-effect event types and  arguments. Experimental results indicate that  ICE achieves state-of-the-art performance on  the ECE-CCKS dataset.",
      "contributor": "",
      "notes": "â”è¿™ä¸ªæ–¹æ³•ä¸ºä»€ä¹ˆå¯ä»¥è§£å†³é—®é¢˜ï¼Ÿ\n    æ ¸å¿ƒæ–¹æ³•æ˜¯ä½¿ç”¨ä¼˜ç§€çš„ä¸“å®¶æ¨¡å‹å¯¹å°æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç»“åˆäº†5ä¸ªå°æŸå¤±å‡½æ•°ï¼ˆä¸¤ä¸ªæ¥æºäºOTï¼‰ï¼Œä»¥å°½å¯èƒ½ä¿è¯çŸ¥è¯†è¿ç§»æ•ˆæœ\n\nâ”æœ‰ä»€ä¹ˆå€¼å¾—æ³¨æ„çš„ç»†èŠ‚å—ï¼Ÿ\n    ğŸ“è®ºæ–‡ä¸ºä»€ä¹ˆé€‰æ‹©è®­ç»ƒä¸¤ä¸ªæ‰¿æ‹…ä¸åŒä»»åŠ¡çš„æ•™å¸ˆæ¨¡å‹ï¼Œä¸€èµ·è’¸é¦å‡ºç›®æ ‡æ¨¡å‹çš„æ–¹æ³•\n        è¿™å‡ ä¹æ˜¯è¿›è¡Œå¾®è°ƒç‰¹åŒ–ç”¨äºè¯¥ä¸‹æ¸¸ä»»åŠ¡çš„å¿…ç„¶é€‰æ‹©\n        å› ä¸ºéœ€è¦è®­ç»ƒä¸¤ä¸ªèƒ½åŠ›ï¼ˆå­ä»»åŠ¡ï¼‰ï¼šæ–‡æœ¬è®ºå…ƒæŠ½å–èƒ½åŠ›ï¼ˆäº‹ä»¶å†…äº¤äº’ï¼‰å’Œäº‹ä»¶ç»“æœè”ç³»èƒ½åŠ›ï¼ˆäº‹ä»¶é—´ï¼‰\n        ä¸¤ä¸ªå­ä»»åŠ¡éœ€è¦åˆ†åˆ«è°ƒæ•´æ•°æ®é›†çš„è¾“å…¥ï¼Œä¸ºä»–ä»¬åˆ†é…ä¸åŒçš„ç‰¹æƒä¿¡æ¯ï¼Œä»è€Œé¿å…æ··æ·†å’Œå‡ºç°â€œä½œå¼Šâ€ï¼ˆçœ‹åˆ°è¿™ä¸ªå­ä»»åŠ¡ä¸åº”çœ‹åˆ°çš„ç‰¹æƒä¿¡æ¯ï¼‰",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/aaai.v38i8.28787",
      "title": "CAMEL: Capturing metaphorical alignment with context disentangling for multimodal emotion recognition",
      "authors": "Linhao Zhang,Li Jin*,Guangluan Xu,Xiaoyu Li,Cai Xu,Kaiwen Wei,Nayu Liu,Haonan Liu",
      "date": "2024-03-24",
      "category": "Sentiment Analysis",
      "summary_motivation": "ä¸ºäº†è§£å†³å¤šæ¨¡æ€å†…å®¹ä¸­å› éšå–»å¯¹é½å¯¼è‡´**æƒ…æ„Ÿè¯¯åˆ¤**çš„é—®é¢˜ï¼šä¹‹å‰çš„æ–¹æ³•æœ¬è´¨ä¸Šæ— æ³•ç†è§£éšå–»,ä¸“æ³¨äºç›´æ¥çš„è¯­ä¹‰å¯¹é½ï¼Œæ— æ³•æ•æ‰å¦‚æ–‡å­—â€œçœ¼æ³ªâ€ä¸å›¾ç‰‡â€œæ²³æµâ€çš„è¿™ç§éšå¼è”ç³»",
      "summary_innovation": "å°†å¤šæ¨¡æ€é—´éšå«è”ç³»çš„å¯¹é½æ€æƒ³åº”ç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸ",
      "summary_method": "ä½¿ç”¨äº†åŸºäºæ¡ä»¶ç”Ÿæˆä¸è§£è€¦ä¸Šä¸‹æ–‡é€‚åº”çš„CAMELæ¡†æ¶:éšå–»å¯¹é½å»ºæ¨¡ï¼ˆæ¡ä»¶ç”Ÿæˆï¼‰(å¼ºåˆ¶æ¨¡å‹æŒ‰ç…§æ¨¡ç‰ˆè¾“å‡ºï¼ˆCMTå’ŒSPVä¸¤ç§æŠ€æœ¯ï¼‰ï¼›ä½¿ç”¨å›¾ç‰‡ã€æ ‡é¢˜ã€æ–‡æœ¬çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿ç”¨ä¸€ä¸ª[CLS] tokenèšåˆå…¨å±€ä¿¡æ¯ï¼‰->ä¸Šä¸‹æ–‡è¯­ä¹‰é€‚åº”ï¼ˆç‰¹å¾èåˆï¼‰ï¼ˆä½¿ç”¨ä¸¤ä¸ªå¼‚æ„æ¨¡å‹ï¼Œåˆ†åˆ«è¾“å…¥å­—é¢ç‰¹å¾ï¼ˆCAMEL-Cï¼ŒCMTï¼‰å’Œéšå–»ç‰¹å¾ï¼ˆCAMEL-Sï¼ŒSPVï¼‰ç”Ÿæˆä¸¤ä¸ªå‘é‡çŸ©é˜µï¼Œé€šè¿‡éšå–»æŸ¥å­—é¢å®ç°å¤šå¤´æ³¨æ„åŠ›ï¼‰->è§£è€¦å¯¹æ¯”åŒ¹é…ï¼ˆä¸Šä¸‹æ–‡æ­£åˆ™åŒ–ï¼‰ï¼ˆç¡®ä¿ä¸åç¦»è¯­å¢ƒã€‚é‡‡ç”¨è§£è€¦å­¦ä¹ æ€æƒ³ï¼Œéšå–»ç‰¹å¾ä¸­åˆ†ç¦»å‡ºä»£è¡¨â€œä¸»å¯¼ä¸Šä¸‹æ–‡ç±»åˆ«â€çš„ç¦»æ•£åˆ†å¸ƒï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œä½¿å­—é¢ç‰¹å¾æ¨å‡ºçš„åˆ†å¸ƒä¸ä¹‹å¯¹é½ï¼‰",
      "summary_conclusion": "è¾¾æˆäº†å¯¹éšå«æƒ…æ„Ÿæ›´ç²¾å‡†ã€é²æ£’çš„è¯†åˆ«æ•ˆæœ",
      "summary_limitation": "æ•´ä¸ªæ–¹æ³•æ¡†æ¶å¤æ‚ï¼Œæ¨¡å‹æ‰€éœ€çš„æ‰€æœ‰èƒ½åŠ›ï¼šæ‰¾å­—é¢ç‰¹å¾ã€æ‰¾éšå–»ç‰¹å¾ã€ä¸¤è€…å¯¹é½ã€æ ¹æ®èåˆç‰¹å¾ç”Ÿæˆæƒ…æ„Ÿåˆ†æï¼Œéƒ½æ˜¯ä¸€æ¬¡è®­ç»ƒå®Œæˆçš„ï¼Œæ˜¯å¦éš¾ä»¥æ”¶æ•›ï¼ˆè™½ç„¶è®ºæ–‡ä½¿ç”¨äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼‰ï¼Œæ˜¯å¦èƒ½å¤Ÿåœ¨è®­ç»ƒå±‚é¢è¿›è¡Œä¸€å®šçš„è§£è€¦ï¼Ÿåˆ†åˆ«è®­ç»ƒå„èƒ½åŠ›",
      "paper_url": "https://ojs.aaai.org/index.php/AAAI/article/view/28787",
      "project_url": "",
      "conference": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "title_translation": "[AI generated] **ä¸­æ–‡æ ‡é¢˜ï¼š** CAMELï¼šåŸºäºä¸Šä¸‹æ–‡è§£è€¦çš„éšå–»å¯¹é½æ•æ‰ç”¨äºå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«",
      "analogy_summary": "[AI generated] CAMEL disentangles metaphorical alignment like a prism separating light, then adaptively fuses context for emotion recognition. [ç¿»è¯‘]CAMELåƒæ£±é•œåˆ†ç¦»å…‰çº¿èˆ¬è§£è€¦éšå–»å¯¹é½ï¼Œå†è‡ªé€‚åº”èåˆä¸Šä¸‹æ–‡è¿›è¡Œæƒ…æ„Ÿè¯†åˆ«ã€‚",
      "pipeline_image": "figures/CAMEL1.png;figures/CAMEL.png",
      "abstract": "Understanding the emotional polarity of multimodal content with metaphorical characteristics, such as memes, poses a significant challenge in Multimodal Emotion Recognition (MER). Previous MER researches have overlooked the phenomenon of metaphorical alignment in multimedia content, which involves non-literal associations between concepts to convey implicit emotional tones.  Metaphor-agnostic MER methods may be misinformed by the isolated unimodal emotions, which are distinct from the real emotions blended in multimodal metaphors. Moreover, contextual semantics can further affect the emotions associated with similar metaphors, leading to the challenge of maintaining contextual compatibility. To address the issue of metaphorical alignment in MER, we propose to leverage a conditional generative approach for capturing metaphorical analogies. Our approach formulates schematic prompts and corresponding references based on theoretical foundations, which allows the model to better grasp metaphorical nuances. In order to maintain contextual sensitivity, we incorporate a disentangled contrastive matching mechanism, which undergoes curricular adjustment to regulate its intensity during the learning process. The automatic and human evaluation experiments on two benchmarks prove that, our model provides considerable and stable improvements in recognizing multimodal emotion with metaphor attributes.",
      "contributor": "",
      "notes": "é¦–å…ˆé€šè¿‡å¤šå¤´è·¨åŸŸæ³¨æ„åŠ›æœºåˆ¶å®ç°åˆæ­¥çš„å¯¹é½ï¼Œç„¶åè®©å­—é¢ç‰¹å¾çš„åˆ†å¸ƒä¸éšå–»ç‰¹å¾çš„åˆ†å¸ƒå¯¹é½ï¼Œè¿›ä¸€æ­¥å¼ºåŒ–å¯¹é½ï¼›",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.18653/v1/2024.acl-long.291",
      "title": "Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning",
      "authors": "Jingbiao Mei,Jinghong Chen,Weizhe Lin,Bill Byrne,Maarcus Tomalin",
      "date": "2024",
      "category": "Hate Speech Analysis",
      "summary_motivation": "ç°æœ‰CLIPç­‰æ¨¡å‹å¯¹ä»‡æ¨è¡¨æƒ…åŒ…çš„å›¾åƒ-æ–‡æœ¬çš„ç»†å¾®å·®å¼‚ï¼ˆå¦‚â€œæ··æ·†æ ·æœ¬â€ï¼‰æ•æ„Ÿåº¦ä¸è¶³ï¼Œå¯¼è‡´çš„è¯¯åˆ¤ã€‚",
      "summary_innovation": "å¯¹äºæ˜“æ··æ·†çš„éš¾ä¾‹ï¼ˆä¸å½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜ä½†æ ‡ç­¾ç›¸åçš„ï¼‰ï¼Œä½¿ç”¨**åŠ¨æ€æ£€ç´¢**æ–¹å¼å•æ‹‰å‡ºæ¥ï¼Œä¸**ä¼ªé»„é‡‘æ­£æ ·æœ¬**ï¼ˆå’Œå½“å‰æ ·æœ¬ç›¸ä¼¼åº¦æœ€é«˜çš„æ ‡ç­¾ç›¸åŒçš„ï¼‰æˆå¯¹ï¼Œä½œä¸ºæ­£åä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚ä»è€Œè§£å†³é—®é¢˜",
      "summary_method": "1. ä½¿ç”¨å†»ç»“çš„CLIPç¼–ç å™¨æå–å›¾æ–‡ç‰¹å¾ï¼›\n2. é€šè¿‡Faissæ£€ç´¢åŠ¨æ€è·å–åŒç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆä¼ªé»„é‡‘æ­£æ ·æœ¬ï¼‰ä¸å¼‚ç±»ç›¸ä¼¼æ ·æœ¬ï¼ˆå›°éš¾è´Ÿæ ·æœ¬ï¼‰ä½œä¸ºæ­£åä¾‹ï¼›\n3. ç»“åˆæ­£åä¾‹å¯¹æ¯”æŸå¤±ï¼ˆRGCLLï¼‰ä¸äº¤å‰ç†µæŸå¤±è®­ç»ƒMLPï¼›\n4. å®ç°é€»è¾‘åˆ†ç±»ä¸KNNæ£€ç´¢åˆ†ç±»ä¸¤ç§åˆ†ç±»å™¨ï¼Œåè€…é€šè¿‡ç›¸ä¼¼åº¦åŠ æƒæŠ•ç¥¨è¿›è¡Œé¢„æµ‹ã€‚",
      "summary_conclusion": "åœ¨HatefulMemesæ•°æ®é›†ä¸Šè¾¾åˆ° AUROC 87.0%ï¼ˆSOTAï¼‰ï¼Œè¶…è¶ŠFlamingo-80Bç­‰å¤§å‹å¤šæ¨¡æ€æ¨¡å‹",
      "summary_limitation": "ä»‡æ¨è¨€è®ºçš„å®šä¹‰å…·æœ‰äº‰è®®æ€§ä¸æ–‡åŒ–ä¾èµ–æ€§ï¼›ç³»ç»Ÿå¯¹ ç»†å¾®é¢éƒ¨è¡¨æƒ… è¯†åˆ«èƒ½åŠ›æœ‰é™ï¼›ä¾èµ–æ•°æ®æ ‡æ³¨è´¨é‡ï¼Œå¯èƒ½å­˜åœ¨æ ‡æ³¨åå·®ã€‚",
      "paper_url": "https://aclanthology.org/2024.acl-long.291",
      "project_url": "",
      "conference": "ACL 2024",
      "title_translation": "[AI generated] **ä¸­æ–‡æ ‡é¢˜ï¼š** é€šè¿‡æ£€ç´¢å¼•å¯¼çš„å¯¹æ¯”å­¦ä¹ æå‡ä»‡æ¨è¡¨æƒ…åŒ…æ£€æµ‹æ€§èƒ½\n\n**è¯´æ˜ï¼š** è¯¥ç¿»è¯‘å‡†ç¡®ä¼ è¾¾äº†åŸæ ‡é¢˜çš„æŠ€æœ¯æ ¸å¿ƒï¼ˆæ£€ç´¢å¼•å¯¼çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼‰ä¸ç ”ç©¶ç›®æ ‡ï¼ˆæå‡ä»‡æ¨è¡¨æƒ…åŒ…æ£€æµ‹ï¼‰ï¼Œç¬¦åˆè®¡ç®—æœºç§‘å­¦é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯å¤šæ¨¡æ€å†…å®¹åˆ†æä¸ä»‡æ¨è¨€è®ºæ£€æµ‹æ–¹å‘çš„å­¦æœ¯è¡¨è¾¾è§„èŒƒï¼Œé£æ ¼ä¸“ä¸šã€ç®€æ´ã€‚",
      "analogy_summary": "ä¸“é¢˜å¼ºåŒ–ï¼šéš¾å­¦æ ·æœ¬å•æ‹‰å‡ºæ¥ä¸æ­£ä¾‹è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œä»è€Œæé«˜è¯†åˆ«èƒ½åŠ›",
      "pipeline_image": "figures/RGCL.png",
      "abstract": "Hateful memes have emerged as a significant concern on the Internet. Detecting hateful memes requires the system to jointly understand the visual and textual modalities. Our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in memes that are vital for correct hatefulness classification. We propose constructing a hatefulness-aware embedding space through retrieval-guided contrastive training. Our approach achieves state-of-the-art performance on the HatefulMemes dataset with an AUROC of 87.0, outperforming much larger fine-tuned large multimodal models. We demonstrate a retrieval-based hateful memes detection system, which is capable of identifying hatefulness based on data unseen in training. This allows developers to update the hateful memes detection system by simply adding new examples without retraining â€” a desirable feature for real services in the constantly evolving landscape of hateful memes on the Internet.",
      "contributor": "",
      "notes": "",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/aaai.v38i1.27788",
      "title": "GAMC: An Unsupervised Method for Fake News Detection Using Graph Autoencoder with Masking",
      "authors": "Shu Yin,Peican Zhu,Lianwei Wu,Chao Gao,Zhen Wang",
      "date": "2024-03-24",
      "category": "Misinformation Analysis",
      "summary_motivation": "ç°æœ‰æ–¹æ³•å¤šä¾èµ–æ–°é—»å†…å®¹æˆ–éœ€å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨ä¼ æ’­ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚",
      "summary_innovation": "é¦–ä¸ªç»“åˆå›¾è‡ªç¼–ç å™¨ã€æ©ç ä¸å¯¹æ¯”å­¦ä¹ çš„æ— ç›‘ç£å‡æ–°é—»æ£€æµ‹æ–¹æ³•ï¼ŒåŒæ—¶åˆ©ç”¨ä¼ æ’­ç»“æ„ä¸å†…å®¹ä¿¡æ¯ï¼Œæ— éœ€æ ‡æ³¨æ•°æ®",
      "summary_method": "1. å°†æ–°é—»ä¼ æ’­å»ºæ¨¡ä¸ºå›¾ï¼ˆæ–°é—»èŠ‚ç‚¹å’Œç”¨æˆ·èŠ‚ç‚¹ï¼Œè¾¹è¡¨ç¤ºè½¬å‘å…³ç³»ï¼ŒèŠ‚ç‚¹ç‰¹å¾æ¥è‡ªæ–°é—»å†…å®¹å’Œç”¨æˆ·å†å²è´´æ–‡ï¼‰ï¼›\n2. æ•°æ®å¢å¼ºï¼ˆèŠ‚ç‚¹ç‰¹å¾æ©ç +è¾¹ä¸¢å¼ƒï¼‰ï¼ˆéšæœºé€‰å–èŠ‚ç‚¹å°†å…¶ç‰¹å¾æ›¿æ¢ä¸ºæ©ç æ ‡è®°ï¼Œéšæœºåˆ é™¤éƒ¨åˆ†è¾¹ï¼‰æ„é€ è‡ªç›‘ç£ç‰¹æ€§ï¼›\n3. å›¾ç¼–ç å™¨ï¼ˆGINï¼‰ç”Ÿæˆæ½œåœ¨è¡¨ç¤ºï¼›\n4. å›¾è§£ç å™¨é‡å»ºç‰¹å¾ï¼›\n5. æŸå¤±å‡½æ•°ç»„æˆï¼ˆ**é‡å»ºæŸå¤±**ï¼ˆä½¿é‡å»ºç‰¹å¾æ¥è¿‘åŸå§‹ç‰¹å¾ï¼‰+**å¯¹æ¯”æŸå¤±**ï¼ˆæ¥è‡ªåŒä¸€ä¸ªåŸå§‹å›¾çš„ä¸¤ä¸ªå¢å¼ºå›¾é‡å»ºååº”å°½é‡ç›¸ä¼¼ï¼‰ï¼‰è®­ç»ƒã€‚",
      "summary_conclusion": "åœ¨ FakeNewsNet æ•°æ®é›†ä¸Šï¼ŒGAMC åœ¨æ— ç›‘ç£æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼ˆå¦‚ GossipCop å‡†ç¡®ç‡ 0.946ï¼‰ï¼Œç”šè‡³æ¥è¿‘æˆ–è¶…è¶Šéƒ¨åˆ†ç›‘ç£æ–¹æ³•",
      "summary_limitation": "éœ€è¦æ–°é—»å…·æœ‰ä¸€å®šçš„ä¼ æ’­é‡æ‰èƒ½å»ºæ¨¡ä¸ºå›¾ï¼›æ—©æœŸä¼ æ’­é˜¶æ®µæ£€æµ‹èƒ½åŠ›å—é™",
      "paper_url": "https://ojs.aaai.org/index.php/AAAI/article/view/27788",
      "project_url": "",
      "conference": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "title_translation": "[AI generated] **ä¸­æ–‡æ ‡é¢˜ï¼š** GAMCï¼šä¸€ç§åŸºäºæ©ç å›¾è‡ªç¼–ç å™¨çš„æ— ç›‘ç£å‡æ–°é—»æ£€æµ‹æ–¹æ³•\n\n**è¯´æ˜ï¼š**\n- **GAMC** ä½œä¸ºæ–¹æ³•åç§°ä¿ç•™ä¸è¯‘ï¼Œç¬¦åˆå­¦æœ¯æƒ¯ä¾‹ã€‚\n- **Graph Autoencoder with Masking** è¯‘ä¸ºâ€œåŸºäºæ©ç çš„å›¾è‡ªç¼–ç å™¨â€æˆ–â€œæ©ç å›¾è‡ªç¼–ç å™¨â€ï¼Œå‡†ç¡®ä¼ è¾¾äº†æ ¸å¿ƒæ–¹æ³•ï¼ˆå›¾è‡ªç¼–ç å™¨ï¼‰åŠå…¶å…³é”®æŠ€æœ¯ï¼ˆæ©ç æ“ä½œï¼‰ã€‚\n- **Unsupervised Method for",
      "analogy_summary": "è‡ªç¼–ç å™¨æ–¹æ³•å¤„ç†ç±»ç¤¾äº¤ç½‘ç»œå›¾ç»“æ„",
      "pipeline_image": "figures/GAMC.png",
      "abstract": "With the rise of social media, the spread of fake news has become a significant concern, potentially misleading public perceptions and impacting social stability. Although deep learning methods like CNNs, RNNs, and Transformer-based models like BERT have enhanced fake news detection. However, they primarily focus on content and do not consider social context during news propagation. Graph-based techniques have incorporated the social context but are limited by the need for large labeled datasets. To address these challenges, this paper introduces GAMC, an unsupervised fake news detection technique using the Graph Autoencoder with Masking and Contrastive learning. By leveraging both the context and content of news propagation as self-supervised signals, our method reduces the dependency on labeled datasets. Specifically, GAMC begins by applying data augmentation to the original news propagation graphs. Subsequently, these augmented graphs are encoded using a graph encoder and subsequently reconstructed via a graph decoder. Finally, a composite loss function that encompasses both reconstruction error and contrastive loss is designed. Firstly, it ensures the model can effectively capture the latent features, based on minimizing the discrepancy between reconstructed and original graph representations. Secondly, it aligns the representations of augmented graphs that originate from the same source. Experiments on the real-world dataset validate the effectiveness of our method.",
      "contributor": "",
      "notes": "",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1145/3442442.3452328",
      "title": "How does truth evolve into fake news? An empirical study of fake news evolution",
      "authors": "Mingfei Guoï¼ŒXiuying Chenï¼ŒJuntao Liï¼ŒDongyan Zhaoï¼ŒRui Yan",
      "date": "2021-06-03",
      "category": "Misinformation Analysis",
      "summary_motivation": "è€Œç°æœ‰æ•°æ®é›†å¤šå…³æ³¨é™æ€æ ‡æ³¨ï¼Œç¼ºä¹å¯¹å…¶å‡æ–°é—»æ¼”åŒ–è¿‡ç¨‹çš„ç ”ç©¶",
      "summary_innovation": "ç»™å‡ºäº†å…³æ³¨å‡æ–°é—»æ¼”åŒ–çš„æ•°æ®é›†FNEï¼ŒåŒ…å«â€œçœŸç›¸-è™šå‡æ–°é—»-æ¼”åŒ–è™šå‡æ–°é—»â€ä¸‰å…ƒç»„",
      "summary_method": "1. ä» Snopes.com(ä¸€ä¸ªè¾Ÿè°£ç½‘ç«™) æŠ“å–truthæ–‡ç« ï¼›\n2. é€šè¿‡å…¶å¼•æ–‡æ”¶é›†è™šå‡æ–°é—»ï¼›\n3. åˆ©ç”¨ç½‘é¡µå­˜æ¡£å¹³å°ï¼ˆå¦‚ Archive Todayï¼‰è·å–æ¼”åŒ–åç‰ˆæœ¬ï¼›\n4. åˆ†æè™šå‡ä¿¡æ¯æŠ€æœ¯åˆ†ç±»ï¼ˆæé€ ã€å¦è®¤ã€æ··æ·†ã€æ­ªæ›²å››ç±»ã€æ–‡æœ¬ç›¸ä¼¼åº¦ã€å…³é”®è¯ã€è¯æ€§ã€æƒ…æ„Ÿç­‰å±æ€§ã€‚",
      "summary_conclusion": "æ¼”åŒ–åè™šå‡æ–°é—»ä¸åŸå§‹è™šå‡æ–°é—»ç›¸ä¼¼åº¦æ›´é«˜ï¼Œæƒ…æ„Ÿæ›´å®¢è§‚ç§¯æï¼Œæ›´éš¾ä»¥è¢«ç°æœ‰åˆ†ç±»æ¨¡å‹æ£€æµ‹ï¼›è™šå‡ä¿¡æ¯æŠ€æœ¯ä¸­ä»¥â€œæé€ â€ä¸ºä¸»ï¼›è¯æ€§å’Œå…³é”®è¯åœ¨æ¼”åŒ–ä¸­ä¿æŒç¨³å®šã€‚",
      "summary_limitation": "æ•°æ®æ¥æºä¾èµ–å•ä¸€äº‹å®æ ¸æŸ¥ç½‘ç«™ï¼ˆSnopesï¼‰ï¼Œå¯èƒ½å¼•å…¥åè§ï¼›ä»…å…³æ³¨æ–‡æœ¬æ–°é—»ï¼Œæœªæ¶µç›–å›¾åƒã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ¼”å˜ï¼›",
      "paper_url": "https://dl.acm.org/doi/10.1145/3442442.3452328",
      "project_url": "",
      "conference": "Companion Proceedings of the Web Conference 2021",
      "title_translation": "[AI generated] **ä¸­æ–‡æ ‡é¢˜ï¼š** çœŸç›¸å¦‚ä½•æ¼”å˜ä¸ºè™šå‡æ–°é—»ï¼Ÿä¸€é¡¹å…³äºè™šå‡æ–°é—»æ¼”åŒ–çš„å®è¯ç ”ç©¶",
      "analogy_summary": "ä¸€ä¸ªåŒ…å«[åŸå§‹æ–°é—»ã€å‡æ–°é—»ã€æ¼”åŒ–åçš„å‡æ–°é—»]ä¸‰å…ƒç»„çš„æ•°æ®é›†",
      "pipeline_image": "figures/FNE.png",
      "abstract": "Automatically identifying fake news from the Internet is a challenging problem in deception detection tasks. Online news is modified constantly during its propagation, e.g., malicious users distort the original truth and make up fake news. However, the continuous evolution process would generate unprecedented fake news and cheat the original model. We present the Fake News Evolution (FNE) dataset: a new dataset tracking the fake news evolution process. Our dataset is composed of 950 paired data, each of which consists of articles representing the three significant phases of the evolution process, which are the truth, the fake news, and the evolved fake news. We observe the features during the evolution and they are the disinformation techniques, text similarity, top 10 keywords, classification accuracy, parts of speech, and sentiment properties.",
      "contributor": "",
      "notes": "",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    },
    {
      "doi": "10.1609/aaai.v39i1.32022",
      "title": "Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference",
      "authors": "Mingxin Li,Yuchen Zhang,Haowei Xu,Xianghua Li*,Chao Gao,Zhen Wang",
      "date": "2025-04-11",
      "category": "Misinformation Analysis",
      "summary_motivation": "ç¤¾äº¤å¹³å°å¤šå…ƒåŒ–å¯¼è‡´æ–°é—»ä¼ æ’­å¤æ‚ã€å¤šæ¨¡æ€ï¼Œä¼ ç»Ÿå‡æ–°é—»æ£€æµ‹æ–¹æ³•ä¾èµ–æ˜¾å¼ä¼ æ’­å…³ç³»ï¼ˆå¦‚è½¬å‘ï¼‰ï¼Œåœ¨æŠ–éŸ³ç­‰å¹³å°éš¾ä»¥ç›´æ¥è·å–ï¼Œæ£€æµ‹éš¾åº¦å¤§ã€‚",
      "summary_innovation": "æå‡ºâ€œç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­Latent Network Inferenceâ€ç­–ç•¥ï¼Œæ— éœ€çœŸå®ä¼ æ’­å…³ç³»ï¼Œå³å¯æ„å»ºæ–°é—»é—´çš„æ½œåœ¨è”ç³»",
      "summary_method": "1. ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ï¼šåŸºäºHawkes Processå»ºæ¨¡æ–°é—»å½±å“åŠ›éšæ—¶é—´å˜åŒ–ï¼Œå¾—åˆ°äº‹ä»¶å†…éƒ¨ä¸äº‹ä»¶é—´çš„å½±å“å¼ºåº¦ï¼Œæ¨æ–­å‡ºæ½œåœ¨ä¼ æ’­ç½‘ç»œã€‚\n2. å¼‚è´¨å›¾æ„å»ºï¼šèŠ‚ç‚¹å‡ä¸ºæ–°é—»ï¼Œè¾¹ç±»å‹åŸºäºå„ç§ç›¸åŒæˆ–ç›¸ä¼¼å±æ€§ï¼ˆå¦‚ä½œè€…ã€æ ‡é¢˜ã€æ—¶é—´ç­‰ï¼‰æ„å»ºã€‚ä½¿ç”¨**æ³¨æ„åŠ›æœºåˆ¶**åŠ¨æ€èåˆä¸åŒè¾¹ç±»å‹ï¼Œç”Ÿæˆç»Ÿä¸€çš„å¼‚è´¨å›¾è¡¨ç¤ºï¼ˆæ¯ä¸ªç±»å‹çš„è¾¹çœ‹åšä¸€ä¸ªâ€œå¤´â€ï¼Œåˆ©ç”¨å¤šå¤´æ³¨æ„åŠ›æ–¹æ³•ï¼‰\n3. è‡ªç›‘ç£å¤šæ¨¡æ€å†…å®¹å­¦ä¹ ï¼šæŸå¤±å‡½æ•°ï¼šå•æ¨¡æ€å¢å¼ºï¼ˆå¯¹åŒä¸€æ¨¡æ€è¿›è¡Œæ©ç ä¸é‡æ„ï¼‰ã€è·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼ˆå¯¹é½ä¸åŒæ¨¡æ€ï¼ˆå¦‚æ–‡æœ¬ä¸è§†é¢‘ï¼‰çš„ç‰¹å¾ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ æ‹‰è¿‘æ­£æ ·æœ¬ã€æ¨å¼€è´Ÿæ ·æœ¬ï¼‰\n4. ä¸ªæ€§åŒ–å›¾è¡¨ç¤ºä¸åˆ†ç±»ï¼šä½¿ç”¨å›¾Transformer Encoderèåˆå›¾ç»“æ„ä¸æ¨¡æ€ç‰¹å¾ï¼Œè¿›è¡Œåˆ†ç±»ã€‚",
      "summary_conclusion": "FakeSVå’ŒFVCæ•°æ®é›†ä¸Šå‡†ç¡®ç‡å‡è¶…89%ï¼Œè¾ƒSOTAæå‡0.12%~4.39%ï¼›åœ¨Twitter/å¾®åšä½œä¸ºæ’ä»¶ä¹Ÿæå‡æ˜æ˜¾ï¼ˆæœ€é«˜+10.71% F1ï¼‰",
      "summary_limitation": "ä¾èµ–äº‹ä»¶å®šä¹‰ä¸æ—¶é—´åºåˆ—å‡è®¾ï¼Œå¯¹å®æ—¶æ€§è¦æ±‚é«˜ï¼›è®¡ç®—å¤æ‚åº¦è¾ƒé«˜",
      "paper_url": "https://ojs.aaai.org/index.php/AAAI/article/view/32022",
      "project_url": "",
      "conference": "Proceedings of the AAAI Conference on Artificial Intelligence",
      "title_translation": "[AI generated] **ä¸­æ–‡æ ‡é¢˜ï¼š** åŸºäºç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­çš„å¤æ‚å¼‚è´¨å¤šæ¨¡æ€å‡æ–°é—»å­¦ä¹ \n\n**è¯´æ˜ï¼š** æ­¤ç¿»è¯‘åŠ›æ±‚å‡†ç¡®ã€ä¸“ä¸šï¼Œç¬¦åˆä¸­æ–‡ç§‘æŠ€è®ºæ–‡çš„è¡¨è¾¾ä¹ æƒ¯ï¼š\n1.  **æ ¸å¿ƒæœ¯è¯­å¤„ç†**ï¼š\n    *   \"Complex Heterogeneous Multimodal\" è¯‘ä¸ºâ€œå¤æ‚å¼‚è´¨å¤šæ¨¡æ€â€ï¼Œæ˜¯é¢†åŸŸå†…å¯¹æ•°æ®/ä¿¡æ¯ç‰¹æ€§çš„æ ‡å‡†è¡¨è¿°ã€‚\n    *   \"Social Latent Network Inference\" è¯‘ä¸ºâ€œç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­â€ï¼Œå…¶ä¸­â€œ",
      "analogy_summary": "é€šè¿‡ç¤¾äº¤æ½œåœ¨ç½‘ç»œæ¨æ–­ä¸è‡ªç›‘ç£å¤šæ¨¡æ€å­¦ä¹ æ£€æµ‹å¤æ‚å¼‚è´¨å¤šæ¨¡æ€å‡æ–°é—»çš„GNNæ–¹æ³•",
      "pipeline_image": "figures/HML.png",
      "abstract": "With the diversification of online social platforms, news dissemination has become increasingly complex, heterogeneous, and multimodal, making the fake news detection task more challenging and crucial.\nPrevious works mainly focus on obtaining social relationships of news via retweets, limiting the accurate detection when real cascades are inaccessible. Given the proven assessment of the spreading influence of events, this paper proposes a method called HML (Complex Heterogeneous Multimodal Fake News Detection method via Latent Network Inference). Specifically, an improved social latent network inference strategy is designed to estimate the maximum likelihood of news influences under the same event. Meanwhile, a novel heterogeneous graph is built based on social attributes for multimodal news under different events. Further, to better aggregate the relationships among heterogeneous multimodal features, this paper proposes a self-supervised-based multimodal content learning strategy, to enhance, align, fuse and compare heterogeneous modal contents. Based above, a personalized heterogeneous graph representation learning is designed to classify fake news. Extensive experiments demonstrate that the proposed method outperforms the SOTA in real social media news datasets.",
      "contributor": "",
      "notes": "",
      "show_in_readme": true,
      "status": "",
      "submission_time": "",
      "conflict_marker": false,
      "invalid_fields": "",
      "is_placeholder": false
    }
  ],
  "meta": {
    "generated_at": "2026-01-23 17:05:11"
  }
}