# Awesome Social Media Analysis with LLM Method
> The version supporting Excel processing is available at [excel version](https://github.com/saiteiii/Awesome-Social-media-LLM-based-Analysis)(**no longer maintained**); In this version, the GUI has no administrator mode, and management is achieved by manually modifying an Excel-formatted database containing review prompt information.

> **Contributions**<br>
> If you want to add your own paper or update paper details, please follow the [contributor_manual](./docs/contributor_manual_chs.md)  for the relevant operations. We greatly appreciate your contributions. Alternatively, you can email me  ([Gmail](lixiajie2182712226@gmail.com))with the links to your paper and project, and I will manually add your paper to the list.

### **technical and manual documentation guide**
[contributor_manual](./docs/contributor_manual_chs.md) 
<br>[plugin_manual](./docs/plugin_manual.md)
<br>[PROJECT_README](./docs/PROJECT_README.md)
<br>[maintenance_manual](./docs/maintenance_manual.md)
>[Download the recommended Zotero plugins](https://github.com/sait-crypto/Awesome-Social-media-LLM-based-Analysis/raw/refs/heads/main/tools/One-Click%20Copy%20Metadata.xpi):
<br>Developed specifically for this project, it can work with the GUI interface to quickly fill in paper information.Refer to the technical documentation for details.
<br>(chs: 特地为该项目开发，可配合gui界面快速填写论文信息，详情见技术文档)
><br><br>This plugin can also be used as an alternative:
<br>https://zotero-chinese.com/plugins/#search=Zutilo%20Utility%20for%20Zotero
---
<p align="center">
<img src="assets/taxonomy.png" width = "95%" alt="" align=center />
</p>

### Key Points for Table Usage
- <b>Paper Link</b>: Please click the paper title
- <b>Paper Project Link</b>: Please click the GitHub icon or Project icon above the paper title
- <b>Summary</b> and <b>Notes</b> can be expanded by clicking
>For complete paper information, please refer to the paper_database.xlsx file.
><br>完整论文信息可以查看paper_database.xlsx文件
## Full paper list (44 papers)
### Quick Links

  - [Uncategorized](#-Uncategorized-0-papers) (0 papers)
  - [Base Techniques](#-Base-Techniques-2-papers) (2 papers)
  - [Perception and Classification](#-Perception-and-Classification-24-papers) (24 papers)
    - [Hate Speech Analysis](#Hate-Speech-Analysis-4-papers) (4 papers)
    - [Misinformation Analysis](#Misinformation-Analysis-7-papers) (7 papers)
    - [Controversy Analysis](#Controversy-Analysis-1-papers) (1 papers)
    - [Sentiment Analysis](#Sentiment-Analysis-3-papers) (3 papers)
    - [Sarcasm Detection](#Sarcasm-Detection-0-papers) (0 papers)
    - [Meme Analysis](#Meme-Analysis-2-papers) (2 papers)
    - [Steganography Detection](#Steganography-Detection-0-papers) (0 papers)
    - [User Stance Detection](#User-Stance-Detection-2-papers) (2 papers)
    - [Malicious User Detection](#Malicious-User-Detection-5-papers) (5 papers)
  - [Understanding](#-Understanding-11-papers) (11 papers)
    - [Event Extraction](#Event-Extraction-6-papers) (6 papers)
    - [Topic Modeling](#Topic-Modeling-0-papers) (0 papers)
    - [Social Psychological Phenomena Analysis](#Social-Psychological-Phenomena-Analysis-1-papers) (1 papers)
    - [Social Popularity Prediction](#Social-Popularity-Prediction-0-papers) (0 papers)
    - [User Identity Understanding](#User-Identity-Understanding-2-papers) (2 papers)
    - [User Profiling](#User-Profiling-2-papers) (2 papers)
    - [User Behavior Prediction](#User-Behavior-Prediction-1-papers) (1 papers)
    - [Dynamic Community Analysis](#Dynamic-Community-Analysis-0-papers) (0 papers)
    - [Information Diffusion Analysis](#Information-Diffusion-Analysis-1-papers) (1 papers)
    - [User Participation Prediction](#User-Participation-Prediction-0-papers) (0 papers)
    - [Recommender System](#Recommender-System-0-papers) (0 papers)
  - [Generation](#-Generation-4-papers) (4 papers)
    - [Comment Generation](#Comment-Generation-2-papers) (2 papers)
    - [Debate Generation](#Debate-Generation-0-papers) (0 papers)
    - [Rumor Refutation Generation](#Rumor-Refutation-Generation-0-papers) (0 papers)
    - [Psychological Healing](#Psychological-Healing-0-papers) (0 papers)
    - [Misinformation Generation](#Misinformation-Generation-0-papers) (0 papers)
    - [Humor Generation](#Humor-Generation-1-papers) (1 papers)
    - [Social Bots](#Social-Bots-1-papers) (1 papers)
  - [Simulation and Deduction](#-Simulation-and-Deduction-6-papers) (6 papers)
    - [Social Simulation](#Social-Simulation-4-papers) (4 papers)
    - [Social Network Simulation](#Social-Network-Simulation-2-papers) (2 papers)
    - [Town/Community Simulation](#TownCommunity-Simulation-0-papers) (0 papers)
    - [Game Simulation](#Game-Simulation-0-papers) (0 papers)
    - [Family Simulation](#Family-Simulation-0-papers) (0 papers)
    - [Macrosocial Phenomena Analysis](#Macrosocial-Phenomena-Analysis-1-papers) (1 papers)
    - [Frontier Applications](#Frontier-Applications-0-papers) (0 papers)
  - [Social Media Security](#-Social-Media-Security-0-papers) (0 papers)
  - [Other](#-Other-1-papers) (1 papers)


### | Base Techniques (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Project](https://img.shields.io/badge/Project-View-blue)](https://netsys.surrey.ac.uk/datasets/slashdot/) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Unde...](https://ojs.aaai.org/index.php/ICWSM/article/view/35800) <br> Vibhor Agarwal,Arjoo Gupta,Suparna De,Nishanth Sastry <br> 2025-06-07 <br> <span style="color:cyan">[multi-category：[Base Techniques](#-Base-Techniques-2-papers), [Comment Generation](#Comment-Generation-2-papers)]</span>|A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.\[翻译\] 一个灵活的结构化上下文发现框架，通过学习关注对话树内相关的拓扑邻域来增强对话理解能力。|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion. \[翻译\] 针对在线言论固有的稀疏性和语境依赖性问题，即传统模型往往难以捕捉对话树内的隐式依赖关系，或因无差别地引入上下文而产生噪声 **[innovation]** The proposal of &quot;Conversation Kernels,&quot; a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the &quot;right&quot; structural neighborhood rather than merely increasing context length. \[翻译\] 提出了“对话核”这一通用机制，利用灵活的拓扑形状来检索细粒度的结构化对话上下文；其独到之处在于通过识别“正确”的结构邻域而非单纯增加上下文长度来理解对话。 **[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder. \[翻译\] 一个端到端训练的概率框架，首先通过相似度评分检索相关的结构化窗口（如祖先、邻居），随后通过对RoBERTa编码器生成的预测分布进行加权求和（边缘化），从而融合这些上下文信息。\[通俗核心\]针对目标评论构建回复树，取几个窗口（如父评论窗口、1跳窗口），每个窗口中所有评论与原评论拼接，并进行预测，最后不同窗口与原评论的相关性经过softmax作为权重，对所有预测置信度加权和，得到最终结果 **[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns. \[翻译\] 在Slashdot数据上的广泛实验表明，上下文增强的核机制在准确率上比基线Transformer模型高出20%，并在特定分类任务中超越了通用大语言模型（GPT-3.5/4），揭示了不同任务需要截然不同的结构化上下文模式。 **[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context. \[翻译\] 该方法严重依赖显式的树状回复线索，限制了其在扁平化讨论形式中的适用性，并且在上下文稀疏的对话早期阶段可能面临冷启动挑战。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.<br>\[翻译\] 针对在线言论固有的稀疏性和语境依赖性问题，即传统模型往往难以捕捉对话树内的隐式依赖关系，或因无差别地引入上下文而产生噪声<br>**[innovation]** The proposal of "Conversation Kernels," a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the "right" structural neighborhood rather than merely increasing context length.<br>\[翻译\] 提出了“对话核”这一通用机制，利用灵活的拓扑形状来检索细粒度的结构化对话上下文；其独到之处在于通过识别“正确”的结构邻域而非单纯增加上下文长度来理解对话。<br>**[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.<br>\[翻译\] 一个端到端训练的概率框架，首先通过相似度评分检索相关的结构化窗口（如祖先、邻居），随后通过对RoBERTa编码器生成的预测分布进行加权求和（边缘化），从而融合这些上下文信息。\[通俗核心\]针对目标评论构建回复树，取几个窗口（如父评论窗口、1跳窗口），每个窗口中所有评论与原评论拼接，并进行预测，最后不同窗口与原评论的相关性经过softmax作为权重，对所有预测置信度加权和，得到最终结果<br>**[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.<br>\[翻译\] 在Slashdot数据上的广泛实验表明，上下文增强的核机制在准确率上比基线Transformer模型高出20%，并在特定分类任务中超越了通用大语言模型（GPT-3.5/4），揭示了不同任务需要截然不同的结构化上下文模式。<br>**[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.<br>\[翻译\] 该方法严重依赖显式的树状回复线索，限制了其在扁平化讨论形式中的适用性，并且在上下文稀疏的对话早期阶段可能面临冷启动挑战。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【基础技术—上下文感知方法】可用于所有内容理解任务，论文中的实验用的是是否受欢迎二分类<br>\[引用文\]To better bridge pattern recognition with social interaction structures, Agarwal et al. \(2025\) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods \(e.g., ancestors or siblings\) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.<br>\[翻译\]<br>为了更好地将模式识别与社会互动结构联系起来，Agarwal等人 \(2025\) 提出了“对话核（Conversation Kernels）”，这是一种旨在从对话树中提取细粒度上下文的端到端框架。通过动态检索并加权特定的拓扑邻域（如祖先或兄弟节点）而非摄入线性历史，该方法有效地过滤了社会讨论中固有的噪声。这种结构选择性证明，结合显式的互动拓扑对于准确解读在线对话的性质至关重要，其表现甚至超越了像 GPT-4 这样的通用大语言模型。</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/OpenBMB/IoA.svg?style=social&label=Star)](https://github.com/OpenBMB/IoA) [![Publish](https://img.shields.io/badge/Conference-The%20Thirteenth%20International%20Conference%20on%20Learning%20Representations-blue)]()<br>[Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence](https://openreview.net/forum?id=o1Et3MogPw) <br> Weize Chen\*, Ziming You\*, Ran Li\*, Yitong Guan\*, Chen Qian, Chenyang Zhao Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun <br> 2024-10-04|agent互联网，升级版ABM系统，采用类似互联网思想，C/S架构，分布化、服务化、平台化|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/IoA2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 先前的multi-agent系统的局限性，系统化平台化程度不足（缺乏第三方集成支持，无法分布式，通信协议和状态转换依赖于硬编码） **[innovation]** 将互联网的开放、分布式、服务化思想引入，构建一种标准化、可扩展的支持分布式、异构的智能体集成与通信协议。 **[method]** 服务器：智能体注册（分发系统提示词）、管理已注册智能体（专家）、专家发现服务、群聊管理和消息传递；客户端：包装具体智能体，提供通信接口；三层结构；通信即可嵌套灵活群聊；群聊采用**有限状态机**管理流程；平台初始化与注册-&gt;任务触发团队形成-&gt;内部嵌套协作 **[conclusion/contribution]** 在 GAIA 基准测试中，仅使用四个基础 ReAct 智能体即达到最佳性能；在 RAG 任务中，基于 GPT-3.5 的 IoA 达到或超过 GPT-4 的性能 **[limitation/future]** 实验中存在冗余消息，通信 Token 消耗增加近一倍，这证明agent作为对话者而非执行者的本质能力区别；单点服务器可能存在瓶颈；智能体通过注册获取提示词成为不同专家，仍高度依赖人工实验设计，且这种专家的能力是否可靠">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 先前的multi-agent系统的局限性，系统化平台化程度不足（缺乏第三方集成支持，无法分布式，通信协议和状态转换依赖于硬编码）<br>**[innovation]** 将互联网的开放、分布式、服务化思想引入，构建一种标准化、可扩展的支持分布式、异构的智能体集成与通信协议。<br>**[method]** 服务器：智能体注册（分发系统提示词）、管理已注册智能体（专家）、专家发现服务、群聊管理和消息传递；客户端：包装具体智能体，提供通信接口；三层结构；通信即可嵌套灵活群聊；群聊采用**有限状态机**管理流程；平台初始化与注册->任务触发团队形成->内部嵌套协作<br>**[conclusion/contribution]** 在 GAIA 基准测试中，仅使用四个基础 ReAct 智能体即达到最佳性能；在 RAG 任务中，基于 GPT-3.5 的 IoA 达到或超过 GPT-4 的性能<br>**[limitation/future]** 实验中存在冗余消息，通信 Token 消耗增加近一倍，这证明agent作为对话者而非执行者的本质能力区别；单点服务器可能存在瓶颈；智能体通过注册获取提示词成为不同专家，仍高度依赖人工实验设计，且这种专家的能力是否可靠</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">每个agent被一个客户端包装；服务器不是agent，它只做四件事：注册、发现、建群、路由；相对于传统ABM，这是一个更大型的服务系统，该方法通过基于任务的“群聊”方式组织问题解决，相对传统回合制方式更加自由。本身也是一个高度可扩展系统。问题在于智能体通过注册获取提示词成为不同专家，仍依赖手工设计，且这种专家的能力是否可靠。对于社会模拟任务相对于传统方法有何决定性优势仍未可知</div></details></div></div>|

### | Perception and Classification (24 papers)


### Hate Speech Analysis (4 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[TOT: Topology-Aware Optimal Transport for Multimodal Hate Detection](https://ojs.aaai.org/index.php/AAAI/article/view/25614) <br> Linhao Zhang，Li Jin，Xian Sun，Guangluan Xu，Zequn Zhang,Xiaoyu Li,Nayu Liu,Qing Liu,Shiyao Yan <br> 2023-06-26|强化恶意Meme的图像与文本之间的语义对齐，使用OT方法建立特征向量间的可解释联系|<img width="1200" alt="pipeline" src="figures/TOT.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 为了解决多模态仇恨检测中因” 隐式对齐” 和” 模态鸿沟” 导致的图像和文本跨模态语义对齐难题 **[innovation]** 将OT用于特征对齐，将句子级对齐细粒化至向量级，为后续工作提供了“显式对齐+结构推理”的范式 **[method]** 最优传输 + 拓扑结构推理方法 TOT：CLIP 方法统一表征映射-&gt;最优传输optimal transport \(OT\)将隐式联系细粒化为向量级（这是一个数学计算过程，不涉及需要学习的参数）-&gt;类GNN迭代捕捉自身语义联系（类自注意力）（因为向量间距离意义明确）-&gt;残差连接 **[conclusion/contribution]** 达成了在两个有害 Meme 检测数据集（Harm-C, Harm-P）上的最先进性能； **[limitation/future]** 对齐和推理仍局限于特征层面，未上升到语义单元（如事件、概念）层面，OT过程为冻结无法训练的，可以训练其参数以实现更好的对齐；对于幽默等类似隐式表达容易误判">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 为了解决多模态仇恨检测中因” 隐式对齐” 和” 模态鸿沟” 导致的图像和文本跨模态语义对齐难题<br>**[innovation]** 将OT用于特征对齐，将句子级对齐细粒化至向量级，为后续工作提供了“显式对齐+结构推理”的范式<br>**[method]** 最优传输 + 拓扑结构推理方法 TOT：CLIP 方法统一表征映射->最优传输optimal transport \(OT\)将隐式联系细粒化为向量级（这是一个数学计算过程，不涉及需要学习的参数）->类GNN迭代捕捉自身语义联系（类自注意力）（因为向量间距离意义明确）->残差连接<br>**[conclusion/contribution]** 达成了在两个有害 Meme 检测数据集（Harm-C, Harm-P）上的最先进性能；<br>**[limitation/future]** 对齐和推理仍局限于特征层面，未上升到语义单元（如事件、概念）层面，OT过程为冻结无法训练的，可以训练其参数以实现更好的对齐；对于幽默等类似隐式表达容易误判</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">最优传输OT负责回答“图片的哪个部分和文本的哪个词相关？”（实现统一且对齐的表示，从而建立跨模态的显式联系，OT方法是可解释的）。【即将CLIP生成的特征矩阵级别的对齐，细化为特征向量间的对齐，两个特征矩阵会更相像。这种显式对齐能力本质上来源于CLIP实现的隐对齐】；拓扑建模负责回答“这些相关的部分组合在一起，表达了什么更深层的含义？”（捕捉文本（图片）中互相有联系的token（patch），进行模态内的深度推理）。【这种类似GNN的方法本质上是更有层次性的自注意力机制，天然适用于处理关系型数据（图结构）】；本质上是将CLIP建立的隐式对齐细粒化为向量层级的显式对齐，进而得以使用图推理进一步学习内部联系</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-IEEE%20Transactions%20on%20Multimedia-blue)]()<br>[Flexible optimal transport with contrastive graphical modeling for multimodal hate detection](https://ieeexplore.ieee.org/abstract/document/11045556) <br> Linhao Zhang，Li Jin，Xiaoyu Li,Xian Sun,Senior Member,IEEE,Xin Wang,Zequn Zhang,Jian Liu，Zhicong Lu，Graduate Student Member,IEEE,and Guangluan Xu <br> 2025|\[AI generated\] This method bridges multimodal gaps like a flexible translator, aligning implicit hateful memes through optimal transport and contrastive graphs. \[翻译\]该方法通过最优传输和图对比学习，像灵活的翻译官一样弥合模态鸿沟，对齐隐含仇恨表情包。|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FLOT.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 社媒中隐含仇恨内容检测困难，传统方法难以实现跨模态隐式对齐。 **[innovation]** 相对于同团队的TOT是改进 **[method]** 相对于同团队的TOT:1.OT的目标域不再是另一模态的特征，而是可学习的统一嵌入（OT引入可学习的参数，它们是两个模态各自对应的目标特征矩阵 $T_v$ 和 $T_t$）；2.引入了图对比学习损失，显式约束一致性（比较两个图的相似程度作为一个损失，之后才进行类GNN聚合（动态拓扑推理）） **[conclusion/contribution]** 在Harm-C、Harm-P、MET-Meme三个数据集上取得SOTA，显著提升准确率与F1 **[limitation/future]** 对于幽默等类似隐式表达容易误判">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 社媒中隐含仇恨内容检测困难，传统方法难以实现跨模态隐式对齐。<br>**[innovation]** 相对于同团队的TOT是改进<br>**[method]** 相对于同团队的TOT:1.OT的目标域不再是另一模态的特征，而是可学习的统一嵌入（OT引入可学习的参数，它们是两个模态各自对应的目标特征矩阵 $T_v$ 和 $T_t$）；2.引入了图对比学习损失，显式约束一致性（比较两个图的相似程度作为一个损失，之后才进行类GNN聚合（动态拓扑推理））<br>**[conclusion/contribution]** 在Harm-C、Harm-P、MET-Meme三个数据集上取得SOTA，显著提升准确率与F1<br>**[limitation/future]** 对于幽默等类似隐式表达容易误判</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-ACL%202024-blue)]()<br>[Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning](https://aclanthology.org/2024.acl-long.291) <br> Jingbiao Mei,Jinghong Chen,Weizhe Lin,Bill Byrne,Maarcus Tomalin <br> 2024|专题强化：难学样本单拉出来与正例进行对比学习，从而提高识别能力|<img width="1200" alt="pipeline" src="figures/RGCL.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 现有CLIP等模型对仇恨表情包的图像-文本的细微差异（如“混淆样本”）敏感度不足，导致的误判。 **[innovation]** 对于易混淆的难例（与当前样本相似度最高但标签相反的），使用**动态检索**方式单拉出来，与**伪黄金正样本**（和当前样本相似度最高的标签相同的）成对，作为正反例进行对比学习。从而解决问题 **[method]** 1. 使用冻结的CLIP编码器提取图文特征； 2. 通过Faiss检索动态获取同类相似样本（伪黄金正样本）与异类相似样本（困难负样本）作为正反例； 3. 结合正反例对比损失（RGCLL）与交叉熵损失训练MLP； 4. 实现逻辑分类与KNN检索分类两种分类器，后者通过相似度加权投票进行预测。 **[conclusion/contribution]** 在HatefulMemes数据集上达到 AUROC 87.0%（SOTA），超越Flamingo-80B等大型多模态模型 **[limitation/future]** 仇恨言论的定义具有争议性与文化依赖性；系统对 细微面部表情 识别能力有限；依赖数据标注质量，可能存在标注偏差。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 现有CLIP等模型对仇恨表情包的图像-文本的细微差异（如“混淆样本”）敏感度不足，导致的误判。<br>**[innovation]** 对于易混淆的难例（与当前样本相似度最高但标签相反的），使用**动态检索**方式单拉出来，与**伪黄金正样本**（和当前样本相似度最高的标签相同的）成对，作为正反例进行对比学习。从而解决问题<br>**[method]** 1. 使用冻结的CLIP编码器提取图文特征；<br>2. 通过Faiss检索动态获取同类相似样本（伪黄金正样本）与异类相似样本（困难负样本）作为正反例；<br>3. 结合正反例对比损失（RGCLL）与交叉熵损失训练MLP；<br>4. 实现逻辑分类与KNN检索分类两种分类器，后者通过相似度加权投票进行预测。<br>**[conclusion/contribution]** 在HatefulMemes数据集上达到 AUROC 87.0%（SOTA），超越Flamingo-80B等大型多模态模型<br>**[limitation/future]** 仇恨言论的定义具有争议性与文化依赖性；系统对 细微面部表情 识别能力有限；依赖数据标注质量，可能存在标注偏差。</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and T...](https://ojs.aaai.org/index.php/ICWSM/article/view/35837) <br> Tommaso Giorgi\*,Lorenzo Cima\*,Tiziano Fagni,Marco Avvenuti,Stefano Cresci <br> 2025-06-07|仇恨言论分析中的数据集标注如何受主观偏见影响，提示词引导的角色扮演LLM能否复刻这种偏见|<img width="1200" alt="pipeline" src="figures/HateAnaBias.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 该领域需要大量人工标注，存在固有的主观性bias问题，需要系统性的研究 **[innovation]** The authors introduce a novel methodological framework on the Measuring Hate Speech corpus that quantifies bias through &quot;Intensity&quot; and &quot;Prevalence&quot; metrics without relying on ground truth, uniquely isolating the interplay between specific annotator profiles and target groups. \[翻译\] 指标设计：提出了偏差强度（Intensity, ??）和偏差普遍性（Prevalence, ??），无需Ground Truth即可衡量相对偏差（将**其余所有标注者（Reference Group）**的共识作为基准）。 LLM对齐分析：评估了角色扮演LLM在“复现标注偏差”任务上的能力 **[method]** Leveraging a large-scale dataset with rich demographic attributes, the methodology employs a comparative analysis using confusion matrices to measure relative labeling discrepancies between demographic groups, subsequently evaluating open-source LLMs via role-playing prompts to assess their alignment with human bias patterns. \[翻译\]通过**混淆矩阵**（行代表不具备该属性，列代表具备该属性）对比特定属性群体在评价特定属性受害者时的标签差异。计算偏差强度和普遍性\\n使用**prompt**引导LLM进行相同任务以对比 **[conclusion/contribution]** Quantitative analysis reveals that while human annotators exhibit significant &quot;in-group&quot; hypersensitivity and demographic-specific labeling variations, persona-based LLMs demonstrate a limited correlation with these human biases, failing to accurately mirror the complex social prejudices inherent in human data. \[翻译\] 人类偏差：存在显著的“组内高敏度”（即倾向于高估针对自身群体的仇恨），受人口统计学交互影响严重（如年轻人倾向低估仇恨，老年人倾向高估）。 LLM表现：M表现出自身偏差，但未能有效复现人类的特定偏差（相关性极低），**欠缺对齐能力**（高估代表更敏感） **[limitation/future]** The study&#x27;s limitations include data scarcity for specific minority groups which constrains statistical significance, and a reliance solely on prompting strategies without fine-tuning, which may restrict the models&#x27; capacity for deep behavioral mimicry. \[翻译\] 该研究的局限性包括特定少数群体的数据稀缺限制了统计显著性，以及仅仅依赖提示策略而没有进行微调，这可能限制了模型的深度行为模仿能力。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 该领域需要大量人工标注，存在固有的主观性bias问题，需要系统性的研究<br>**[innovation]** The authors introduce a novel methodological framework on the Measuring Hate Speech corpus that quantifies bias through "Intensity" and "Prevalence" metrics without relying on ground truth, uniquely isolating the interplay between specific annotator profiles and target groups.<br>\[翻译\] 指标设计：提出了偏差强度（Intensity, ??）和偏差普遍性（Prevalence, ??），无需Ground Truth即可衡量相对偏差（将**其余所有标注者（Reference Group）**的共识作为基准）。<br>LLM对齐分析：评估了角色扮演LLM在“复现标注偏差”任务上的能力<br>**[method]** Leveraging a large-scale dataset with rich demographic attributes, the methodology employs a comparative analysis using confusion matrices to measure relative labeling discrepancies between demographic groups, subsequently evaluating open-source LLMs via role-playing prompts to assess their alignment with human bias patterns.<br>\[翻译\]通过**混淆矩阵**（行代表不具备该属性，列代表具备该属性）对比特定属性群体在评价特定属性受害者时的标签差异。计算偏差强度和普遍性\\n使用**prompt**引导LLM进行相同任务以对比<br>**[conclusion/contribution]** Quantitative analysis reveals that while human annotators exhibit significant "in-group" hypersensitivity and demographic-specific labeling variations, persona-based LLMs demonstrate a limited correlation with these human biases, failing to accurately mirror the complex social prejudices inherent in human data.<br>\[翻译\] 人类偏差：存在显著的“组内高敏度”（即倾向于高估针对自身群体的仇恨），受人口统计学交互影响严重（如年轻人倾向低估仇恨，老年人倾向高估）。<br>LLM表现：M表现出自身偏差，但未能有效复现人类的特定偏差（相关性极低），**欠缺对齐能力**（高估代表更敏感）<br>**[limitation/future]** The study's limitations include data scarcity for specific minority groups which constrains statistical significance, and a reliance solely on prompting strategies without fine-tuning, which may restrict the models' capacity for deep behavioral mimicry.<br>\[翻译\] 该研究的局限性包括特定少数群体的数据稀缺限制了统计显著性，以及仅仅依赖提示策略而没有进行微调，这可能限制了模型的深度行为模仿能力。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用句\]Serving as a foundational critique within the transition from static classification to dynamic social simulation, Giorgi et al. \(2025\) demonstrate that although human perception of hate speech is fundamentally shaped by the interplay between annotator and target demographics, current persona-based LLMs fail to faithfully emulate these emergent sociological biases, highlighting a critical gap in the development of realistic AI agents.<br>\[翻译\] 作为从静态分类向动态社会仿真过渡过程中的一项基础性批判研究，Giorgi等人（2025）证明，尽管人类对仇恨言论的感知从根本上受标注者与目标人口统计特征交互作用的影响，但当前的基于角色的LLM无法忠实地模拟这些涌现的社会学偏差，突显了构建逼真AI智能体方面的一个关键差距。</div></details></div></div>|

### Misinformation Analysis (7 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Susceptibility of Communities Against Low-Credibility Content in Social News Websites](https://ojs.aaai.org/index.php/ICWSM/article/view/35813) <br> Yigit Ege Bayiz, Arash Amini, Radu Marculescu, Ufuk Topcu <br> 2025-06-07 <br> <span style="color:cyan">[multi-category：[User Identity Understanding](#User-Identity-Understanding-2-papers), [Misinformation Analysis](#Misinformation-Analysis-7-papers)]</span>|This work presents a computational framework for identifying and profiling ideological communities on social news platforms based on their susceptibility to low-credibility and biased content, using stance-derived user embeddings.<br>\[翻译\]<br>本研究提出了一个计算框架，利用立场导出的用户嵌入，来识别社交新闻平台上的意识形态社区并刻画其对于低可信度和偏见内容的易感性特征。|<img width="1200" alt="pipeline" src="figures/SC-LCC.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** The proliferation of low-credibility and highly biased content on social news platforms like Reddit necessitates moving beyond individual fake-news detection to understanding systemic vulnerabilities at the community level. This study is motivated by the need to identify ideological communities that are particularly susceptible to such content. \[翻译\] Reddit等社交新闻平台上低可信度和高偏见内容的泛滥，要求研究超越个体假新闻检测，转向理解社区层面的系统性脆弱性。本研究旨在识别对此类内容特别易感的意识形态社区。 **[innovation]** Its primary innovation lies in a novel framework that detects ideological communities based on user stance-aware embeddings, rather than platform-defined groups. It uniquely combines fine-tuned LLM-based stance detection, a learned affine transformation for contrary opinions, and spectral clustering to map communities onto a credibility-bias space for susceptibility analysis. \[翻译\] 其主要创新在于一个新颖的框架，该框架基于用户立场感知嵌入而非平台定义的群组来检测意识形态社区。它独特地结合了基于微调LLM的立场检测、用于相反观点的仿射变换学习以及谱聚类，将社区映射到可信度-偏见空间以进行易感性分析。 **[method]** The methodology first embeds post titles via SBERT. It then employs a LoRA-tuned LLM to detect user stances \(favor/against/neutral\) in comments relative to parent posts. Comment embeddings are assigned based on these stances, using the post embedding or its learned affine-transformed negation. User embeddings are derived by averaging their comment embeddings. User-level credibility and bias scores are similarly aggregated from stance-adjusted scores of news sources \(per Ad Fontes Media\). Finally, spectral clustering on user embeddings reveals communities, whose susceptibility is profiled via the aggregated scores. \[翻译\] 该方法首先通过SBERT嵌入帖子标题，然后使用经LoRA微调的大语言模型检测评论中用户相对于父帖的立场（支持/反对/中立）。根据这些立场，使用帖子嵌入或其学习到的仿射变换否定结果为评论分配嵌入向量。通过对用户的评论嵌入取平均得到用户嵌入。用户级的可信度与偏见分数以类似方式，根据立场调整后的新闻源分数进行聚合。最后，对用户嵌入进行谱聚类以揭示社区，并通过聚合分数分析其易感性。 **[conclusion/contribution]** The study demonstrates significant variance in susceptibility across the identified ideological clusters. For instance, the proportion of users prone to low-credibility content differed by 34 percentage points between the most and least susceptible clusters. A correlation was observed between the constructed user embedding space and the credibility-bias space, indicating that latent representations capture susceptibility-related features. \[翻译\] 研究表明，所识别的不同意识形态聚类之间的易感性存在显著差异。例如，对低可信度内容易感的用户比例在最具易感性和最不具易感性的聚类间相差34个百分点。研究观察到构建的用户嵌入空间与可信度-偏见空间之间存在相关性，表明潜在表征捕捉到了与易感性相关的特征。 **[limitation/future]** Limitations include reliance on a single external source for news credibility/bias labels, potential platform-specific biases in the Reddit dataset, and the inherent assumption equating opposition to high-credibility content with low-credibility preference. Future work suggests incorporating comment semantics and user interaction graphs for richer embeddings. \[翻译\] 局限性包括依赖单一外部来源进行新闻可信度/偏见标注、Reddit数据集中可能存在的平台特定偏见，以及将反对高可信度内容等同于偏好低可信度内容的内在假设。未来工作建议融入评论语义和用户交互图以获得更丰富的嵌入表征。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** The proliferation of low-credibility and highly biased content on social news platforms like Reddit necessitates moving beyond individual fake-news detection to understanding systemic vulnerabilities at the community level. This study is motivated by the need to identify ideological communities that are particularly susceptible to such content.<br>\[翻译\]<br>Reddit等社交新闻平台上低可信度和高偏见内容的泛滥，要求研究超越个体假新闻检测，转向理解社区层面的系统性脆弱性。本研究旨在识别对此类内容特别易感的意识形态社区。<br>**[innovation]** Its primary innovation lies in a novel framework that detects ideological communities based on user stance-aware embeddings, rather than platform-defined groups. It uniquely combines fine-tuned LLM-based stance detection, a learned affine transformation for contrary opinions, and spectral clustering to map communities onto a credibility-bias space for susceptibility analysis.<br>\[翻译\]<br>其主要创新在于一个新颖的框架，该框架基于用户立场感知嵌入而非平台定义的群组来检测意识形态社区。它独特地结合了基于微调LLM的立场检测、用于相反观点的仿射变换学习以及谱聚类，将社区映射到可信度-偏见空间以进行易感性分析。<br>**[method]** The methodology first embeds post titles via SBERT. It then employs a LoRA-tuned LLM to detect user stances \(favor/against/neutral\) in comments relative to parent posts. Comment embeddings are assigned based on these stances, using the post embedding or its learned affine-transformed negation. User embeddings are derived by averaging their comment embeddings. User-level credibility and bias scores are similarly aggregated from stance-adjusted scores of news sources \(per Ad Fontes Media\). Finally, spectral clustering on user embeddings reveals communities, whose susceptibility is profiled via the aggregated scores.<br>\[翻译\]<br>该方法首先通过SBERT嵌入帖子标题，然后使用经LoRA微调的大语言模型检测评论中用户相对于父帖的立场（支持/反对/中立）。根据这些立场，使用帖子嵌入或其学习到的仿射变换否定结果为评论分配嵌入向量。通过对用户的评论嵌入取平均得到用户嵌入。用户级的可信度与偏见分数以类似方式，根据立场调整后的新闻源分数进行聚合。最后，对用户嵌入进行谱聚类以揭示社区，并通过聚合分数分析其易感性。<br>**[conclusion/contribution]** The study demonstrates significant variance in susceptibility across the identified ideological clusters. For instance, the proportion of users prone to low-credibility content differed by 34 percentage points between the most and least susceptible clusters. A correlation was observed between the constructed user embedding space and the credibility-bias space, indicating that latent representations capture susceptibility-related features.<br>\[翻译\]<br>研究表明，所识别的不同意识形态聚类之间的易感性存在显著差异。例如，对低可信度内容易感的用户比例在最具易感性和最不具易感性的聚类间相差34个百分点。研究观察到构建的用户嵌入空间与可信度-偏见空间之间存在相关性，表明潜在表征捕捉到了与易感性相关的特征。<br>**[limitation/future]** Limitations include reliance on a single external source for news credibility/bias labels, potential platform-specific biases in the Reddit dataset, and the inherent assumption equating opposition to high-credibility content with low-credibility preference. Future work suggests incorporating comment semantics and user interaction graphs for richer embeddings.<br>\[翻译\]<br>局限性包括依赖单一外部来源进行新闻可信度/偏见标注、Reddit数据集中可能存在的平台特定偏见，以及将反对高可信度内容等同于偏好低可信度内容的内在假设。未来工作建议融入评论语义和用户交互图以获得更丰富的嵌入表征。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【使用**立场检测**得到用户嵌入、然后**谱聚类用于社区分析**】\[方法概括\]<br>1.帖子进行embedding获得特征向量，帖子的所有回复进行相对于帖子的立场检测。2.为评论分配特征向量（相同同帖子，相反为仿射，中立为均值）。3.对每个用户的所有评论进行特征聚合得到用户特征向量（特征向量只用于聚类）。4.通过比较源媒体数据为帖子内容分配可信度和偏见分数，根据对应评论的立场为其分配两个值，同样的聚合得到用户两值。5.根据用户特征向量进行聚类，结合用户两值获得聚类的两值，进行分析\[引用文\]Situated within the evolving scholarly focus that bridges pattern recognition and the simulation of collective social dynamics, Bayiz et al. \(2025\) shift the unit of analysis from individual users or sources to ideological communities to study their susceptibility to misinformation. This is achieved by constructing stance-aware user embeddings—where the stance of comments towards posts, identified via stance detection, is used to infer latent representations—followed by the application of spectral clustering to discover communities based on ideological alignment. They examine these communities within a credibility-bias space, revealing significant inter-community differences in susceptibility to misinformation<br>\[翻译\]<br>置于连接模式识别与集体社会动态仿真的学术演进焦点中，Bayiz等人（2025）将分析单元从个体用户或信源转向意识形态社区，以研究其对错误信息的易感性。这是通过构建立场感知的用户嵌入来实现的——其中，通过立场检测识别出的评论对帖子的立场被用于推断潜在表征——随后应用谱聚类来发现基于意识形态一致性的社区。他们在可信度-偏见空间中研究这些社区，揭示了对错误信息易感性的显著社群间差异。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[GAMC: An Unsupervised Method for Fake News Detection Using Graph Autoencoder with Masking](https://ojs.aaai.org/index.php/AAAI/article/view/27788) <br> Shu Yin,Peican Zhu,Lianwei Wu,Chao Gao,Zhen Wang <br> 2024-03-24|自编码器方法处理类社交网络图结构|<img width="1200" alt="pipeline" src="figures/GAMC.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 现有方法多依赖新闻内容或需大量标注数据，难以有效利用传播上下文信息。 **[innovation]** 首个结合图自编码器、掩码与对比学习的无监督假新闻检测方法，同时利用传播结构与内容信息，无需标注数据 **[method]** 1. 将新闻传播建模为图（新闻节点和用户节点，边表示转发关系，节点特征来自新闻内容和用户历史贴文）； 2. 数据增强（节点特征掩码+边丢弃）（随机选取节点将其特征替换为掩码标记，随机删除部分边）构造自监督特性； 3. 图编码器（GIN）生成潜在表示； 4. 图解码器重建特征； 5. 损失函数组成（**重建损失**（使重建特征接近原始特征）+**对比损失**（来自同一个原始图的两个增强图重建后应尽量相似））训练。 **[conclusion/contribution]** 在 FakeNewsNet 数据集上，GAMC 在无监督方法中表现最佳（如 GossipCop 准确率 0.946），甚至接近或超越部分监督方法 **[limitation/future]** 需要新闻具有一定的传播量才能建模为图；早期传播阶段检测能力受限">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 现有方法多依赖新闻内容或需大量标注数据，难以有效利用传播上下文信息。<br>**[innovation]** 首个结合图自编码器、掩码与对比学习的无监督假新闻检测方法，同时利用传播结构与内容信息，无需标注数据<br>**[method]** 1. 将新闻传播建模为图（新闻节点和用户节点，边表示转发关系，节点特征来自新闻内容和用户历史贴文）；<br>2. 数据增强（节点特征掩码+边丢弃）（随机选取节点将其特征替换为掩码标记，随机删除部分边）构造自监督特性；<br>3. 图编码器（GIN）生成潜在表示；<br>4. 图解码器重建特征；<br>5. 损失函数组成（**重建损失**（使重建特征接近原始特征）+**对比损失**（来自同一个原始图的两个增强图重建后应尽量相似））训练。<br>**[conclusion/contribution]** 在 FakeNewsNet 数据集上，GAMC 在无监督方法中表现最佳（如 GossipCop 准确率 0.946），甚至接近或超越部分监督方法<br>**[limitation/future]** 需要新闻具有一定的传播量才能建模为图；早期传播阶段检测能力受限</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Companion%20Proceedings%20of%20the%20Web%20Conference%202021-blue)]()<br>[How does truth evolve into fake news? An empirical study of fake news evolution](https://dl.acm.org/doi/10.1145/3442442.3452328) <br> Mingfei Guo，Xiuying Chen，Juntao Li，Dongyan Zhao，Rui Yan <br> 2021-06-03|一个包含\[原始新闻、假新闻、演化后的假新闻\]三元组的数据集|<img width="1200" alt="pipeline" src="figures/FNE.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 而现有数据集多关注静态标注，缺乏对其假新闻演化过程的研究 **[innovation]** 给出了关注假新闻演化的数据集FNE，包含“真相-虚假新闻-演化虚假新闻”三元组 **[method]** 1. 从 Snopes.com\(一个辟谣网站\) 抓取truth文章； 2. 通过其引文收集虚假新闻； 3. 利用网页存档平台（如 Archive Today）获取演化后版本； 4. 分析虚假信息技术分类（捏造、否认、混淆、歪曲四类、文本相似度、关键词、词性、情感等属性。 **[conclusion/contribution]** 演化后虚假新闻与原始虚假新闻相似度更高，情感更客观积极，更难以被现有分类模型检测；虚假信息技术中以“捏造”为主；词性和关键词在演化中保持稳定。 **[limitation/future]** 数据来源依赖单一事实核查网站（Snopes），可能引入偏见；仅关注文本新闻，未涵盖图像、视频等多模态演变；">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 而现有数据集多关注静态标注，缺乏对其假新闻演化过程的研究<br>**[innovation]** 给出了关注假新闻演化的数据集FNE，包含“真相-虚假新闻-演化虚假新闻”三元组<br>**[method]** 1. 从 Snopes.com\(一个辟谣网站\) 抓取truth文章；<br>2. 通过其引文收集虚假新闻；<br>3. 利用网页存档平台（如 Archive Today）获取演化后版本；<br>4. 分析虚假信息技术分类（捏造、否认、混淆、歪曲四类、文本相似度、关键词、词性、情感等属性。<br>**[conclusion/contribution]** 演化后虚假新闻与原始虚假新闻相似度更高，情感更客观积极，更难以被现有分类模型检测；虚假信息技术中以“捏造”为主；词性和关键词在演化中保持稳定。<br>**[limitation/future]** 数据来源依赖单一事实核查网站（Snopes），可能引入偏见；仅关注文本新闻，未涵盖图像、视频等多模态演变；</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference](https://ojs.aaai.org/index.php/AAAI/article/view/32022) <br> Mingxin Li,Yuchen Zhang,Haowei Xu,Xianghua Li\*,Chao Gao,Zhen Wang <br> 2025-04-11|通过社交潜在网络推断与自监督多模态学习检测复杂异质多模态假新闻的GNN方法|<img width="1200" alt="pipeline" src="figures/HML.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 社交平台多元化导致新闻传播复杂、多模态，传统假新闻检测方法依赖显式传播关系（如转发），在抖音等平台难以直接获取，检测难度大。 **[innovation]** 提出“社交潜在网络推断Latent Network Inference”策略，无需真实传播关系，即可构建新闻间的潜在联系 **[method]** 1. 社交潜在网络推断：基于Hawkes Process建模新闻影响力随时间变化，得到事件内部与事件间的影响强度，推断出潜在传播网络。 2. 异质图构建：节点均为新闻，边类型基于各种相同或相似属性（如作者、标题、时间等）构建。使用**注意力机制**动态融合不同边类型，生成统一的异质图表示（每个类型的边看做一个“头”，利用多头注意力方法） 3. 自监督多模态内容学习：损失函数：单模态增强（对同一模态进行掩码与重构）、跨模态对比学习（对齐不同模态（如文本与视频）的特征，通过对比学习拉近正样本、推开负样本） 4. 个性化图表示与分类：使用图Transformer Encoder融合图结构与模态特征，进行分类。 **[conclusion/contribution]** FakeSV和FVC数据集上准确率均超89%，较SOTA提升0.12%~4.39%；在Twitter/微博作为插件也提升明显（最高+10.71% F1） **[limitation/future]** 依赖事件定义与时间序列假设，对实时性要求高；计算复杂度较高">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 社交平台多元化导致新闻传播复杂、多模态，传统假新闻检测方法依赖显式传播关系（如转发），在抖音等平台难以直接获取，检测难度大。<br>**[innovation]** 提出“社交潜在网络推断Latent Network Inference”策略，无需真实传播关系，即可构建新闻间的潜在联系<br>**[method]** 1. 社交潜在网络推断：基于Hawkes Process建模新闻影响力随时间变化，得到事件内部与事件间的影响强度，推断出潜在传播网络。<br>2. 异质图构建：节点均为新闻，边类型基于各种相同或相似属性（如作者、标题、时间等）构建。使用**注意力机制**动态融合不同边类型，生成统一的异质图表示（每个类型的边看做一个“头”，利用多头注意力方法）<br>3. 自监督多模态内容学习：损失函数：单模态增强（对同一模态进行掩码与重构）、跨模态对比学习（对齐不同模态（如文本与视频）的特征，通过对比学习拉近正样本、推开负样本）<br>4. 个性化图表示与分类：使用图Transformer Encoder融合图结构与模态特征，进行分类。<br>**[conclusion/contribution]** FakeSV和FVC数据集上准确率均超89%，较SOTA提升0.12%~4.39%；在Twitter/微博作为插件也提升明显（最高+10.71% F1）<br>**[limitation/future]** 依赖事件定义与时间序列假设，对实时性要求高；计算复杂度较高</div></details></div>|
|[![Star](https://img.shields.io/github/stars/xxfwin/NAGASIL.svg?style=social&label=Star)](https://github.com/xxfwin/NAGASIL) [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Harnessing Network Effect for Fake News Mitigation: Selecting Debunkers via Self-Imitation Learning](https://ojs.aaai.org/index.php/AAAI/article/view/30252) <br> Xiaofei Xu, Ke Deng, Michael Dann, Xiuzhen Zhang <br> 2024-03-24|一个辟谣者选择策略（MDP风格）的生成器|<img width="1200" alt="pipeline" src="figures/NAGASIL.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Current approaches to multi-stage fake news mitigation often fail to address the episodic reward problem, where the effect of selecting an individual debunker cannot be measured until the campaign concludes. This sparse and delayed feedback limits the applicability of standard Reinforcement Learning \(RL\) in real-world social networks. \[翻译\] 现有的多阶段假新闻治理方法往往未能解决片段式奖励问题，即选择单个辟谣者的效果只有在活动结束时才能衡量。这种稀疏且延迟的反馈限制了标准强化学习在现实社交网络中的适用性。 **[innovation]** The authors propose NAGASIL, introducing two key enhancements to Self-Imitation Learning: 1\) Negative Sampling, which leverages low-reward historical episodes to explicitly penalize poor debunker selections, and 2\) State Augmentation, which enriches the observed state by integrating historical state-action sequences from the same campaign to address partial observability. \[翻译\] 作者提出了NAGASIL，为自模仿学习引入了两个关键增强：1\) 负采样，利用历史低奖励片段显式惩罚不良的辟谣者选择；2\) 状态增强，通过融合同一活动中的历史状态-动作序列来丰富观测状态，以应对部分可观测性问题。 **[method]** The debunker selection is formulated as a sequential decision-making problem under a budget constraint. A generative adversarial framework is employed, where a generator selects debunkers and a discriminator distinguishes between state-action pairs from high-reward historical episodes and those generated by the current policy. The generator is trained by integrating signals from the discriminator, an entropy regularizer for exploration, and a novel regularizer derived from a negative sampling model trained on low-reward episodes. This process yields an optimal generator capable of outputting an effective debunker selection policy. \[翻译\] 辟谣者选择被建模为预算约束下的序列决策问题。采用生成对抗框架，其中生成器选择辟谣者，判别器区分来自高奖励历史片段的状态-动作对与当前策略生成的对。生成器的训练整合了来自判别器的信号、用于探索的熵正则项，以及一个从低奖励片段训练得到的负采样模型所衍生的新正则项。该过程最终产生一个能输出有效辟谣者选择策略的最优生成器。 **[conclusion/contribution]** Experiments conducted on both real-world \(Facebook\) and synthetic \(Twitter\) networks demonstrate that NAGASIL outperforms state-of-the-art fake news mitigation baselines and standard self-imitation learning methods across various budgets, stage lengths, and network densities. \[翻译\] 在真实世界（Facebook）和合成（Twitter）网络上的实验表明，NAGASIL在各种预算、阶段长度和网络密度设置下，均优于先进的假新闻治理基线方法和标准自模仿学习方法。 **[limitation/future]** The proposed method operates under the assumption that the veracity of news is pre-determined, necessitating integration with an external fake news detection system. Future research could explore adaptive propagation models and the dynamic nature of user behavior. \[翻译\] 所提方法基于新闻真伪已知的假设运行，因此需要与外部假新闻检测系统结合。未来研究可探索自适应的传播模型和用户行为的动态特性。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Current approaches to multi-stage fake news mitigation often fail to address the episodic reward problem, where the effect of selecting an individual debunker cannot be measured until the campaign concludes. This sparse and delayed feedback limits the applicability of standard Reinforcement Learning \(RL\) in real-world social networks.<br>\[翻译\]<br>现有的多阶段假新闻治理方法往往未能解决片段式奖励问题，即选择单个辟谣者的效果只有在活动结束时才能衡量。这种稀疏且延迟的反馈限制了标准强化学习在现实社交网络中的适用性。<br>**[innovation]** The authors propose NAGASIL, introducing two key enhancements to Self-Imitation Learning: 1\) Negative Sampling, which leverages low-reward historical episodes to explicitly penalize poor debunker selections, and 2\) State Augmentation, which enriches the observed state by integrating historical state-action sequences from the same campaign to address partial observability.<br>\[翻译\]<br>作者提出了NAGASIL，为自模仿学习引入了两个关键增强：1\) 负采样，利用历史低奖励片段显式惩罚不良的辟谣者选择；2\) 状态增强，通过融合同一活动中的历史状态-动作序列来丰富观测状态，以应对部分可观测性问题。<br>**[method]** The debunker selection is formulated as a sequential decision-making problem under a budget constraint. A generative adversarial framework is employed, where a generator selects debunkers and a discriminator distinguishes between state-action pairs from high-reward historical episodes and those generated by the current policy. The generator is trained by integrating signals from the discriminator, an entropy regularizer for exploration, and a novel regularizer derived from a negative sampling model trained on low-reward episodes. This process yields an optimal generator capable of outputting an effective debunker selection policy.<br>\[翻译\]<br>辟谣者选择被建模为预算约束下的序列决策问题。采用生成对抗框架，其中生成器选择辟谣者，判别器区分来自高奖励历史片段的状态-动作对与当前策略生成的对。生成器的训练整合了来自判别器的信号、用于探索的熵正则项，以及一个从低奖励片段训练得到的负采样模型所衍生的新正则项。该过程最终产生一个能输出有效辟谣者选择策略的最优生成器。<br>**[conclusion/contribution]** Experiments conducted on both real-world \(Facebook\) and synthetic \(Twitter\) networks demonstrate that NAGASIL outperforms state-of-the-art fake news mitigation baselines and standard self-imitation learning methods across various budgets, stage lengths, and network densities.<br>\[翻译\]<br>在真实世界（Facebook）和合成（Twitter）网络上的实验表明，NAGASIL在各种预算、阶段长度和网络密度设置下，均优于先进的假新闻治理基线方法和标准自模仿学习方法。<br>**[limitation/future]** The proposed method operates under the assumption that the veracity of news is pre-determined, necessitating integration with an external fake news detection system. Future research could explore adaptive propagation models and the dynamic nature of user behavior.<br>\[翻译\]<br>所提方法基于新闻真伪已知的假设运行，因此需要与外部假新闻检测系统结合。未来研究可探索自适应的传播模型和用户行为的动态特性。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]The work by Xu et al. \(2024\) marks a pivotal transition from merely recognizing patterns of disinformation to actively intervening to curtail its spread. By harnessing network effects within a reinforcement learning framework enhanced by self-imitative adversarial learning, their NAGASIL model transcends static pattern recognition. It implements a dynamic, goal-oriented policy learning process that provides actionable guidance for debunker selection strategies.<br>\[翻译\]<br>Xu等人（2024）的研究标志着一个关键的转变：从仅仅识别虚假信息模式，转向主动干预以遏制其传播。通过在一个由自模仿对抗学习增强的强化学习框架内利用网络效应，他们的NAGASIL模型超越了静态模式识别。它实现了一个动态的、目标导向的策略学习过程，为辟谣者选择策略提供了可行的指导。<br>\[notes\]1.这是一个对抗性学习框架，判别器希望好序列的置信度高，其他序列的置信度低，通过损失函数训练优化。生成器依据目标函数进行训练优化，目标函数包含三部分：判别器传来的对抗信号（置信度）、鼓励多样性的熵正则、负采样正则项（来自坏序列的距离（训练另一个模型以输出该值））。好经验和坏经验每轮通过奖励值V\(τ\) = -log\(感染用户比例\)获得。<br>2.每**轮**中每个**阶段**选择一个用户恢复并作为辟谣者，预算减去其成本，进行w个**时间步**的辟谣。每个阶段的预算用完后，进行每轮一次的梯度更新和好坏序列评选，然后进入下一轮</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[News Source Credibility Assessment: A Reddit Case Study](https://ojs.aaai.org/index.php/ICWSM/article/view/35804) <br> Arash Amini, Yigit Ege Bayiz, Ashwin Ram, Radu Marculescu, and Ufuk Topcu <br> 2025-06-07|通过帖子间的评论区相似性构建加权铁子网络，以求找到水军蛛丝马迹，进而确定新闻来源是否可信|<img width="1200" alt="pipeline" src="figures/CREDiBERT.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin. \[翻译\] 本研究受社交媒体虚假信息泛滥的驱动，将重点从核查单一新闻的真实性，转向评估新闻来源的系统性可信度，以应对从源头治理信息污染这一关键问题。 **[innovation]** Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network \(GCN\) to enhance the binary classification of source credibility. \[翻译\] 其核心创新在于基于用户评论的语义相似性构建了一个加权帖子间网络。该网络建模了帖子间潜在的社会语境关联，并通过图卷积网络（GCN）整合这些关联，以提升对新闻来源可信度的二分类性能。 **[method]** The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification. \[翻译\] 该框架（CREDiBERT）首先在描述同一事件的成对帖子上训练一个双编码器，以学习具有可信度感知的文本嵌入。随后，它构建了一个新颖的图结构，其中边的权重通过评论编码了用户反应的相似性。最后，一个图卷积网络（GCN）融合了这些文本与社会信号以完成最终分类。 **[conclusion/contribution]** The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems. \[翻译\] 该模型在可信度评估任务上的F1分数比基于BERT的基线模型高出3%。融入用户交互图后，性能进一步提升了8%，这证明了基于社交的感知信号在评估信息生态系统中的重要价值。 **[limitation/future]** The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities. \[翻译\] 该方法评估的是来源声誉而非文章真实性，因此无法识别那些来自通常可信媒体的偶然性虚假信息。同时，其性能受限于来自特定网络社区的训练数据中存在的固有偏差。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Driven by the proliferation of misinformation on social media, this work shifts focus from fact-checking individual news items to assessing the systemic credibility of news sources, addressing a critical gap in combating information pollution at its origin.<br>\[翻译\]<br>本研究受社交媒体虚假信息泛滥的驱动，将重点从核查单一新闻的真实性，转向评估新闻来源的系统性可信度，以应对从源头治理信息污染这一关键问题。<br>**[innovation]** Its core innovation lies in constructing a weighted post-to-post network based on the semantic similarity of user comments. This network models latent socio-contextual linkages between submissions, which are then integrated via a Graph Convolutional Network \(GCN\) to enhance the binary classification of source credibility.<br>\[翻译\]<br>其核心创新在于基于用户评论的语义相似性构建了一个加权帖子间网络。该网络建模了帖子间潜在的社会语境关联，并通过图卷积网络（GCN）整合这些关联，以提升对新闻来源可信度的二分类性能。<br>**[method]** The framework, CREDiBERT, first trains a bi-encoder on paired submissions about the same event to learn credibility-aware text embeddings. It then builds a novel graph where edge weights encode user reaction similarity via comments. Finally, a GCN fuses these textual and social signals for final classification.<br>\[翻译\]<br>该框架（CREDiBERT）首先在描述同一事件的成对帖子上训练一个双编码器，以学习具有可信度感知的文本嵌入。随后，它构建了一个新颖的图结构，其中边的权重通过评论编码了用户反应的相似性。最后，一个图卷积网络（GCN）融合了这些文本与社会信号以完成最终分类。<br>**[conclusion/contribution]** The model outperforms BERT-based baselines by 3% in F1-score for credibility assessment. Incorporating the user-interaction graph yields a further 8% gain, demonstrating the significant value of socially-grounded signals in evaluating information ecosystems.<br>\[翻译\]<br>该模型在可信度评估任务上的F1分数比基于BERT的基线模型高出3%。融入用户交互图后，性能进一步提升了8%，这证明了基于社交的感知信号在评估信息生态系统中的重要价值。<br>**[limitation/future]** The method assesses source reputation rather than article veracity, leaving it blind to one-off falsehoods from otherwise credible outlets. Its performance is also tied to the bias present in the training data from specific online communities.<br>\[翻译\]<br>该方法评估的是来源声誉而非文章真实性，因此无法识别那些来自通常可信媒体的偶然性虚假信息。同时，其性能受限于来自特定网络社区的训练数据中存在的固有偏差。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]关键设计在于通过评论区的评论相似性建模不同帖子间的潜在联系（加权帖子网络的边权重），在GCN中利用该联系来进行帖子的来源新闻的可信性二分类<br>\[引用文\]Amini et al. \(2025\) move beyond purely content-based pattern recognition, attempting instead to establish connections between posts and the credibility of news sources. Their CREDiBERT framework innovatively constructs a weighted post-to-post network from user comment similarities. This graph structure captures community-specific reaction patterns, which, when processed through a Graph Convolutional Network, significantly enhance the classification of news source credibility. This work underscores a paradigm shift: credibility assessment is beginning to focus on the patterns of information dissemination, rather than solely analyzing the specific content.<br>\[翻译\]<br>Amini等人（2025）的研究超越了单纯的基于内容的模式识别，转而尝试建立帖子与新闻来源可信度的联系。他们的CREDiBERT框架创新性地从用户评论相似性中构建了一个加权帖子间网络。该图结构捕获了社区的特定反应模式，这些模式通过图卷积网络处理后，显著增强了对新闻来源可信度的分类能力。这项工作强调了一个范式转变：可信度评估开始关注消息的传播模式，而不仅仅是分析具体内容。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-CIKM%20%2724-blue)]()<br>[Let silence speak: Enhancing fake news detection with generated comments from large language models](https://dl.acm.org/doi/10.1145/3627673.3679519) <br> Qiong Nan,Qiang Sheng?,Juan Cao,Beizhe Hu,Danding Wang,Jintao Li <br> 2024-10-21|“让沉默的用户发声——用LLM生成多样评论，补充评论特征，提升虚假新闻检测的覆盖力和早期性能。”|<img width="1200" alt="pipeline" src="figures/GenFEND.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments \(e.g., in early stages or from “silent” users\), leading to an incomplete and biased perception of public feedback.  \[翻译\]基于评论的虚假新闻检测受限于真实用户评论的稀缺性与分布偏差（例如在早期传播阶段或来自“沉默”用户），导致对公众反馈的感知不完整且存在偏差。 **[innovation]** 使用LLM补充评论特征，解决该领域评论数据不足和不全面的问题 **[method]** The GenFEND framework: \(1\) generates comments by prompting an LLM with 30 predefined user profiles \(gender/age/education\); \(2\) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; \(3\) aggregates intra-view and inter-view features adaptively for final classification.  \[翻译\]GenFEND框架：\(1\) 通过为LLM提供30个预定义用户画像（性别/年龄/教育）来生成评论；\(2\) 通过分组语义平均和跨人口统计视图的多样性度量对其进行分析；\(3\) 自适应地聚合视图内和视图间的特征以进行最终分类。 **[conclusion/contribution]** GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.  \[翻译\]GenFEND在多个数据集上持续提升了仅使用内容和使用评论的检测器性能。值得注意的是，LLM生成的评论为早期检测提供了有效信号，并且可以超越真实评论的效果，尤其在识别虚假新闻方面。 **[limitation/future]** Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.  \[翻译\]局限性包括对LLM生成质量的依赖、所考虑用户属性的有限性以及较高的计算成本。未来工作可探索更细致的用户建模、动态画像生成以及与真实社交图谱的结合。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Comment-based fake news detection is hindered by the scarcity and skewed distribution of real user comments \(e.g., in early stages or from “silent” users\), leading to an incomplete and biased perception of public feedback.<br><br>\[翻译\]基于评论的虚假新闻检测受限于真实用户评论的稀缺性与分布偏差（例如在早期传播阶段或来自“沉默”用户），导致对公众反馈的感知不完整且存在偏差。<br>**[innovation]** 使用LLM补充评论特征，解决该领域评论数据不足和不全面的问题<br>**[method]** The GenFEND framework: \(1\) generates comments by prompting an LLM with 30 predefined user profiles \(gender/age/education\); \(2\) analyzes them via group-wise semantic averaging and diversity measurement across demographic views; \(3\) aggregates intra-view and inter-view features adaptively for final classification.<br><br>\[翻译\]GenFEND框架：\(1\) 通过为LLM提供30个预定义用户画像（性别/年龄/教育）来生成评论；\(2\) 通过分组语义平均和跨人口统计视图的多样性度量对其进行分析；\(3\) 自适应地聚合视图内和视图间的特征以进行最终分类。<br>**[conclusion/contribution]** GenFEND consistently boosts both content-only and comment-based detectors across datasets. Notably, LLM-generated comments provide effective signals for early detection and can outperform actual comments, especially in identifying fake news.<br><br>\[翻译\]GenFEND在多个数据集上持续提升了仅使用内容和使用评论的检测器性能。值得注意的是，LLM生成的评论为早期检测提供了有效信号，并且可以超越真实评论的效果，尤其在识别虚假新闻方面。<br>**[limitation/future]** Limitations include dependence on LLM generation quality, limited considered user attributes, and higher computational cost. Future work may explore more nuanced user modeling, dynamic profile generation, and integration with real social graphs.<br><br>\[翻译\]局限性包括对LLM生成质量的依赖、所考虑用户属性的有限性以及较高的计算成本。未来工作可探索更细致的用户建模、动态画像生成以及与真实社交图谱的结合。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]Within the task of False Content Analysis, a key bottleneck is the scarcity of early-stage comments and the absence of opinions from silent users. The GenFEND framework \(Nan et al., 2024\) addresses this by using Large Language Models \(LLMs\) to supplement these missing comments. Instead of passively relying on sparse real comments, their approach actively generates a rich set of synthetic comments conditioned on diverse user profiles \(e.g., gender, age, education level\). This method effectively performs data augmentation in the social comment space, providing a stable and diverse informational supplement. This helps models establish a more complete perceptual foundation for veracity judgment and has proven to be highly effective for early fake news detection.<br>\[翻译\]<br>在虚假内容分析任务中，一个关键瓶颈是早期评论的稀缺性和沉默用户意见的缺失。GenFEND框架 \(Nan et al., 2024\) 通过使用大语言模型来补充这部分缺失的评论，从而解决了这一问题。该方法不再被动地依赖稀疏的真实评论，而是主动生成一组以多样化用户画像（如性别、年龄、教育程度）为条件的丰富合成评论。该方法有效地在社交评论空间进行了数据增强，提供了一个稳定且多样化的信息补充。这有助于模型为真实性判断建立更完整的感知基础，并被证明对早期虚假新闻检测非常有效。</div></details></div></div>|

### Controversy Analysis (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/gvrkiran/controversy-detection.svg?style=social&label=Star)](https://github.com/gvrkiran/controversy-detection) [![Publish](https://img.shields.io/badge/Conference-World%20Wide%20Web-blue)]()<br>[A text and GNN based controversy detection method on social media](https://doi.org/10.1007/s11280-022-01116-0) <br> Samy Benslimane, Jér?me Azé, Sandra Bringay, Maximilien Servajean, Caroline Mollevi <br> 2023-03-01|To identify controversial topics from discussion inputs, the method aggregates historical comments into user node features to encode intrinsic user and network attributes, and subsequently applies GNN methods on the user-centric social network to achieve binary classification.<br>\[翻译\] 在争议话题识别中，输入是一段讨论，为了编码用户本身特征和用户网络特征，将用户历史评论聚合为用户节点特征，在以用户为节点的社交网络上，进行GNN方法，实现二分类。|<img width="1200" alt="pipeline" src="figures/HRL-GCN.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Existing controversy detection approaches often treat structural patterns and semantic content in isolation or rely solely on post-reply trees, neglecting the critical role of user entities and their interaction dynamics in driving social polarization. \[翻译\] 现有的争议检测方法通常将结构模式和语义内容割裂处理，或单纯依赖帖子回复树结构，忽视了用户实体及其交互动态在驱动社会极化中的关键作用。 **[innovation]** The study shifts focus from message-level dependencies to user-centric interaction graphs. A key innovation lies in aggregating individual comments into unified user features, which allows the model to encode network-level information and actor stances simultaneously within the graph structure. \[翻译\] 该研究将焦点从消息级依赖关系转移到了以用户为中心的交互图上。其主要创新在于将分散的评论聚合为统一的用户特征，这使得模型能够在图结构中同时编码网络层面的信息和行动者的立场。 **[method]** The framework constructs a user graph where node features are initialized with BERT-encoded textual features aggregated from user historical comments. Subsequently, two GNN methods—Hierarchical Representation Learning via differentiable pooling \(HRL-GCN\) or Attention-based Representation Learning \(ARL-GAT\)—are employed to capture structural patterns, ultimately performing graph-level binary classification. \[翻译\] 该框架构建了一个用户图，其中节点特征初始化为从用户历史评论中聚合的BERT编码文本特征。随后，利用通过可微池化实现的分层表示学习（HRL-GCN）或基于注意力的表示学习（ARL-GAT）两种GNN方法来捕捉结构模式，最终完成图级二分类。 **[conclusion/contribution]** Empirical evaluations on Reddit and Twitter datasets demonstrate that the hierarchical pooling strategy \(HRL-GCN\) achieves superior performance by effectively capturing community-level structures, validating that combining aggregated user semantics with interaction topology significantly outperforms structure-only baselines. \[翻译\] 在Reddit和Twitter数据集上的实证评估表明，分层池化策略（HRL-GCN）通过有效捕捉社区级结构实现了更优的性能，证实了结合聚合的用户语义与交互拓扑结构显著优于仅依赖基线的结构。 **[limitation/future]** Standard pre-trained language models perform suboptimally on noisy Twitter data without domain-specific fine-tuning. Additionally, the approach is currently limited to homogeneous graphs, suggesting that future work could explore heterogeneous graph modeling to integrate multiple interaction types. \[翻译\] 标准预训练语言模型在未经领域微调的情况下在噪声较大的Twitter数据上表现欠佳，以及仅限于同构图，未来可以探索异构图建模以整合多种交互类型。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Existing controversy detection approaches often treat structural patterns and semantic content in isolation or rely solely on post-reply trees, neglecting the critical role of user entities and their interaction dynamics in driving social polarization.<br>\[翻译\] 现有的争议检测方法通常将结构模式和语义内容割裂处理，或单纯依赖帖子回复树结构，忽视了用户实体及其交互动态在驱动社会极化中的关键作用。<br>**[innovation]** The study shifts focus from message-level dependencies to user-centric interaction graphs. A key innovation lies in aggregating individual comments into unified user features, which allows the model to encode network-level information and actor stances simultaneously within the graph structure.<br>\[翻译\] 该研究将焦点从消息级依赖关系转移到了以用户为中心的交互图上。其主要创新在于将分散的评论聚合为统一的用户特征，这使得模型能够在图结构中同时编码网络层面的信息和行动者的立场。<br>**[method]** The framework constructs a user graph where node features are initialized with BERT-encoded textual features aggregated from user historical comments. Subsequently, two GNN methods—Hierarchical Representation Learning via differentiable pooling \(HRL-GCN\) or Attention-based Representation Learning \(ARL-GAT\)—are employed to capture structural patterns, ultimately performing graph-level binary classification.<br>\[翻译\] 该框架构建了一个用户图，其中节点特征初始化为从用户历史评论中聚合的BERT编码文本特征。随后，利用通过可微池化实现的分层表示学习（HRL-GCN）或基于注意力的表示学习（ARL-GAT）两种GNN方法来捕捉结构模式，最终完成图级二分类。<br>**[conclusion/contribution]** Empirical evaluations on Reddit and Twitter datasets demonstrate that the hierarchical pooling strategy \(HRL-GCN\) achieves superior performance by effectively capturing community-level structures, validating that combining aggregated user semantics with interaction topology significantly outperforms structure-only baselines.<br>\[翻译\] 在Reddit和Twitter数据集上的实证评估表明，分层池化策略（HRL-GCN）通过有效捕捉社区级结构实现了更优的性能，证实了结合聚合的用户语义与交互拓扑结构显著优于仅依赖基线的结构。<br>**[limitation/future]** Standard pre-trained language models perform suboptimally on noisy Twitter data without domain-specific fine-tuning. Additionally, the approach is currently limited to homogeneous graphs, suggesting that future work could explore heterogeneous graph modeling to integrate multiple interaction types.<br>\[翻译\] 标准预训练语言模型在未经领域微调的情况下在噪声较大的Twitter数据上表现欠佳，以及仅限于同构图，未来可以探索异构图建模以整合多种交互类型。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]To better capture the dynamics of social polarization in the field of controversial content identification, Benslimane et al. \(2023\) shift from content-based analysis to a user-centric perspective. They argue that the structural relationships between users and the users' inherent attributes are pivotal for understanding controversy. Unlike traditional methods that treat posts as isolated nodes, their approach constructs a user interaction graph where node representations are derived by aggregating the semantic content of each user’s historical comments. This design encodes complex network information and individual stances into a unified feature space. By employing GNN methods such as Hierarchical Graph Representation Learning \(HRL-GCN\), the model performs multi-layer aggregation on the graph to capture high-level community structures, demonstrating that the fusion of user features with social interaction patterns provides an effective mechanism for controversy identification in social media.<br>\[翻译\] 为了更好地在争议内容识别领域捕捉社会极化的动态，Benslimane等人 \(2023\) 的方法从基于内容的分析转变为以用户为中心视角。他们认为，用户之间的结构关系以及用户本身的属性对于理解争议至关重要。与将帖子视为孤立节点的传统方法不同，他们的方法构建了一个用户交互图，其中节点表示通过聚合每个用户历史评论的语义内容得到。这种设计将复杂的网络信息和个人立场编码到了统一的特征空间中。通过采用分层图表示学习（HRL-GCN）等GNN的方法，该模型对图进行多层聚合以捕捉高层级的社区结构，证明了用户特征与社交交互模式的融合为识别社交媒体中的争议识别提供了一种有效的机制。</div></details></div></div>|

### Sentiment Analysis (3 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence-blue)]()<br>[CAMEL: Capturing metaphorical alignment with context disentangling for multimodal emotion recogni...](https://ojs.aaai.org/index.php/AAAI/article/view/28787) <br> Linhao Zhang,Li Jin\*,Guangluan Xu,Xiaoyu Li,Cai Xu,Kaiwen Wei,Nayu Liu,Haonan Liu <br> 2024-03-24|\[AI generated\] CAMEL disentangles metaphorical alignment like a prism separating light, then adaptively fuses context for emotion recognition. \[翻译\]CAMEL像棱镜分离光线般解耦隐喻对齐，再自适应融合上下文进行情感识别。|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/CAMEL.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 为了解决多模态内容中因隐喻对齐导致**情感误判**的问题：之前的方法本质上无法理解隐喻,专注于直接的语义对齐，无法捕捉如文字“眼泪”与图片“河流”的这种隐式联系 **[innovation]** 将多模态间隐含联系的对齐思想应用于多模态情感识别领域 **[method]** 使用了基于条件生成与解耦上下文适应的CAMEL框架:隐喻对齐建模（条件生成）\(强制模型按照模版输出（CMT和SPV两种技术）；使用图片、标题、文本的交叉注意力机制，使用一个\[CLS\] token聚合全局信息）-&gt;上下文语义适应（特征融合）（使用两个异构模型，分别输入字面特征（CAMEL-C，CMT）和隐喻特征（CAMEL-S，SPV）生成两个向量矩阵，通过隐喻查字面实现多头注意力）-&gt;解耦对比匹配（上下文正则化）（确保不偏离语境。采用解耦学习思想，隐喻特征中分离出代表“主导上下文类别”的离散分布，通过对比学习，使字面特征推出的分布与之对齐） **[conclusion/contribution]** 达成了对隐含情感更精准、鲁棒的识别效果 **[limitation/future]** 整个方法框架复杂，模型所需的所有能力：找字面特征、找隐喻特征、两者对齐、根据融合特征生成情感分析，都是一次训练完成的，是否难以收敛（虽然论文使用了课程学习策略），是否能够在训练层面进行一定的解耦？分别训练各能力">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 为了解决多模态内容中因隐喻对齐导致**情感误判**的问题：之前的方法本质上无法理解隐喻,专注于直接的语义对齐，无法捕捉如文字“眼泪”与图片“河流”的这种隐式联系<br>**[innovation]** 将多模态间隐含联系的对齐思想应用于多模态情感识别领域<br>**[method]** 使用了基于条件生成与解耦上下文适应的CAMEL框架:隐喻对齐建模（条件生成）\(强制模型按照模版输出（CMT和SPV两种技术）；使用图片、标题、文本的交叉注意力机制，使用一个\[CLS\] token聚合全局信息）->上下文语义适应（特征融合）（使用两个异构模型，分别输入字面特征（CAMEL-C，CMT）和隐喻特征（CAMEL-S，SPV）生成两个向量矩阵，通过隐喻查字面实现多头注意力）->解耦对比匹配（上下文正则化）（确保不偏离语境。采用解耦学习思想，隐喻特征中分离出代表“主导上下文类别”的离散分布，通过对比学习，使字面特征推出的分布与之对齐）<br>**[conclusion/contribution]** 达成了对隐含情感更精准、鲁棒的识别效果<br>**[limitation/future]** 整个方法框架复杂，模型所需的所有能力：找字面特征、找隐喻特征、两者对齐、根据融合特征生成情感分析，都是一次训练完成的，是否难以收敛（虽然论文使用了课程学习策略），是否能够在训练层面进行一定的解耦？分别训练各能力</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">首先通过多头跨域注意力机制实现初步的对齐，然后让字面特征的分布与隐喻特征的分布对齐，进一步强化对齐；</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/neuralnaresh/multimodal-emotion-recognition.svg?style=social&label=Star)](https://github.com/neuralnaresh/multimodal-emotion-recognition) [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%2031st%20ACM%20International%20Conference%20on%20Multimedia-blue)]()<br>[Multi-label emotion analysis in conversation via multimodal knowledge distillation](https://dl.acm.org/doi/10.1145/3581783.3612517) <br> Sidharth Anand?,Naresh Kumar Devulapally?,Sreyasee Das Bhattacharjee,Junsong Yuan <br> 2023-10-27|三个专家分别处理一个模态，训练的同时将能力蒸馏给融合分支，最终形成一个整体模型，教师（分支专家）与学生（融合专家）一同处理多模态内容，得到情感分类|<img width="1200" alt="pipeline" src="figures/SeMuL-PCD.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations. \[翻译\] 针对现有多模态方法主要关注单一主导情感的局限性，该研究致力于解决情感标签共现的识别难题，并提升模型在不同社会人口统计学群体（特别是不同年龄段人群）中的泛化能力。 **[innovation]** 将多模态知识蒸馏与标签一致性校准损失（LCC）相结合，减轻了模型对简单标签的过拟合（保证置信度相近）；构建了一个利用蒸馏方法的整体框架，其目的是为了融合各模态能力 **[method]** Employing a Multimodal Transformer Network where mode-specific peer branches \(visual, audio, textual\) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.…… \[翻译\] 将三个特定模态的对等分支通过跨网络注意力和噪声对比估计，协同地将其学习到的概率蒸馏到融合分支中，构建了一个拥有四个分支的整体预测模型。\[值得关注\]视频使用Tubelet embedding技术，将视频切分为时空小块（Spatial-Temporal Tubes），保留时空信息 **[conclusion/contribution]** Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios. \[翻译\] 在MOSEI、EmoReact和ElderReact数据集上最先进的性能，跨数据集评估有约17%的加权F1提升，在跨年龄场景下具有鲁棒性。 **[limitation/future]** The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism. \[翻译\] 为了保持跨数据集一致性，要将复杂情感类归约为基础子集，由于采用时空Tubelet嵌入机制，导致了显著的计算开销">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the limitations of single-dominant emotion assumptions by tackling the challenge of multi-label emotion co-occurrence and generalization across diverse socio-demographic groups, particularly varying age populations.<br>\[翻译\] 针对现有多模态方法主要关注单一主导情感的局限性，该研究致力于解决情感标签共现的识别难题，并提升模型在不同社会人口统计学群体（特别是不同年龄段人群）中的泛化能力。<br>**[innovation]** 将多模态知识蒸馏与标签一致性校准损失（LCC）相结合，减轻了模型对简单标签的过拟合（保证置信度相近）；构建了一个利用蒸馏方法的整体框架，其目的是为了融合各模态能力<br>**[method]** Employing a Multimodal Transformer Network where mode-specific peer branches \(visual, audio, textual\) collaboratively distill learned probabilistic uncertainty into a fusion branch via cross-network attention and noise contrastive estimation.……<br>\[翻译\] 将三个特定模态的对等分支通过跨网络注意力和噪声对比估计，协同地将其学习到的概率蒸馏到融合分支中，构建了一个拥有四个分支的整体预测模型。\[值得关注\]视频使用Tubelet embedding技术，将视频切分为时空小块（Spatial-Temporal Tubes），保留时空信息<br>**[conclusion/contribution]** Demonstrates state-of-the-art performance on MOSEI, EmoReact, and ElderReact datasets, achieving an approximate 17% improvement in weighted F1-score during cross-dataset evaluations, thereby validating robustness in age-diverse scenarios.<br>\[翻译\] 在MOSEI、EmoReact和ElderReact数据集上最先进的性能，跨数据集评估有约17%的加权F1提升，在跨年龄场景下具有鲁棒性。<br>**[limitation/future]** The approach necessitates the reduction of complex emotion categories to basic subsets for cross-dataset consistency and entails significant computational overhead due to the spatiotemporal tubelet embedding mechanism.<br>\[翻译\] 为了保持跨数据集一致性，要将复杂情感类归约为基础子集，由于采用时空Tubelet嵌入机制，导致了显著的计算开销</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【面向结果模型训练】\[引用句\]"Transscending the traditional paradigm of identifying single dominant emotions, Anand et al. \[2023\] proposed SeMuL-PCD to enhance the granularity of affective perception in diverse social contexts; by leveraging a collaborative distillation mechanism that calibrates mode-specific feedback, their model robustly disentangles multi-label emotional co-occurrences across varying demographic backgrounds \(e.g., children and the elderly\), thereby providing a more nuanced foundation for socially adaptive agents."<br>\[翻译\] “为了超越识别单一主导情感的传统范式，Anand等人\[2023\]提出了SeMuL-PCD，旨在增强不同社会语境下情感感知的粒度；通过利用一种校准模态特定反馈的协作蒸馏机制，该模型能够在不同的人口统计背景（如儿童和老人）下鲁棒地解耦多标签情感的共现关系，从而为具备社会适应能力的智能体提供了更精细的情感理解基础。”</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/dess-mannheim/temporal-adapters.svg?style=social&label=Star)](https://github.com/dess-mannheim/temporal-adapters) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Extracting affect aggregates from longitudinal social media data with temporal adapters for large...](https://ojs.aaai.org/index.php/ICWSM/article/view/35801) <br> Georg Ahnert, Max Pellert, David Garcia, Markus Strohmaier <br> 2025-06-07|对于每周，训练一个LoRA作为时间适配器，使模型获得了根据时间段预测情感的能力|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Temporal Adapters.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Temporal Adapters2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries. \[翻译\] 解决了基于提示词的in silico（计算机模拟）调查中固有的时间错位问题，以及传统情感计算严重依赖资源密集型标注数据集或静态词典的可扩展性瓶颈 **[innovation]** 利用LoRA作为模块化学习元件的“时间适配器”，以捕捉特定时期独有的时间与语言特征。通过将这些轻量级适配器与冻结基座模型的固有推理能力产生协同作用，该框架实现了高效且可扩展的纵向情感预测。 **[method]** Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions. \[翻译\] 采用双阶段框架：首先，通过自监督的因果语言建模目标在纵向Twitter时间线上微调每周的LoRA适配器；其次，使用标准心理测量问卷探测适配后的模型，通过Token概率分布提取聚合情感 \[通俗核心\]在每周分别进行LoRA自监督微调，让模型的预测尽可能和原数据一样。使用专业问卷作为prompt，模拟模型回答问卷，最终得到一个情感概率随时间的分布，与公众真实分布对比 **[conclusion/contribution]** Demonstrates strong, significant correlations with representative polling data \(YouGov\) during the COVID-19 pandemic, achieving performance comparable to supervised baselines \(e.g., TweetNLP\) while offering superior flexibility in querying diverse and complex collective attitudes. \[翻译\] 展示了在COVID-19大流行期间与代表性民调数据（YouGov）的强显著相关性，实现了与监督基线模型（如TweetNLP）相当的性能，同时在查询多样化且复杂的集体态度方面提供了更优越的灵活性。 **[limitation/future]** Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora. \[翻译\] 主要在纵向趋势分析而非绝对横截面校准方面有效，且涌现出的情感代表性受限于社交媒体训练语料库中固有的人口统计学偏差">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the temporal misalignment inherent in prompt-based in silico surveys and the scalability bottlenecks of traditional affective computing, which heavily relies on resource-intensive labeled datasets or static dictionaries.<br>\[翻译\] 解决了基于提示词的in silico（计算机模拟）调查中固有的时间错位问题，以及传统情感计算严重依赖资源密集型标注数据集或静态词典的可扩展性瓶颈<br>**[innovation]** 利用LoRA作为模块化学习元件的“时间适配器”，以捕捉特定时期独有的时间与语言特征。通过将这些轻量级适配器与冻结基座模型的固有推理能力产生协同作用，该框架实现了高效且可扩展的纵向情感预测。<br>**[method]** Employs a two-stage framework: first, fine-tuning weekly LoRA adapters on longitudinal Twitter timelines via a self-supervised causal language modeling objective; second, probing the adapted models with standard psychometric questionnaires to extract aggregate affect via token probability distributions.<br>\[翻译\] 采用双阶段框架：首先，通过自监督的因果语言建模目标在纵向Twitter时间线上微调每周的LoRA适配器；其次，使用标准心理测量问卷探测适配后的模型，通过Token概率分布提取聚合情感<br>\[通俗核心\]在每周分别进行LoRA自监督微调，让模型的预测尽可能和原数据一样。使用专业问卷作为prompt，模拟模型回答问卷，最终得到一个情感概率随时间的分布，与公众真实分布对比<br>**[conclusion/contribution]** Demonstrates strong, significant correlations with representative polling data \(YouGov\) during the COVID-19 pandemic, achieving performance comparable to supervised baselines \(e.g., TweetNLP\) while offering superior flexibility in querying diverse and complex collective attitudes.<br>\[翻译\] 展示了在COVID-19大流行期间与代表性民调数据（YouGov）的强显著相关性，实现了与监督基线模型（如TweetNLP）相当的性能，同时在查询多样化且复杂的集体态度方面提供了更优越的灵活性。<br>**[limitation/future]** Primarily effective for longitudinal trend analysis rather than absolute cross-sectional calibration, and the representativeness of the emergent sentiment is constrained by the demographic biases inherent in the social media training corpora.<br>\[翻译\] 主要在纵向趋势分析而非绝对横截面校准方面有效，且涌现出的情感代表性受限于社交媒体训练语料库中固有的人口统计学偏差</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【集体情感分析】通过LoRA自监督学到的是该特定时间段内公众的语言风格和关注点，结合基础模型的固有能力获得了预测特定时间内公众情感的能力，很神奇，这是一个通用方法<br>\[引用文\]Moving beyond traditional supervised classifiers, Ahnert et al. \(2025\) demonstrate a shift toward the social simulation paradigm by proposing Temporal Adapters. Instead of training models to explicitly recognize emotion patterns, they utilize self-supervised learning to train lightweight LoRA modules as learning components, aligning the frozen LLM with specific temporal and linguistic contexts derived from longitudinal social media data. This equips the model with the capability to predict public sentiment within specific timeframes. Their approach validates that scalable and accurate tracking of public opinion dynamic<br>\[翻译\]<br>超越了传统的监督分类器，Ahnert等人 \(2025\) 通过提出 “时间适配器” 展示了向社会仿真范式的转变。他们不再训练模型去显式地识别情感模式，而是通过自监督学习训练轻量级的LoRA模块作为学习元件，将冻结的大语言模型与源自纵向社交媒体数据的特定时间及语言语境相对齐。使模型获得了预测特定时间内公众情感的能力。他们的方法证实，通过时间对齐而非标签监督，即可实现对民意动态的可扩展且准确的追踪。</div></details></div></div>|

### Meme Analysis (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/tygobl/meme-clustering.svg?style=social&label=Star)](https://github.com/tygobl/meme-clustering) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity](https://ojs.aaai.org/index.php/ICWSM/article/view/35815) <br> Tygo Bloem, Filip Ilievski <br> 2025-06-07|Utilizing the Louvain community detection algorithm for meme clustering, the study decomposes similarity into four dimensions \(form, visual content, text, and identity\) to construct adjacency matrices, and employs a strategy of filtering prior to clustering, followed by matching filtered samples, to enhance efficiency and purity by reducing noise.<br>\[翻译\] 为实现meme的聚类，使用社区发现算法louvain。首先将meme相似度分为4个维度（形式、图义、文本、身份），据其构建邻接矩阵。为提高聚类效率和纯度（降低噪声），采用先过滤，再聚类，最后匹配被过滤样本的方法。|<img width="1200" alt="pipeline" src="figures/meme-clustering.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Existing approaches often rely on static, incomplete databases or single-modality features, failing to capture the dynamic evolution and multi-layered semantics of internet memes. \[翻译\] 现有方法通常依赖静态、不完整的数据库或单一模态特征，难以捕捉互联网模因的动态演化及多层语义。 **[innovation]** The study introduces a fine-grained multi-dimensional similarity framework and a two-stage strategy that filters weak connections to bootstrap high-purity template clusters, significantly enhancing the efficiency of community detection algorithms like Louvain. \[翻译\] 该研究提出了一种细粒度的多维相似度框架，以及一种两阶段策略，通过过滤弱连接来自举生成高纯度的模版簇，显著提升了Louvain等社区发现算法的效率。 **[method]** The method constructs adjacency matrices based on form, content, text, and identity features, applying a filtering threshold to simplify the graph structure for robust, low-noise template identification, followed by classifying the remaining samples via similarity matching. \[翻译\] 该方法基于形式、内容、文本和身份特征构建邻接矩阵，应用过滤阈值简化图结构以实现稳健、低噪声的模版识别，随后通过相似度匹配对剩余样本进行分类。 **[conclusion/contribution]** Experimental results demonstrate that this template-based approach achieves superior cluster consistency \(0.94\) compared to standard baselines, effectively handling diverse meme variants while aligning with human semantic intuition. \[翻译\] 实验结果表明，这种基于模版的方法实现了优于标准基线的聚类一致性（0.94），在有效处理多样化模因变体的同时，与人类的语义直觉保持一致。 **[limitation/future]** The framework&#x27;s performance is contingent on the quality of upstream feature extractors and currently lacks integration with external knowledge graphs to interpret complex cultural metaphors or irony. \[翻译\] 该框架的性能取决于上游特征提取器的质量，且目前缺乏与外部知识图谱的整合以解释复杂的文化隐喻或反讽。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Existing approaches often rely on static, incomplete databases or single-modality features, failing to capture the dynamic evolution and multi-layered semantics of internet memes.<br>\[翻译\] 现有方法通常依赖静态、不完整的数据库或单一模态特征，难以捕捉互联网模因的动态演化及多层语义。<br>**[innovation]** The study introduces a fine-grained multi-dimensional similarity framework and a two-stage strategy that filters weak connections to bootstrap high-purity template clusters, significantly enhancing the efficiency of community detection algorithms like Louvain.<br>\[翻译\] 该研究提出了一种细粒度的多维相似度框架，以及一种两阶段策略，通过过滤弱连接来自举生成高纯度的模版簇，显著提升了Louvain等社区发现算法的效率。<br>**[method]** The method constructs adjacency matrices based on form, content, text, and identity features, applying a filtering threshold to simplify the graph structure for robust, low-noise template identification, followed by classifying the remaining samples via similarity matching.<br>\[翻译\] 该方法基于形式、内容、文本和身份特征构建邻接矩阵，应用过滤阈值简化图结构以实现稳健、低噪声的模版识别，随后通过相似度匹配对剩余样本进行分类。<br>**[conclusion/contribution]** Experimental results demonstrate that this template-based approach achieves superior cluster consistency \(0.94\) compared to standard baselines, effectively handling diverse meme variants while aligning with human semantic intuition.<br>\[翻译\] 实验结果表明，这种基于模版的方法实现了优于标准基线的聚类一致性（0.94），在有效处理多样化模因变体的同时，与人类的语义直觉保持一致。<br>**[limitation/future]** The framework's performance is contingent on the quality of upstream feature extractors and currently lacks integration with external knowledge graphs to interpret complex cultural metaphors or irony.<br>\[翻译\] 该框架的性能取决于上游特征提取器的质量，且目前缺乏与外部知识图谱的整合以解释复杂的文化隐喻或反讽。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【meme聚类】\[引用文\]To address the limitations of static database matching in capturing evolving digital content, Bloem and Ilievski \(2025\) proposed a template-based clustering framework that deconstructs meme similarity into four fine-grained dimensions: form, visual content, text, and identity. A key innovation is the introduction of a graph filtering mechanism prior to clustering with community detection algorithms. By pruning weak connections in the adjacency matrix, the method simplifies the graph structure to efficiently identify high-purity core templates using the Louvain algorithm. The remaining instances are subsequently re-associated through similarity matching, thereby effectively balancing computational complexity with semantic coherence in tracking meme propagation.<br>\[翻译\] 为了解决静态数据库匹配在捕捉演化数字内容方面的局限性，Bloem和Ilievski \(2025\) 提出了一种基于模版的聚类框架，将模因相似度解构为形式、视觉内容、文本和身份四个细粒度维度。关键创新是在使用社区发现算法进行聚类之前引入了图过滤机制。通过剪除邻接矩阵中的弱连接，该方法简化了图结构，从而利用Louvain算法高效地识别出高纯度的核心模版。剩余的实例随后通过相似度匹配被重新关联，从而在追踪模因传播时有效平衡了计算复杂度与语义连贯性。</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/Social-AI-Studio/MemeCraft.svg?style=social&label=Star)](https://github.com/Social-AI-Studio/MemeCraft) [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20ACM%20Web%20Conference%202024%EF%BC%88WWW%20%2724%29-blue)]()<br>[MemeCraft: Contextual and stance-driven multimodal meme generation](https://dl.acm.org/doi/10.1145/3589334.3648151) <br> Han Wang, Roy Ka-Wei Lee <br> 2024-05-13 <br> <span style="color:cyan">[multi-category：[Meme Analysis](#Meme-Analysis-2-papers), [Humor Generation](#Humor-Generation-1-papers)]</span>|This work presents an end-to-end, training-free meme generator that operates through a sequence of template retrieval, visual description generation, text synthesis via structured prompting, meme composition, and final hate speech detection.<br>\[翻译\] 端到端无训练meme生成器：获得模板->生成模板描述->结构化prompt生成meme文本->组合为meme->仇恨检测。|<img width="1200" alt="pipeline" src="figures/MemeCraft.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** While internet memes have evolved into potent vehicles for social and political discourse, existing generation tools often lack the capability to align content with specific ideological stances or ensure safety against hate speech. \[翻译\] 虽然网络迷因已演变为社会和政治话语的有力载体，但现有的生成工具往往缺乏将内容与特定意识形态立场对齐的能力，也难以确保内容安全以防止仇恨言论。 **[innovation]** This work proposes a novel framework utilizing off-the-shelf Large Language Models \(LLMs\) and Visual Language Models \(VLMs\) to generate advocacy-driven memes without fine-tuning, incorporating a dedicated safety mechanism to mitigate the production of hateful content. \[翻译\] 该工作提出了一个利用现成的多模态大模型（LLMs和VLMs）生成宣传性迷因的新颖框架，无需进行微调，并内置了专门的安全机制以减少仇恨内容的产生。 **[method]** The authors devise an inference-only pipeline that decouples visual processing from text generation: a VLM first converts meme templates into textual descriptions, which serve as context for an LLM conditioned on structured prompts \(e.g., stance, persuasion technique\) to synthesize humorous captions. \[翻译\] 作者设计了一个仅推理（inference-only）的流水线，将视觉处理与文本生成解耦：首先由VLM将迷因模板转换为文本描述，随后将其作为上下文，结合结构化提示（如立场、说服技巧）引导LLM合成幽默配文。 **[conclusion/contribution]** Experimental evaluations focusing on UN Sustainable Development Goals demonstrate that the approach, particularly when leveraging ChatGPT, significantly outperforms state-of-the-art baselines in terms of hilarity and persuasiveness, achieving authenticity scores comparable to human-created content. \[翻译\] 针对联合国可持续发展目标的实验评估表明，该方法（尤其是基于ChatGPT的版本）在幽默感和说服力方面显著优于最先进的基线模型，并达到了与人类创作内容相当的真实性评分。 **[limitation/future]** A notable limitation lies in the information bottleneck introduced by converting visual data into text descriptions, which may fail to capture fine-grained visual nuances or pixel-level text-image interplay compared to end-to-end multimodal training. \[翻译\] 一个显著的局限性在于将视觉数据转换为文本描述所引入的信息瓶颈，与端到端的多模态训练相比，这种方法可能难以捕捉细粒度的视觉细微差别或像素级的图文互动。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** While internet memes have evolved into potent vehicles for social and political discourse, existing generation tools often lack the capability to align content with specific ideological stances or ensure safety against hate speech.<br>\[翻译\] 虽然网络迷因已演变为社会和政治话语的有力载体，但现有的生成工具往往缺乏将内容与特定意识形态立场对齐的能力，也难以确保内容安全以防止仇恨言论。<br>**[innovation]** This work proposes a novel framework utilizing off-the-shelf Large Language Models \(LLMs\) and Visual Language Models \(VLMs\) to generate advocacy-driven memes without fine-tuning, incorporating a dedicated safety mechanism to mitigate the production of hateful content.<br>\[翻译\] 该工作提出了一个利用现成的多模态大模型（LLMs和VLMs）生成宣传性迷因的新颖框架，无需进行微调，并内置了专门的安全机制以减少仇恨内容的产生。<br>**[method]** The authors devise an inference-only pipeline that decouples visual processing from text generation: a VLM first converts meme templates into textual descriptions, which serve as context for an LLM conditioned on structured prompts \(e.g., stance, persuasion technique\) to synthesize humorous captions.<br>\[翻译\] 作者设计了一个仅推理（inference-only）的流水线，将视觉处理与文本生成解耦：首先由VLM将迷因模板转换为文本描述，随后将其作为上下文，结合结构化提示（如立场、说服技巧）引导LLM合成幽默配文。<br>**[conclusion/contribution]** Experimental evaluations focusing on UN Sustainable Development Goals demonstrate that the approach, particularly when leveraging ChatGPT, significantly outperforms state-of-the-art baselines in terms of hilarity and persuasiveness, achieving authenticity scores comparable to human-created content.<br>\[翻译\] 针对联合国可持续发展目标的实验评估表明，该方法（尤其是基于ChatGPT的版本）在幽默感和说服力方面显著优于最先进的基线模型，并达到了与人类创作内容相当的真实性评分。<br>**[limitation/future]** A notable limitation lies in the information bottleneck introduced by converting visual data into text descriptions, which may fail to capture fine-grained visual nuances or pixel-level text-image interplay compared to end-to-end multimodal training.<br>\[翻译\] 一个显著的局限性在于将视觉数据转换为文本描述所引入的信息瓶颈，与端到端的多模态训练相比，这种方法可能难以捕捉细粒度的视觉细微差别或像素级的图文互动。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]In the pursuit of deploying generative AI for specific social goals, Wang and Lee \[1\] introduce MemeCraft, a framework designed to fabricate memes advocating for UN Sustainable Development Goals \(e.g., climate action\). It functions as an end-to-end, inference-only generation framework where visual semantics are compressed into textual descriptions by a VLM to guide an LLM in generating stance-aligned captions. While this structured prompting approach ensures high controllability and safety in propagating social messages, the reliance on intermediate textual representations instead of joint multimodal embedding implies a potential granularity loss in capturing complex visual-semantic interplay.<br>\[翻译\] 在探索将生成式AI应用于特定社会目标的背景下，Wang和Lee \[1\] 推出了MemeCraft，这是一个旨在制作倡导联合国可持续发展目标（如气候行动）迷因的框架。这是一个端到端的、仅推理（inference-only）的生成框架，通过VLM将视觉语义压缩为文本描述，进而引导LLM生成与立场一致的配文。虽然这种结构化提示方法在传播社会信息时确保了高度的可控性和安全性，但依赖中间文本表示而非联合多模态嵌入的做法，也意味着在捕捉复杂的视觉-语义交互时可能存在细粒度信息的缺失。</div></details></div></div>|

### User Stance Detection (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/HITSZ-HLT/KA-Stance-Detection.svg?style=social&label=Star)](https://github.com/HITSZ-HLT/KA-Stance-Detection) [![Publish](https://img.shields.io/badge/Conference-EMNLP%202023-blue)]()<br>[Stance Detection on Social Media with Background Knowledge](https://aclanthology.org/2023.emnlp-main.972) <br> Ang Li, Bin Liang, Jingqian Zhao, Bowen Zhang, Min Yang, Ruifeng Xu <br> 2023|A retrieval-augmented stance detection framework that synthesizes LLM-refined Wikipedia facts and linguistic expansions to address the issue of stance implicitness in social media posts.<br>\[翻译\] 检索增强的立场检测框架，通过综合经LLM提炼的维基百科事实和语言扩展信息，来解决社交媒体帖子的立场隐含性问题。|<img width="1200" alt="pipeline" src="figures/KASD.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Stance detection often struggles with the brevity and implicit nature of social media texts, where conventional keyword-based retrieval methods frequently introduce noise or fail to capture the underlying sociopoli \[翻译\] 立场检测常受限于社交媒体文本的短小和隐含性，而传统的基于关键词的检索方法往往引入噪声或未能捕捉潜在的社会政治语境。 **[innovation]** Li et al. \(2023\) introduce the KASD framework, which categorizes background information into episodic \(factual\) and discourse \(linguistic\) knowledge, distinctively utilizing Large Language Models \(LLMs\) as active semantic filters and paraphrasers rather than mere predictive engines. \[翻译\] Li等人（2023）引入了KASD框架，将背景信息分类为情景知识（事实）和语篇知识（语言），其独特之处在于利用大语言模型（LLM）作为主动的语义过滤器和改写器，而不仅仅是预测引擎。 **[method]** The methodology operates at the discourse level by utilizing LLMs to expand slang and hashtags into explicit text, and at the episodic level by employing topic modeling with heuristic metrics to retrieve Wikipedia documents for LLM summarization, ultimately fusing both into a structured input for classifica \[翻译\] 语篇层面利用LLM将俚语和标签扩展为明确文本，情景层面利用主题建模和启发式度量检索维基百科文档并由LLM进行总结，最后将两者融合为结构化输入以进行分类。 **[conclusion/contribution]** Experimental results across four benchmarks demonstrate that KASD achieves state-of-the-art performance, with knowledge-augmented fine-tuned models significantly outperforming standard LLMs in both in-target and zero-shot scenarios. \[翻译\] 在四个基准测试上的实验结果表明，KASD取得了最先进的性能，经过知识增强的微调模型在目标内和零样本场景中均显著优于标准LLM。 **[limitation/future]** A primary limitation lies in the reliance on pre-crawled Wikipedia dumps, which may inhibit the detection of stances regarding real-time events or breaking news not yet documented in static knowledge bases. \[翻译\] 主要局限性在于依赖预先爬取的维基百科数据，这可能阻碍对静态知识库中尚未记录的实时事件或突发新闻的立场检测。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Stance detection often struggles with the brevity and implicit nature of social media texts, where conventional keyword-based retrieval methods frequently introduce noise or fail to capture the underlying sociopoli<br>\[翻译\] 立场检测常受限于社交媒体文本的短小和隐含性，而传统的基于关键词的检索方法往往引入噪声或未能捕捉潜在的社会政治语境。<br>**[innovation]** Li et al. \(2023\) introduce the KASD framework, which categorizes background information into episodic \(factual\) and discourse \(linguistic\) knowledge, distinctively utilizing Large Language Models \(LLMs\) as active semantic filters and paraphrasers rather than mere predictive engines.<br>\[翻译\] Li等人（2023）引入了KASD框架，将背景信息分类为情景知识（事实）和语篇知识（语言），其独特之处在于利用大语言模型（LLM）作为主动的语义过滤器和改写器，而不仅仅是预测引擎。<br>**[method]** The methodology operates at the discourse level by utilizing LLMs to expand slang and hashtags into explicit text, and at the episodic level by employing topic modeling with heuristic metrics to retrieve Wikipedia documents for LLM summarization, ultimately fusing both into a structured input for classifica<br>\[翻译\] 语篇层面利用LLM将俚语和标签扩展为明确文本，情景层面利用主题建模和启发式度量检索维基百科文档并由LLM进行总结，最后将两者融合为结构化输入以进行分类。<br>**[conclusion/contribution]** Experimental results across four benchmarks demonstrate that KASD achieves state-of-the-art performance, with knowledge-augmented fine-tuned models significantly outperforming standard LLMs in both in-target and zero-shot scenarios.<br>\[翻译\] 在四个基准测试上的实验结果表明，KASD取得了最先进的性能，经过知识增强的微调模型在目标内和零样本场景中均显著优于标准LLM。<br>**[limitation/future]** A primary limitation lies in the reliance on pre-crawled Wikipedia dumps, which may inhibit the detection of stances regarding real-time events or breaking news not yet documented in static knowledge bases.<br>\[翻译\] 主要局限性在于依赖预先爬取的维基百科数据，这可能阻碍对静态知识库中尚未记录的实时事件或突发新闻的立场检测。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[方法总结\]输入：评论和他的target->输入通过LLM将俚语简写标签扩展为完整内容->对输入进行主题建模，从维基百科中通过主题相似度和内容相似度（与评论）检索出相关知识->相关知识交由LLM进行过滤总结->生成结构化输出模板->使用输出模板进行微调或作为少样本进行立场分类\[引用文\]To bridge the gap between static text recognition and dynamic context understanding, Li et al. \(2023\) proposed the Knowledge-Augmented Stance Detection \(KASD\) framework to address the semantic scarcity of short texts. Their approach simulates a human-like reasoning process on two levels: at the discourse level, it utilizes LLMs to interpret and expand sociolinguistic cues, such as hashtags and slang, into explicit natural language; at the episodic level, it combines topic modeling with heuristic similarity metrics to retrieve relevant Wikipedia documents, which are filtered and summarized by an LLM to extract precise episodic knowledge. By fusing this refined external context with the original input for fine-tuning or few-shot inference, KASD demonstrates that guiding models with structured, retrieved knowledge yields superior performance compared to unguided generation, marking a shift towards more robust, context-aware social computing agents.<br>\[翻译\] 为了弥合静态文本识别与动态语境理解之间的鸿沟，Li等人（2023）提出了知识增强立场检测（KASD）框架，以解决短文本的语义稀缺问题。他们的方法从两个层面模拟了类人的推理过程：语篇层面，利用LLM解释并将标签、俚语等社会语言线索扩展为明确的自然语言；情景层面，结合主题建模与启发式相似度度量检索相关的维基百科文档，并通过LLM进行过滤和总结以提取精确的情景知识。通过将这种提炼后的外部语境与原始输入融合进行微调或少样本推理，KASD证明了利用结构化的检索知识引导模型比无引导的生成具有更优越的性能，这标志着向更鲁棒、具备语境感知能力的社会计算代理的转变。</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/tsinghua-fib-lab/COLA.svg?style=social&label=Star)](https://github.com/tsinghua-fib-lab/COLA) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Stance Detection with Collaborative Role-Infused LLM-Based Agents](https://ojs.aaai.org/index.php/ICWSM/article/view/31360) <br> Xiaochong Lan, Chen Gao, Depeng Jin, Yong Li <br> 2024-05-28|AMB辩论场模拟（本质上类似高级cot）|<img width="1200" alt="pipeline" src="figures/COLA.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** In addressing the dual challenges of stance detection—the need for multi-faceted textual comprehension and complex reasoning over implicit stances—this study seeks to move beyond the data dependency of traditional methods and the suboptimal direct application of Large Language Models \(LLMs\). \[翻译\] 为解决立场检测中的双重挑战——需要多层面的文本理解能力和对隐含立场的复杂推理——本研究旨在超越传统方法对数据的依赖以及直接应用大语言模型（LLM）的次优表现。 **[innovation]** The key innovation is the design of a multi-agent system \(COLA\) that simulates a debate arena, where LLM-based agents advocate for different stances, thereby transforming stance inference into a structured process of adversarial reasoning and collaborative synthesis. \[翻译\] 其核心创新在于设计了一个模拟辩论场的多智能体系统（COLA），其中基于LLM的智能体为不同立场进行辩护，从而将立场推断转化为一个对抗性推理与协作合成的结构化过程。 **[method]** The COLA framework operates in three stages: a multi-dimensional analysis by role-specific agents \(linguist, domain expert, social media veteran\), a reasoning-enhanced debate where dedicated agents argue for ‘Favor’, ‘Against’, or ‘Neutral’ stances, and a final judgment stage that synthesizes all arguments. \[翻译\] COLA框架按三阶段运行：由角色化智能体（语言学家、领域专家、社交媒体资深用户）进行多维度分析；一个推理增强的辩论阶段，由专门智能体为“支持”、“反对”或“中立”立场进行论证；以及一个综合所有论点的最终裁决阶段。 **[conclusion/contribution]** Experimental results demonstrate that this zero-shot, training-free approach achieves state-of-the-art performance, matching or surpassing models trained on in-target labeled data across multiple benchmarks, while providing explainable outputs. \[翻译\] 实验结果表明，这种零样本、无需训练的方法实现了最先进的性能，在多个基准测试中达到甚至超越了依赖靶向标注数据训练的模型，同时能提供可解释的输出。 **[limitation/future]** A primary limitation is the potential inadequacy in handling real-time events due to static LLM knowledge. Future work aims to integrate real-time knowledge retrieval and extend the multi-agent debate paradigm to broader social reasoning tasks. \[翻译\] 一个主要局限在于，由于LLM知识的静态性，其在处理实时事件时可能存在不足。未来工作旨在集成实时知识检索，并将多智能体辩论范式扩展到更广泛的社会推理任务中。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** In addressing the dual challenges of stance detection—the need for multi-faceted textual comprehension and complex reasoning over implicit stances—this study seeks to move beyond the data dependency of traditional methods and the suboptimal direct application of Large Language Models \(LLMs\).<br>\[翻译\]<br>为解决立场检测中的双重挑战——需要多层面的文本理解能力和对隐含立场的复杂推理——本研究旨在超越传统方法对数据的依赖以及直接应用大语言模型（LLM）的次优表现。<br>**[innovation]** The key innovation is the design of a multi-agent system \(COLA\) that simulates a debate arena, where LLM-based agents advocate for different stances, thereby transforming stance inference into a structured process of adversarial reasoning and collaborative synthesis.<br>\[翻译\]<br>其核心创新在于设计了一个模拟辩论场的多智能体系统（COLA），其中基于LLM的智能体为不同立场进行辩护，从而将立场推断转化为一个对抗性推理与协作合成的结构化过程。<br>**[method]** The COLA framework operates in three stages: a multi-dimensional analysis by role-specific agents \(linguist, domain expert, social media veteran\), a reasoning-enhanced debate where dedicated agents argue for ‘Favor’, ‘Against’, or ‘Neutral’ stances, and a final judgment stage that synthesizes all arguments.<br>\[翻译\]<br>COLA框架按三阶段运行：由角色化智能体（语言学家、领域专家、社交媒体资深用户）进行多维度分析；一个推理增强的辩论阶段，由专门智能体为“支持”、“反对”或“中立”立场进行论证；以及一个综合所有论点的最终裁决阶段。<br>**[conclusion/contribution]** Experimental results demonstrate that this zero-shot, training-free approach achieves state-of-the-art performance, matching or surpassing models trained on in-target labeled data across multiple benchmarks, while providing explainable outputs.<br>\[翻译\]<br>实验结果表明，这种零样本、无需训练的方法实现了最先进的性能，在多个基准测试中达到甚至超越了依赖靶向标注数据训练的模型，同时能提供可解释的输出。<br>**[limitation/future]** A primary limitation is the potential inadequacy in handling real-time events due to static LLM knowledge. Future work aims to integrate real-time knowledge retrieval and extend the multi-agent debate paradigm to broader social reasoning tasks.<br>\[翻译\]<br>一个主要局限在于，由于LLM知识的静态性，其在处理实时事件时可能存在不足。未来工作旨在集成实时知识检索，并将多智能体辩论范式扩展到更广泛的社会推理任务中。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【ABM方法】\[引用文\]Within the exploration of agent-based social interaction and emergent behavior, the work by Lan et al. \(2024\) constitutes an attempt to transition from static pattern recognition to dynamic, goal-oriented interaction simulation. Their proposed COLA framework transforms stance detection into a process of multi-agent collaborative and adversarial reasoning by constructing a “simulated debate arena” populated by role-infused LLM agents. The framework achieves excellent zero-shot performance without additional data training. Its “analyst-debater-summarizer” architecture mimics the social deliberation involved in opinion formation, serving as a prime example of how structured multi-agent interaction can be harnessed to elicit and regulate complex reasoning capabilities.<br>\[翻译\]<br>在探索基于智能体的社会性交互与涌现行为的背景下，Lan等人（2024）的工作进行了从静态模式识别向动态、目标导向交互仿真过渡的尝试。他们提出的COLA框架通过构建一个由角色化大语言模型智能体组成的“模拟辩论场”，将立场检测任务转化为一个多智能体协作推理与对抗辩论的过程。该框架在没有额外数据训练的情况下取得了优异的零样本检测性能。其“分析师-辩论家-总结者”的架构模拟了观点形成过程中的社会性思辨，是通过结构化多智能体交互来激发并规制复杂推理能力的典型例子。</div></details></div></div>|

### Malicious User Detection (5 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Pre-trained Behavioral Model for Malicious User Prediction on Social Platform](https://ojs.aaai.org/index.php/AAAI/article/view/35032) <br> Meng Jiang, Wenjie Wang, Shaofeng Hu, Kaishen Ou, Zhenjing Zheng, Fuli Feng <br> 2025-04-11|MaP is a self-supervised pre-training framework designed to extract robust representations of malicious users by modeling repetitive and sporadic anomalies in behavior sequences without relying on content analysis.<br>\[翻译\] MaP是一个自监督预训练框架，旨在通过对行为序列中的重复性和零星异常进行建模来提取鲁棒的恶意用户表示，而不依赖于内容分析。|<img width="1200" alt="pipeline" src="figures/MaP.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Current supervised methods heavily rely on scarce labeled data, while existing self-supervised approaches often fail to capture complex repetitive and sporadic camouflaged patterns in user behavior sequences. \[翻译\] 现有的监督学习方法严重依赖稀缺的标注数据，而现有的自监督方法往往难以捕捉用户行为序列中复杂的重复性模式和零星的伪装模式。 **[innovation]** Distinct from content-based approaches, this work focuses exclusively on user behavior sequences, introducing behavior consistency and local disruption augmentations to specifically target repetitive and sporadic malicious patterns. \[翻译\] 与基于内容的方法不同，该工作专注于用户行为序列，引入了行为一致性增强和局部破坏增强策略，专门针对重复性和零星的恶意行为模式。 **[method]** The framework employs a three-stage self-supervised pre-training pipeline based on BERT, integrating masked behavior reconstruction, contrastive learning for pattern recognition, and a pseudo-malicious user sampling strategy to refine representations. \[翻译\] 该框架采用基于BERT的三阶段自监督预训练流程，集成了掩码行为重建、用于模式识别的对比学习以及伪恶意用户采样策略以优化特征表示。 **[conclusion/contribution]** Evaluated on a billion-scale industrial dataset from Weixin, the model demonstrates superior performance in both malicious user detection and classification tasks compared to graph-based and sequence-based baselines, particularly in cold-start scenarios. \[翻译\] 在微信的十亿级工业数据集上进行的评估显示，该模型在恶意用户检测和分类任务中均表现出优于基于图和基于序列的基线模型的性能，尤其是在冷启动场景下。 **[limitation/future]** The current iteration relies solely on behavior ID sequences, neglecting potential semantic information from generated content and structural signals from social interaction graphs. \[翻译\] 当前版本仅依赖于行为ID序列，忽略了生成内容中潜在的语义信息以及社交互动图中的结构性信号。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Current supervised methods heavily rely on scarce labeled data, while existing self-supervised approaches often fail to capture complex repetitive and sporadic camouflaged patterns in user behavior sequences.<br>\[翻译\] 现有的监督学习方法严重依赖稀缺的标注数据，而现有的自监督方法往往难以捕捉用户行为序列中复杂的重复性模式和零星的伪装模式。<br>**[innovation]** Distinct from content-based approaches, this work focuses exclusively on user behavior sequences, introducing behavior consistency and local disruption augmentations to specifically target repetitive and sporadic malicious patterns.<br>\[翻译\] 与基于内容的方法不同，该工作专注于用户行为序列，引入了行为一致性增强和局部破坏增强策略，专门针对重复性和零星的恶意行为模式。<br>**[method]** The framework employs a three-stage self-supervised pre-training pipeline based on BERT, integrating masked behavior reconstruction, contrastive learning for pattern recognition, and a pseudo-malicious user sampling strategy to refine representations.<br>\[翻译\] 该框架采用基于BERT的三阶段自监督预训练流程，集成了掩码行为重建、用于模式识别的对比学习以及伪恶意用户采样策略以优化特征表示。<br>**[conclusion/contribution]** Evaluated on a billion-scale industrial dataset from Weixin, the model demonstrates superior performance in both malicious user detection and classification tasks compared to graph-based and sequence-based baselines, particularly in cold-start scenarios.<br>\[翻译\] 在微信的十亿级工业数据集上进行的评估显示，该模型在恶意用户检测和分类任务中均表现出优于基于图和基于序列的基线模型的性能，尤其是在冷启动场景下。<br>**[limitation/future]** The current iteration relies solely on behavior ID sequences, neglecting potential semantic information from generated content and structural signals from social interaction graphs.<br>\[翻译\] 当前版本仅依赖于行为ID序列，忽略了生成内容中潜在的语义信息以及社交互动图中的结构性信号。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【恶意用户分析（基于行为模式）】\[引用文\]To address the limitations of content reliance and the scarcity of labeled data in anomaly detection, Jiang et al. \(2025\) proposed the Malicious User Behavior Pre-training framework \(MaP\). Instead of modeling user-generated content, this approach focuses exclusively on discerning patterns within user behavior sequences. The authors introduced a three-stage self-supervised learning pipeline that incorporates specific augmentation strategies—namely behavior consistency and local disruption—to capture two distinct categories of malicious activities: repetitive automated behaviors and sporadic, camouflaged actions. By leveraging a pseudo-malicious user sampling strategy, the model effectively generates discriminative user representations from billion-scale unlabeled data, significantly enhancing detection performance in downstream tasks compared to traditional sequence modeling approaches.\[翻译\]<br>为了解决异常检测中对内容的依赖以及标注数据稀缺的局限性，Jiang等人 \(2025\) 提出了恶意用户行为预训练框架 \(MaP\)。该方法不单纯对用户生成的内容进行建模，而是专注于识别用户行为序列中的模式。作者引入了一个三阶段的自监督学习流程，结合了特定的增强策略——即行为一致性和局部破坏——以捕捉两类截然不同的恶意活动：重复的自动化行为和零星的、经过伪装的行动。通过利用伪恶意用户采样策略，该模型有效地从十亿级无标签数据中生成了具有判别力的用户表示，与传统的序列建模方法相比，显著提升了下游任务中的检测性能。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%2031st%20ACM%20International%20Conference%20on%20Multimedia-blue)]()<br>[Multi-modal social bot detection: Learning homophilic and heterophilic connections adaptively](https://dl.acm.org/doi/10.1145/3581783.3612569) <br> Shilong Li, Boyu Qiao, Kun Li, Qianqian Lu, Meng Lin, Wei Zhou <br> 2023-10-26|【争对包含机器人网络的异质性】使用节点特征相似度补充转发图中的边，确保bot的特征不会被包围他的正常用户平滑掉|<img width="1200" alt="pipeline" src="figures/BothH.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Existing graph-based detection methods largely rely on the homophily assumption, often failing to address relation camouflage, where bots establish heterophilic connections with humans to evade detection through feature smoothing. \[翻译\] 现有的基于图的检测方法很大程度上依赖于同质性假设，往往无法解决关系伪装问题，即机器人通过与人类建立异质连接，利用特征平滑来逃避检测。 **[innovation]** The study introduces an adaptive mechanism to distinguish between homophilic and heterophilic edges and constructs a node similarity graph to mitigate the isolation of bots within human-dominated neighborhoods. \[翻译\] 该研究引入了一种自适应机制来区分同质和异质边，并构建了一个节点相似性图，以缓解机器人在以人类为主的邻域中的孤立问题。 **[method]** BothH initializes multi-modal user representations using LMs and MLPs, constructs a composite graph supplemented by feature similarity, and employs an end-to-end framework that dynamically classifies edges to apply differentiated attention weights during neighbor aggregation. \[翻译\] BothH 利用语言模型和多层感知机初始化多模态用户表示，构建了由特征相似性补充的组合图，并采用端到端框架动态分类边缘，以便在邻居聚合过程中应用差异化的注意力权重。 **[conclusion/contribution]** The model achieves state-of-the-art performance across Cresci-15, MGTAB, and Twibot-20 datasets, notably attaining an F1-score of 91.27% on the highly heterophilic Twibot-20 benchmark. \[翻译\] 该模型在 Cresci-15、MGTAB 和 Twibot-20 数据集上均取得了最先进的性能，特别是在高度异质的 Twibot-20 基准测试中达到了 91.27% 的 F1 分数。 **[limitation/future]** Future work is suggested to explore the distinct connection preferences of various social bot types to further refine the heterophily-aware aggregation. \[翻译\] 未来的工作建议探索不同类型社交机器人的独特连接偏好，以进一步完善异质性感知聚合。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Existing graph-based detection methods largely rely on the homophily assumption, often failing to address relation camouflage, where bots establish heterophilic connections with humans to evade detection through feature smoothing.<br>\[翻译\] 现有的基于图的检测方法很大程度上依赖于同质性假设，往往无法解决关系伪装问题，即机器人通过与人类建立异质连接，利用特征平滑来逃避检测。<br>**[innovation]** The study introduces an adaptive mechanism to distinguish between homophilic and heterophilic edges and constructs a node similarity graph to mitigate the isolation of bots within human-dominated neighborhoods.<br>\[翻译\] 该研究引入了一种自适应机制来区分同质和异质边，并构建了一个节点相似性图，以缓解机器人在以人类为主的邻域中的孤立问题。<br>**[method]** BothH initializes multi-modal user representations using LMs and MLPs, constructs a composite graph supplemented by feature similarity, and employs an end-to-end framework that dynamically classifies edges to apply differentiated attention weights during neighbor aggregation.<br>\[翻译\] BothH 利用语言模型和多层感知机初始化多模态用户表示，构建了由特征相似性补充的组合图，并采用端到端框架动态分类边缘，以便在邻居聚合过程中应用差异化的注意力权重。<br>**[conclusion/contribution]** The model achieves state-of-the-art performance across Cresci-15, MGTAB, and Twibot-20 datasets, notably attaining an F1-score of 91.27% on the highly heterophilic Twibot-20 benchmark.<br>\[翻译\] 该模型在 Cresci-15、MGTAB 和 Twibot-20 数据集上均取得了最先进的性能，特别是在高度异质的 Twibot-20 基准测试中达到了 91.27% 的 F1 分数。<br>**[limitation/future]** Future work is suggested to explore the distinct connection preferences of various social bot types to further refine the heterophily-aware aggregation.<br>\[翻译\] 未来的工作建议探索不同类型社交机器人的独特连接偏好，以进一步完善异质性感知聚合。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[方法概括\]1.初始化用户节点表示，meta info经过MLP，语义信息经过LM和MLP，分别编码后拼接。2.构建关注图。为防止bot特征被平滑，使用相似度补充图的边。3.经过一个分类模型将图的边进行分类，区分同质和异质边。4.进行GNN的邻居聚合，同质和异质视为不同的边，分别计算权重。5.残差后进行节点分类，损失为节点分类Loss + 边分类Loss\[引用文\]Addressing the limitation of homophily assumptions in graph-based detection, Li et al. \[?\] proposed BothH to counter relation camouflage where bots mix with human neighbors. The method fuses semantic and metadata features to initialize node representations and augments the original topology with a node similarity graph to connect isolated bots. It incorporates an auxiliary edge classifier to distinguish homophilic and heterophilic connections, subsequently splitting relations to apply distinct aggregation strategies. This approach effectively prevents feature smoothing in heterophilic environments and demonstrates superior performance on benchmarks like Twibot-20.<br>\[翻译\] 中文文本：<br>针对基于图的检测中同质性假设的局限性，Li 等人 \[?\] 提出了 BothH 以应对机器人混迹于人类邻居中的关系伪装问题。该方法融合语义和元数据特征来初始化节点表示，并利用节点相似性图增强原始拓扑结构以连接孤立的机器人。它结合了一个辅助边缘分类器来区分同质和异质连接，随后拆分关系以应用不同的聚合策略。这种方法有效地防止了异质环境中的特征平滑，并在 Twibot-20 等基准测试中表现出优越的性能。</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/alceufc/rsc_model.svg?style=social&label=Star)](https://github.com/alceufc/rsc_model) [![Publish](https://img.shields.io/badge/Conference-KDD%20%2715%3A%20The%2021th%20ACM%20SIGKDD%20International%20Conference%20on%20Knowledge%20Discovery%20and%20Data%20Mining-blue)]()<br>[RSC: Mining and modeling temporal activity in social media](https://dl.acm.org/doi/10.1145/2783258.2783294) <br> Alceu Ferraz Costa, Yuto Yamaguchi, Agma Juci Machado Traina, Caetano Traina, Christos Faloutsos <br> 2015-08-10|构建了一个正常人类发帖时间特征的数学模型（时间间隔正相关性、重尾分布、24h周期性、双峰分布）。相对于传统的泊松分布更符合现实，相异度较高的用户判定为机器人。是一个**只依赖时间特征**的模型|<img width="1200" alt="pipeline" src="figures/RSC.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Existing stochastic models for human dynamics, such as Poisson processes, fail to simultaneously capture the complex temporal patterns—specifically burstiness, circadian rhythms, and heavy-tailed distributions—observed in large-scale social media data. \[翻译\] 现有的针对人类动力学的随机模型（如泊松过程）无法同时捕捉在大规模社交媒体数据中观察到的复杂时间模式，具体包括阵发性、昼夜节律和重尾分布。 **[innovation]** The paper proposes RSC, a generative model that introduces a Self-Correlated Process \(SCorr\) to incorporate memory effects into event generation, effectively modeling the positive correlation of inter-arrival times \(IAT\) that memoryless baselines ignore. \[翻译\] 该论文提出了RSC，这是一种生成模型，它引入了自相关过程（SCorr）将记忆效应纳入事件生成中，有效建模了无记忆基线模型所忽略的事件间隔时间（IAT）的正相关性 **[method]** The approach mines four statistical patterns from raw timestamps \(positive correlation, heavy tails, periodic spikes, bimodal distribution\) and employs a three-state stochastic machine \(Active, Rest, Sleep\) to generate synthetic timelines for anomaly detection. \[翻译\] 该方法从原始时间戳中挖掘出四种统计模式（正相关性、重尾、周期性峰值、双峰分布），并采用三状态随机机（活跃、休息、睡眠）来生成用于异常检测的合成时间线。 **[conclusion/contribution]** Experiments on 35 million postings demonstrate that RSC fits empirical data distributions more accurately than Self-Feeding Processes \(SFP\) and achieves over 94% precision in bot detection using solely temporal features. \[翻译\] 对3500万条帖子的实验表明，RSC在拟合经验数据分布方面比自反馈过程（SFP）更准确，并且仅使用时间特征即可实现超过94%的机器人检测精度。 **[limitation/future]** The model assumes a single, stable physiological rhythm, which may lead to false positives for accounts operated by multiple users, those employing scheduling tools, or users with extremely fragmented activity patterns lacking distinct sleep cycles. \[翻译\] 该模型假设存在单一且稳定的生理节律，对于由多人操作的账户、使用调度工具的账户，或缺乏明显睡眠周期的极度碎片化活跃用户，可能会导致误报。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Existing stochastic models for human dynamics, such as Poisson processes, fail to simultaneously capture the complex temporal patterns—specifically burstiness, circadian rhythms, and heavy-tailed distributions—observed in large-scale social media data.<br>\[翻译\] 现有的针对人类动力学的随机模型（如泊松过程）无法同时捕捉在大规模社交媒体数据中观察到的复杂时间模式，具体包括阵发性、昼夜节律和重尾分布。<br>**[innovation]** The paper proposes RSC, a generative model that introduces a Self-Correlated Process \(SCorr\) to incorporate memory effects into event generation, effectively modeling the positive correlation of inter-arrival times \(IAT\) that memoryless baselines ignore.<br>\[翻译\] 该论文提出了RSC，这是一种生成模型，它引入了自相关过程（SCorr）将记忆效应纳入事件生成中，有效建模了无记忆基线模型所忽略的事件间隔时间（IAT）的正相关性<br>**[method]** The approach mines four statistical patterns from raw timestamps \(positive correlation, heavy tails, periodic spikes, bimodal distribution\) and employs a three-state stochastic machine \(Active, Rest, Sleep\) to generate synthetic timelines for anomaly detection.<br>\[翻译\] 该方法从原始时间戳中挖掘出四种统计模式（正相关性、重尾、周期性峰值、双峰分布），并采用三状态随机机（活跃、休息、睡眠）来生成用于异常检测的合成时间线。<br>**[conclusion/contribution]** Experiments on 35 million postings demonstrate that RSC fits empirical data distributions more accurately than Self-Feeding Processes \(SFP\) and achieves over 94% precision in bot detection using solely temporal features.<br>\[翻译\] 对3500万条帖子的实验表明，RSC在拟合经验数据分布方面比自反馈过程（SFP）更准确，并且仅使用时间特征即可实现超过94%的机器人检测精度。<br>**[limitation/future]** The model assumes a single, stable physiological rhythm, which may lead to false positives for accounts operated by multiple users, those employing scheduling tools, or users with extremely fragmented activity patterns lacking distinct sleep cycles.<br>\[翻译\] 该模型假设存在单一且稳定的生理节律，对于由多人操作的账户、使用调度工具的账户，或缺乏明显睡眠周期的极度碎片化活跃用户，可能会导致误报。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]In the transition from statistical pattern recognition to generative social simulation, Costa et al. \[1\] introduced the Rest-Sleep-and-Comment \(RSC\) model. Transcending traditional memoryless baselines like Poisson processes, RSC employs a Self-Correlated Process \(SCorr\) within a three-state stochastic machine \(Active, Rest, Sleep\) to mathematically formalize human physiological rhythms. This approach allows for the generative reproduction of complex temporal dynamics—specifically positive inter-arrival time correlations, heavy tails, circadian periodicities, and bimodal distributions. By establishing a simulation-based baseline of organic behavior, the model enables a lightweight, timestamp-only anomaly detection framework where non-human actors are identified through their distributional dissimilarity to the generated human patterns.<br>\[翻译\] 在从统计模式识别向生成式社会仿真过渡的过程中，Costa等人 \[1\] 引入了 Rest-Sleep-and-Comment \(RSC\) 模型。RSC 超越了像泊松过程这样的传统无记忆基线，在一个三状态随机机（活跃、休息、睡眠）中采用了自相关过程 \(SCorr\)，以此在数学上形式化人类的生理节律。这种方法允许对复杂的时间动力学进行生成式复现——具体包括正向间隔时间相关性、重尾、昼夜周期性和双峰分布。通过建立基于仿真的自然行为基线，该模型实现了一种轻量级、仅依赖时间戳的异常检测框架，非人类行动者通过其与生成的人类模式的分布相异度被识别出来。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-IEEE%20Trans.%20Neural%20Netw.%20Learn.%20Syst.-blue)]()<br>[Dispelling the fake: Social bot detection based on edge confidence evaluation](https://ieeexplore.ieee.org/document/10530431/) <br> Boyu Qiao, Wei Zhou, Kun Li, Shilong Li, Songlin Hu <br> 2025-04|【争对包含机器人网络的异质性】BECE is a GNN-based framework that restores graph homophily by dynamically pruning unreliable human-bot connections through a Gaussian-regularized edge confidence evaluation mechanism.<br>\[翻译\] BECE是一个基于GNN的框架，它通过高斯正则化的边置信度评估机制动态剪枝不可靠的人-机连接，从而恢复图的同质性。|<img width="1200" alt="pipeline" src="figures/BECE.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Mainstream GNN-based detection methods often struggle when the homophily assumption is violated by camouflaged connections between bots and humans. These &quot;unreliable edges&quot; cause message passing mechanisms to aggregate noise, making it difficult to differentiate bot representations from genuine users. \[翻译\] 主流基于GNN的检测方法常因机器人与人类之间的伪装连接破坏同质性假设而受挫。这些“不可靠边”导致消息传递机制聚合噪声，使得难以区分机器人与真实用户的表示。 **[innovation]** The paper proposes the BECE framework, which introduces an edge confidence evaluation mechanism to dynamically identify and pr \[翻译\] 该论文提出了BECE框架，引入边置信度评估机制以动态识别并剪枝不可靠边。其核心创新在于利用参数化高斯分布将边嵌入映射到随机潜在空间，通过正则化增强了模型对特征扰动的鲁棒性。 **[method]** The method first fuses multi-modal user features using multi-head attention mechanisms. It then constructs edge representations and reconstructs them via a parameterized Gaussian distribution to predict confidence scores. Finally, unreliable edges are removed based on Bernoulli sampling before performing node classification with standard GNN encoders. \[翻译\] 该方法首先利用多头注意力机制融合多模态用户特征。随后构建边表示，并通过参数化高斯分布对其进行重构以预测置信度分数。最后，在利用标准GNN编码器进行节点分类前，基于伯努利采样移除不可靠边。 **[conclusion/contribution]** Experiments on Cresci-15, Twibot-20, and MGTAB datasets demonstrate that BECE consistently outperforms state-of-the-art baselines like BotRGCN and RGT. Additionally, the edge confidence module proves effective as a plug-in across six different GNN architectures, maintaining high performance even with limited training data \(30-50%\). \[翻译\] 在Cresci-15、Twibot-20和MGTAB数据集上的实验表明，BECE在性能上持续优于BotRGCN和RGT等先进基线方法。此外，边置信度模块作为插件在六种不同的GNN架构中均表现有效，即使在训练数据有限（30-50%）的情况下仍保持高性能。 **[limitation/future]** The model exhibits limitations in discerning heterogeneous edges when the representations of connected node pairs are highly similar, as observed in parts of the MGTAB dataset. Future work intends to leverage richer structural information to refine edge embeddings and optimization strategies. \[翻译\] 当相连节点对的表示高度相似时（如在MGTAB数据集的部分样本中），模型在识别异质边方面表现出局限性。未来工作计划利用更丰富的结构信息来优化边嵌入和策略。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Mainstream GNN-based detection methods often struggle when the homophily assumption is violated by camouflaged connections between bots and humans. These "unreliable edges" cause message passing mechanisms to aggregate noise, making it difficult to differentiate bot representations from genuine users.<br>\[翻译\] 主流基于GNN的检测方法常因机器人与人类之间的伪装连接破坏同质性假设而受挫。这些“不可靠边”导致消息传递机制聚合噪声，使得难以区分机器人与真实用户的表示。<br>**[innovation]** The paper proposes the BECE framework, which introduces an edge confidence evaluation mechanism to dynamically identify and pr<br>\[翻译\] 该论文提出了BECE框架，引入边置信度评估机制以动态识别并剪枝不可靠边。其核心创新在于利用参数化高斯分布将边嵌入映射到随机潜在空间，通过正则化增强了模型对特征扰动的鲁棒性。<br>**[method]** The method first fuses multi-modal user features using multi-head attention mechanisms. It then constructs edge representations and reconstructs them via a parameterized Gaussian distribution to predict confidence scores. Finally, unreliable edges are removed based on Bernoulli sampling before performing node classification with standard GNN encoders.<br>\[翻译\] 该方法首先利用多头注意力机制融合多模态用户特征。随后构建边表示，并通过参数化高斯分布对其进行重构以预测置信度分数。最后，在利用标准GNN编码器进行节点分类前，基于伯努利采样移除不可靠边。<br>**[conclusion/contribution]** Experiments on Cresci-15, Twibot-20, and MGTAB datasets demonstrate that BECE consistently outperforms state-of-the-art baselines like BotRGCN and RGT. Additionally, the edge confidence module proves effective as a plug-in across six different GNN architectures, maintaining high performance even with limited training data \(30-50%\).<br>\[翻译\] 在Cresci-15、Twibot-20和MGTAB数据集上的实验表明，BECE在性能上持续优于BotRGCN和RGT等先进基线方法。此外，边置信度模块作为插件在六种不同的GNN架构中均表现有效，即使在训练数据有限（30-50%）的情况下仍保持高性能。<br>**[limitation/future]** The model exhibits limitations in discerning heterogeneous edges when the representations of connected node pairs are highly similar, as observed in parts of the MGTAB dataset. Future work intends to leverage richer structural information to refine edge embeddings and optimization strategies.<br>\[翻译\] 当相连节点对的表示高度相似时（如在MGTAB数据集的部分样本中），模型在识别异质边方面表现出局限性。未来工作计划利用更丰富的结构信息来优化边嵌入和策略。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">相对于论文BothH（Multi-modal social bot detection: Learning homophilic and heterophilic connections adaptively）对异质关系进行显性的建模，该文则选择排除异质关系以防止干扰\[引用文\]Unlike BothH \[Citation\] which explicitly models heterophilic connections to adaptively extract high-pass information, Qiao et al. \[Year\] propose a subtractive strategy in their BECE model to mitigate interference. Arguing that camouflaged edges between bots and humans violate the GNN homophily assumption, they introduce an Edge Confidence Evaluation module to filter out these unreliable connections. To address the noise inherent in edge features, BECE maps edge embeddings into a parameterized Gaussian distribution, ensuring that minor feature perturbations do not compromise detection accuracy. This stochastic reconstruction allows the model to robustly identify and prune heterophilic edges via Bernoulli sampling, thereby purifying the graph structure for subsequent message passing.<br>\[翻译\] 与 BothH \[引文\] 显式建模异质连接以自适应提取高频信息的做法不同，Qiao等人 \[年份\] 在其 BECE 模型中提出了一种减法策略以减少干扰。他们认为机器人与人类之间的伪装连接破坏了GNN的同质性假设，因此引入了边置信度评估模块来过滤这些不可靠连接。为了解决边特征中固有的噪声问题，BECE将边嵌入映射为参数化高斯分布，确保微小的特征扰动不会损害检测精度。这种随机重构使得模型能够通过伯努利采样鲁棒地识别并剪枝异质边，从而为随后的消息传递净化图结构。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[BotSim: LLM-Powered Malicious Social Botnet Simulation](https://ojs.aaai.org/index.php/AAAI/article/view/33575) <br> Boyu Qiao, Kun Li\*, Wei Zhou, Shilong Li, Qianqian Lu, Songlin Hu <br> 2025-04-11|\[AI generated\] BotSim is like a digital petri dish for cultivating and studying intelligent malicious bots. \[翻译\] BotSim如同一个数字培养皿，用于培育和研究智能恶意机器人。|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] To simulate and study the threat of LLM-powered malicious social botnets for improved detection. \[翻译\] 模拟和研究由大语言模型驱动的恶意社交僵尸网络的威胁，以改进检测。 **[innovation]** \[AI generated\] Proposes BotSim, an LLM-powered framework for simulating intelligent malicious botnets and generating realistic datasets for detection benchmarking. \[翻译\] 提出了BotSim，一个利用大语言模型模拟智能恶意僵尸网络并生成用于检测基准测试的真实数据集的框架。 **[method]** \[AI generated\] Proposes BotSim, an LLM-powered simulation framework that creates a virtual social network of intelligent agent bots and human users to model malicious botnet behavior and information dissemination patterns. \[翻译\] 提出了BotSim，一个由大语言模型驱动的仿真框架，它创建一个由智能代理机器人和真实用户组成的虚拟社交网络，以模拟恶意僵尸网络的行为和信息传播模式。 **[conclusion/contribution]** \[AI generated\] BotSim-24, a highly human-like bot dataset, reveals that traditional bot detection methods underperform against advanced LLM-powered bots, underscoring the need for new detection strategies. \[翻译\] BotSim-24是一个高度类人的机器人数据集，它表明传统的机器人检测方法在面对先进的LLM驱动的机器人时表现不佳，凸显了对新检测策略的需求。 **[limitation/future]** \[AI generated\] The simulation relies on LLM capabilities and lacks real-world deployment validation. \[翻译\] 整个模拟依赖LLM能力，缺乏真实世界部署验证。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] To simulate and study the threat of LLM-powered malicious social botnets for improved detection.<br>\[翻译\]<br>模拟和研究由大语言模型驱动的恶意社交僵尸网络的威胁，以改进检测。<br>**[innovation]** \[AI generated\] Proposes BotSim, an LLM-powered framework for simulating intelligent malicious botnets and generating realistic datasets for detection benchmarking.<br>\[翻译\]<br>提出了BotSim，一个利用大语言模型模拟智能恶意僵尸网络并生成用于检测基准测试的真实数据集的框架。<br>**[method]** \[AI generated\] Proposes BotSim, an LLM-powered simulation framework that creates a virtual social network of intelligent agent bots and human users to model malicious botnet behavior and information dissemination patterns.<br>\[翻译\]<br>提出了BotSim，一个由大语言模型驱动的仿真框架，它创建一个由智能代理机器人和真实用户组成的虚拟社交网络，以模拟恶意僵尸网络的行为和信息传播模式。<br>**[conclusion/contribution]** \[AI generated\] BotSim-24, a highly human-like bot dataset, reveals that traditional bot detection methods underperform against advanced LLM-powered bots, underscoring the need for new detection strategies.<br>\[翻译\]<br>BotSim-24是一个高度类人的机器人数据集，它表明传统的机器人检测方法在面对先进的LLM驱动的机器人时表现不佳，凸显了对新检测策略的需求。<br>**[limitation/future]** \[AI generated\] The simulation relies on LLM capabilities and lacks real-world deployment validation. \[翻译\] 整个模拟依赖LLM能力，缺乏真实世界部署验证。</div></details></div>|

### | Understanding (11 papers)


### Event Extraction (6 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%202023%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing-blue)]()<br>[Event causality extraction via implicit cause-effect interactions](https://aclanthology.org/2023.emnlp-main.420) <br> Jintao Liu,Zequn Zhang,Kaiwen Wei,Zhi Guo,Xian Sun,Li Jin,Xiaoyu Li <br> 2023|通过OT强制学生模型与教师模型对齐|<img width="1200" alt="pipeline" src="figures/ICE.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 现有ECE（事件因果关系抽取）方式没有充分利用原因事件和结果事件之间的相互作用。这本可以为因果关系推理提供关键线索 **[innovation]** 论文解耦ECE的两个任务（论元抽取、结果事件预测），并使用OT进行教师模型和学生模型的细粒度对齐，增强了因果事件之间的隐式联系 **[method]** 基于模板的条件生成（输入基于模板附有特定特权信息的prompt，使预训练模型BART（基于transformer）输出基于模板的结构化的文本，用于后续微调）-&gt;教师-学生知识蒸馏（微调了两个教师模型负责不同任务：事件论元抽取、结果事件预测）-&gt;因果最优传输CEOT（相关损失并入蒸馏损失，参与蒸馏训练，学生模型与教师模型细粒度对齐） **[conclusion/contribution]** ECE任务中显著提升了性能，ECE-CCKS数据集上比此前最优方法F1值提高了8.39% **[limitation/future]** 多教师蒸馏机制和复杂的OT计算显著增加了模型训练阶段的成本">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 现有ECE（事件因果关系抽取）方式没有充分利用原因事件和结果事件之间的相互作用。这本可以为因果关系推理提供关键线索<br>**[innovation]** 论文解耦ECE的两个任务（论元抽取、结果事件预测），并使用OT进行教师模型和学生模型的细粒度对齐，增强了因果事件之间的隐式联系<br>**[method]** 基于模板的条件生成（输入基于模板附有特定特权信息的prompt，使预训练模型BART（基于transformer）输出基于模板的结构化的文本，用于后续微调）->教师-学生知识蒸馏（微调了两个教师模型负责不同任务：事件论元抽取、结果事件预测）->因果最优传输CEOT（相关损失并入蒸馏损失，参与蒸馏训练，学生模型与教师模型细粒度对齐）<br>**[conclusion/contribution]** ECE任务中显著提升了性能，ECE-CCKS数据集上比此前最优方法F1值提高了8.39%<br>**[limitation/future]** 多教师蒸馏机制和复杂的OT计算显著增加了模型训练阶段的成本</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">?这个方法为什么可以解决问题？<br>    核心方法是使用优秀的专家模型对小模型进行微调，结合了5个小损失函数（两个来源于OT），以尽可能保证知识迁移效果<br><br>?有什么值得注意的细节吗？<br>    ??论文为什么选择训练两个承担不同任务的教师模型，一起蒸馏出目标模型的方法<br>        这几乎是进行微调特化用于该下游任务的必然选择<br>        因为需要训练两个能力（子任务）：文本论元抽取能力（事件内交互）和事件结果联系能力（事件间）<br>        两个子任务需要分别调整数据集的输入，为他们分配不同的特权信息，从而避免混淆和出现“作弊”（看到这个子任务不应看到的特权信息）</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/social-info-lab/disaster_event_analysis.svg?style=social&label=Star)](https://github.com/social-info-lab/disaster_event_analysis) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Identifying and Investigating Global News Coverage of Critical Events Such as Disasters and Terro...](https://ojs.aaai.org/index.php/ICWSM/article/view/35818) <br> Erica Cai1,Xi Chen1,Reagan Grey Keeney1,Ethan Zuckerman1,Brendan O'Connor1,Przemyslaw A.Grabowicz <br> 2025-06-07|两级匹配筛选要求新闻，关键词匹配初步筛选（关键词通过启发式方法获得）->事件抽取|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FAME.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/FAME2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Traditional computational studies of news coverage bias are hindered by the inability to efficiently and accurately identify articles discussing the same real-world event across massive, multilingual corpora without costly, language-specific training data. \[翻译\] 传统的新闻覆盖偏见计算研究面临一个瓶颈：难以在不依赖昂贵且语言特定的训练数据前提下，高效、精确地从大规模多语言语料库中识别出讨论同一现实事件的报道。 **[innovation]** It introduces FAME, a scalable, zero-shot framework that utilizes minimalist “event fingerprints” \(time, location, class\) to match news articles across languages via a two-stage screening pipeline, eliminating the need for annotated training data. \[翻译\] 其提出了FAME框架，这是一个可扩展的零样本方法。它利用极简的“事件指纹”（时间、地点、类别），通过一个两级筛选流程实现跨语言新闻文章匹配，从而无需标注训练数据。 **[method]** The method employs a two-stage pipeline: 1\) Heuristic keyword filtering to recall candidate articles within a time window, followed by 2\) a semantic filter using a large language model \(LLM\) for question-answering to achieve high-precision event-article matching. \[翻译\] 该方法采用一个两级处理流程：1）基于关键词的启发式过滤，用于在时间窗口内召回候选文章；2）利用大语言模型进行问答的语义过滤器，以实现高精度的事件-文章匹配。 **[conclusion/contribution]** FAME achieved state-of-the-art performance \(average F1 &gt; 94% across English, Spanish, and French\), and its application revealed that media attention to disasters and terrorist attacks is strongly correlated with death tolls, the GDP of the affected country, and bilateral trade volume. \[翻译\] FAME取得了先进的性能（在英、西、法语上平均F1&gt;94%）。应用该方法发现，媒体对灾害和恐怖袭击的关注度，与死亡人数、受影响国家的GDP以及双边贸易额高度相关。 **[limitation/future]** The reliance on a two-stage screening pipeline depends on the quality of external event databases \(e.g., GTD\), and the minimalist fingerprint design, while enabling scalability, can lead to ambiguities for events with similar metadata. \[翻译\] 两级筛选流程依赖于外部事件数据库（如GTD）的质量，且极简的指纹设计虽然保证了可扩展性，但可能导致具有相似元数据的事件产生匹配歧义。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Traditional computational studies of news coverage bias are hindered by the inability to efficiently and accurately identify articles discussing the same real-world event across massive, multilingual corpora without costly, language-specific training data.<br>\[翻译\] 传统的新闻覆盖偏见计算研究面临一个瓶颈：难以在不依赖昂贵且语言特定的训练数据前提下，高效、精确地从大规模多语言语料库中识别出讨论同一现实事件的报道。<br>**[innovation]** It introduces FAME, a scalable, zero-shot framework that utilizes minimalist “event fingerprints” \(time, location, class\) to match news articles across languages via a two-stage screening pipeline, eliminating the need for annotated training data.<br>\[翻译\] 其提出了FAME框架，这是一个可扩展的零样本方法。它利用极简的“事件指纹”（时间、地点、类别），通过一个两级筛选流程实现跨语言新闻文章匹配，从而无需标注训练数据。<br>**[method]** The method employs a two-stage pipeline: 1\) Heuristic keyword filtering to recall candidate articles within a time window, followed by 2\) a semantic filter using a large language model \(LLM\) for question-answering to achieve high-precision event-article matching.<br>\[翻译\] 该方法采用一个两级处理流程：1）基于关键词的启发式过滤，用于在时间窗口内召回候选文章；2）利用大语言模型进行问答的语义过滤器，以实现高精度的事件-文章匹配。<br>**[conclusion/contribution]** FAME achieved state-of-the-art performance \(average F1 > 94% across English, Spanish, and French\), and its application revealed that media attention to disasters and terrorist attacks is strongly correlated with death tolls, the GDP of the affected country, and bilateral trade volume.<br>\[翻译\] FAME取得了先进的性能（在英、西、法语上平均F1>94%）。应用该方法发现，媒体对灾害和恐怖袭击的关注度，与死亡人数、受影响国家的GDP以及双边贸易额高度相关。<br>**[limitation/future]** The reliance on a two-stage screening pipeline depends on the quality of external event databases \(e.g., GTD\), and the minimalist fingerprint design, while enabling scalability, can lead to ambiguities for events with similar metadata.<br>\[翻译\] 两级筛选流程依赖于外部事件数据库（如GTD）的质量，且极简的指纹设计虽然保证了可扩展性，但可能导致具有相似元数据的事件产生匹配歧义。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]Cai et al. \(2025\) propose the FAME framework, aiming to efficiently and accurately identify news reports on specific events from massive, multilingual news streams. Its innovation lies in a two-stage, zero-shot methodology. The framework first applies heuristic filtering using event “fingerprints” \(time, location, category\) to retrieve candidate articles, followed by a refinement step leveraging an LLM for precise event-article matching. This approach enables scalable, training-free analysis, successfully linking over 27,000 articles to 470 global events.<br>\[翻译\]<br>Cai等人\(2025\)提出的FAME框架，旨在从海量、多语言的新闻流中高效、精确地识别出关于特定事件的报道，其创新在于一种两级、零样本的方法。它首先使用事件“指纹”（时间、地点、类别）进行启发式过滤以获取候选文章，随后通过基于LLM进行事件匹配。这实现了可扩展的、免训练的分析，成功将超过2.7万篇文章与470个全球事件关联起来。</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/shiqinghuayi19/LLMforEvent.svg?style=social&label=Star)](https://github.com/shiqinghuayi19/LLMforEvent) [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Is a Large Language Model a Good Annotator for Event Extraction?](https://ojs.aaai.org/index.php/AAAI/article/view/29730) <br> Ruirui Chen1,Chengwei Qin,Weifeng Jiang,Dongkyu Choi <br> 2024-03-24|\[AI generated\] This method uses LLMs as expert annotators to generate high-quality training data, akin to employing a master chef to prepare ingredients for a specialized dish. \[翻译\]该方法利用大语言模型作为专家标注员生成高质量训练数据，如同聘请主厨为特色菜肴准备食材。|<img width="1200" alt="pipeline" src="figures/Annotator for Event Extraction.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 在提示中使用上下文示例来引导大语言模型生成与目标基准数据集分布和标注模式对齐的新样本，从而直接解决数据不平衡问题。 **[innovation]** \[AI generated\] Employing LLMs as expert annotators with in-context examples to generate distribution-aligned data, directly addressing data scarcity and imbalance. \[翻译\] 利用大语言模型作为专家标注器，结合上下文示例生成分布对齐的数据，直接解决数据稀缺与不平衡问题。 **[method]** 针对“训练样本稀少的（长尾）事件类型，使用合适的prompt模板（包含真实例子）要求LLM生成标注，进行质量筛选，合并到原始数据集，最终通过实验与合并前的效果比较 **[conclusion/contribution]** Fine-tuning models like BERT-CRF on the GPT-4-augmented ACE 2005 data led to consistent F1-score improvements in both Event Detection and Argument Extraction tasks, proving the high utility of LLM-generated annotations as a training resource. \[翻译\] 在GPT-4增强的ACE 2005数据上微调BERT-CRF等模型，在事件检测和论元抽取任务中均带来了F1分数的持续提升，证明了LLM生成的标注作为训练资源的高效用。 **[limitation/future]** 高度依赖LLM自身能力">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 在提示中使用上下文示例来引导大语言模型生成与目标基准数据集分布和标注模式对齐的新样本，从而直接解决数据不平衡问题。<br>**[innovation]** \[AI generated\] Employing LLMs as expert annotators with in-context examples to generate distribution-aligned data, directly addressing data scarcity and imbalance.<br>\[翻译\]<br>利用大语言模型作为专家标注器，结合上下文示例生成分布对齐的数据，直接解决数据稀缺与不平衡问题。<br>**[method]** 针对“训练样本稀少的（长尾）事件类型，使用合适的prompt模板（包含真实例子）要求LLM生成标注，进行质量筛选，合并到原始数据集，最终通过实验与合并前的效果比较<br>**[conclusion/contribution]** Fine-tuning models like BERT-CRF on the GPT-4-augmented ACE 2005 data led to consistent F1-score improvements in both Event Detection and Argument Extraction tasks, proving the high utility of LLM-generated annotations as a training resource.<br>\[翻译\]<br>在GPT-4增强的ACE 2005数据上微调BERT-CRF等模型，在事件检测和论元抽取任务中均带来了F1分数的持续提升，证明了LLM生成的标注作为训练资源的高效用。<br>**[limitation/future]** 高度依赖LLM自身能力</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]To overcome data scarcity in specialized tasks within event extraction, large language models \(LLMs\) can be utilized as data augmentation tools. The work by Chen et al. \(2024\) exemplifies this by employing LLMs as structured annotators: using few-shot prompting with models such as GPT-4, they generate synthetic training data aligned with target schemas. This augmentation strategy effectively alleviates long-tail data imbalance and delivers measurable performance improvements for downstream extraction models.<br>\[翻译\]<br>为克服事件抽取领域专业任务中的数据稀缺问题，可以将大语言模型作为数据增强工具。Chen等人\(2024\)的研究通过将大语言模型用作结构化标注器来展示这一点：他们使用少量示例提示GPT-4等模型，生成与目标模式对齐的合成训练数据。这种增强策略有效缓解了长尾数据不平衡问题，为下游抽取模型带来了可观的性能提升。</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/RingBDStack/FinEvent.svg?style=social&label=Star)](https://github.com/RingBDStack/FinEvent) [![Publish](https://img.shields.io/badge/Conference-IEEE%20Transactions%20on%20Pattern%20Analysis%20and%20Machine%20Intelligence-blue)]()<br>[Reinforced, Incremental and Cross-Lingual Event Detection From Social Messages](https://ieeexplore.ieee.org/document/9693189/) <br> Hao Peng,Ruitong Zhang,Shaoning Li,Yuwei Cao,Shirui Pan,Philip S. Yu <br> 2023-01-01|\[AI generated\] FinEvent is like a multilingual, self-optimizing news curator that continuously learns and adapts from live social media streams. \[翻译\] FinEvent 如同一个多语言的、自优化的新闻策展人，能从实时社交媒体流中持续学习与适应。|<img width="1200" alt="pipeline" src="figures/FinEvent.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Event detection in social media streams is challenged by ambiguous event features, dispersed text content, multilingualism, and long-tail distribution, where traditional methods struggle in dynamic, incremental, and cross-lingual scenarios. \[翻译\] 社交媒体流中的事件检测面临事件特征模糊、文本内容分散、多语言和长尾分布等挑战，传统方法在动态、增量和跨语言场景中表现不佳。 **[innovation]** Its core advancement lies in enabling continuous, cross-lingual social event detection through a life-cycle mechanism that dynamically updates both the message graph and model without full retraining. \[翻译\] 其核心进步在于，通过一个能动态更新消息图与模型而无需全量重训练的生命周期机制，实现了持续的、跨语言的社交事件检测。 **[method]** The pipeline includes: \(1\) constructing a weighted multi-relational graph from social messages; \(2\) using multi-agent reinforcement learning to learn relation-specific thresholds for neighbor selection and aggregation; \(3\) training with balanced sampling-based contrastive learning; \(4\) clustering via DRL-optimized DBSCAN; and \(5\) enabling incremental updates and cross-lingual transfer via parameter preservation. \[翻译\] 流程包括：\(1\) 从社交消息构建加权多关系图；\(2\) 使用多智能体强化学习学习关系特定的阈值以进行邻居选择和聚合；\(3\) 通过基于平衡采样的对比学习训练；\(4\) 使用DRL优化的DBSCAN聚类；\(5\) 通过参数保留支持增量更新和跨语言迁移。 **[conclusion/contribution]** On Twitter streams, FinEvent significantly outperforms baselines in offline, online, and cross-lingual detection tasks, with improvements of 14%-118% in NMI, 8%-170% in AMI, and 2%-21% in ARI, demonstrating robust performance across diverse settings. \[翻译\] 在Twitter流数据上，FinEvent在离线、在线和跨语言检测任务中显著优于基线，NMI提升14%-118%，AMI提升8%-170%，ARI提升2%-21%，展现了在不同设置下的鲁棒性能。 **[limitation/future]** Limitations include high computational complexity, dependence on external translation for low-resource languages, potential knowledge forgetting during incremental updates, and limited generalization due to evaluation primarily on Twitter data. \[翻译\] 局限性包括计算复杂度高、对低资源语言依赖外部翻译、增量更新中可能遗忘早期知识，以及由于主要基于Twitter数据评估导致的泛化性有限。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Event detection in social media streams is challenged by ambiguous event features, dispersed text content, multilingualism, and long-tail distribution, where traditional methods struggle in dynamic, incremental, and cross-lingual scenarios.<br>\[翻译\]<br>社交媒体流中的事件检测面临事件特征模糊、文本内容分散、多语言和长尾分布等挑战，传统方法在动态、增量和跨语言场景中表现不佳。<br>**[innovation]** Its core advancement lies in enabling continuous, cross-lingual social event detection through a life-cycle mechanism that dynamically updates both the message graph and model without full retraining.<br>\[翻译\]<br>其核心进步在于，通过一个能动态更新消息图与模型而无需全量重训练的生命周期机制，实现了持续的、跨语言的社交事件检测。<br>**[method]** The pipeline includes: \(1\) constructing a weighted multi-relational graph from social messages; \(2\) using multi-agent reinforcement learning to learn relation-specific thresholds for neighbor selection and aggregation; \(3\) training with balanced sampling-based contrastive learning; \(4\) clustering via DRL-optimized DBSCAN; and \(5\) enabling incremental updates and cross-lingual transfer via parameter preservation.<br>\[翻译\]<br>流程包括：\(1\) 从社交消息构建加权多关系图；\(2\) 使用多智能体强化学习学习关系特定的阈值以进行邻居选择和聚合；\(3\) 通过基于平衡采样的对比学习训练；\(4\) 使用DRL优化的DBSCAN聚类；\(5\) 通过参数保留支持增量更新和跨语言迁移。<br>**[conclusion/contribution]** On Twitter streams, FinEvent significantly outperforms baselines in offline, online, and cross-lingual detection tasks, with improvements of 14%-118% in NMI, 8%-170% in AMI, and 2%-21% in ARI, demonstrating robust performance across diverse settings.<br>\[翻译\]<br>在Twitter流数据上，FinEvent在离线、在线和跨语言检测任务中显著优于基线，NMI提升14%-118%，AMI提升8%-170%，ARI提升2%-21%，展现了在不同设置下的鲁棒性能。<br>**[limitation/future]** Limitations include high computational complexity, dependence on external translation for low-resource languages, potential knowledge forgetting during incremental updates, and limited generalization due to evaluation primarily on Twitter data.<br>\[翻译\]<br>局限性包括计算复杂度高、对低资源语言依赖外部翻译、增量更新中可能遗忘早期知识，以及由于主要基于Twitter数据评估导致的泛化性有限。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]Peng et al. \(2023\) proposed FinEvent, a reinforced, incremental, and cross-lingual detection architecture. Its core innovation lies in a life-cycle learning mechanism that supports incremental adaptation: the system dynamically updates a multi-relational message graph, employs multi-agent reinforcement learning to continuously optimize aggregation strategies, and utilizes a DRL-optimized clustering module to self-adjust parameters for each data block—enabling the model to co-evolve with the social data stream.<br><br>\[翻译\]<br>Peng等人（2023）提出了FinEvent，一个强化的增量与跨语言检测架构。其核心创新在于一个支持增量适应的生命周期学习机制：系统动态更新多关系消息图，并采用多智能体强化学习持续优化聚合策略，同时通过DRL优化的聚类模块实现每个数据块的自调参，使模型能随社交数据流共同演化。\[notes\]根据消息间的多种语义关系构建异构消息网络网络->通过多智能体强化学习得到每个关系的保留阈值（多智能体强化指的是每个智能体负责一个关系），对于每个消息节点的每个关系图，通过保留阈值剪除掉对聚合作用低的邻居节点->先图内聚合，再图间聚合得到每个节点的特征向量->使用Triplet Loss（拉近同类消息、推远异类消息）和Global-Local Loss（保持图结构的全局一致性）两个损失函数进行GNN训练，得到不同事件区分能力->使用DRL-DBSCAN进行自适应聚类，得到事件分类输出->支持增量更新与跨语言迁移</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Towards Effective, Efficient and Unsupervised Social Event Detection in the Hyperbolic Space](https://ojs.aaai.org/index.php/AAAI/article/view/33430) <br> Xiaoyan Yu,Yifan Wei,Shuaishuai Zhou,Zhiwei Yang,Li Sun,Hao Peng,Liehuang Zhu\*,Philip S. Yu <br> 2025-04-11|通过两层压缩减少开销（简化边、节点聚合为锚点），通过划分树表示事件聚类|<img width="1200" alt="pipeline" src="figures/HyperSED.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures. \[翻译\]：由于用户生成内容规模庞大、动态性强且关系结构复杂，社交媒体平台上的社交事件检测面临显著挑战。现有方法在处理海量消息流时常效率低下，且在捕捉层次化事件结构方面表达能力有限。 **[innovation]** The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanism—semantic-based anchor construction and graph sparsification—and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts. \[翻译\]：本文提出HyperSED，一种新颖的无监督框架，通过基于语义的锚点构建与图稀疏化两阶段压缩机制降低计算开销，并利用在双曲空间中学习的可微划分树表示事件聚类。该方法无需预设聚类数量，即可有效捕捉层次化与嵌套的事件结构。 **[method]** The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters. \[翻译\]：该框架首先构建语义锚点图以压缩消息节点并简化关系边，随后将锚点图映射至双曲空间，采用双曲图自编码器学习结构感知表示，最终通过可微结构信息最小化构建并优化划分树，得到层次化事件簇 **[conclusion/contribution]** Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines. \[翻译\]：在真实Twitter数据集上的实验表明，HyperSED在归一化互信息、调整互信息与调整兰德指数上均取得具有竞争力的性能，同时相比前沿无监督基线，计算效率提升最高达37倍。 **[limitation/future]** The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control. \[翻译\]：由于锚点构建中可能出现语义不同消息被错误分组的情况，该模型在部分消息块上的性能可能略有下降。此外，效率提升在一定程度上以聚类粒度控制的精细度为代价。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Social event detection on social media platforms faces significant challenges due to the large scale, dynamic nature, and complex relational structures inherent in user-generated content. Existing methods often suffer from inefficiency in processing massive message streams and limited expressive power in capturing hierarchical event structures.<br>\[翻译\]：由于用户生成内容规模庞大、动态性强且关系结构复杂，社交媒体平台上的社交事件检测面临显著挑战。现有方法在处理海量消息流时常效率低下，且在捕捉层次化事件结构方面表达能力有限。<br>**[innovation]** The paper introduces HyperSED, a novel unsupervised framework that reduces computational overhead through a two-stage compression mechanism—semantic-based anchor construction and graph sparsification—and represents event clusters via a differentiable partitioning tree learned in hyperbolic space. This approach effectively captures hierarchical and nested event structures without requiring predefined cluster counts.<br>\[翻译\]：本文提出HyperSED，一种新颖的无监督框架，通过基于语义的锚点构建与图稀疏化两阶段压缩机制降低计算开销，并利用在双曲空间中学习的可微划分树表示事件聚类。该方法无需预设聚类数量，即可有效捕捉层次化与嵌套的事件结构。<br>**[method]** The framework first constructs a semantic anchor graph to compress message nodes and simplify relational edges. It then maps the anchor graph into hyperbolic space and employs a hyperbolic graph autoencoder to learn structure-aware representations. Finally, a partitioning tree is built and optimized via differentiable structural information minimization, yielding hierarchical event clusters.<br>\[翻译\]：该框架首先构建语义锚点图以压缩消息节点并简化关系边，随后将锚点图映射至双曲空间，采用双曲图自编码器学习结构感知表示，最终通过可微结构信息最小化构建并优化划分树，得到层次化事件簇<br>**[conclusion/contribution]** Experiments on real-world Twitter datasets demonstrate that HyperSED achieves competitive performance in normalized mutual information, adjusted mutual information, and adjusted Rand index, while improving computational efficiency by up to 37 times compared to state-of-the-art unsupervised baselines.<br>\[翻译\]：在真实Twitter数据集上的实验表明，HyperSED在归一化互信息、调整互信息与调整兰德指数上均取得具有竞争力的性能，同时相比前沿无监督基线，计算效率提升最高达37倍。<br>**[limitation/future]** The performance may marginally decline in some message blocks due to potential errors in anchor construction, where semantically distinct messages are incorrectly grouped. Additionally, the efficiency gains come with a slight trade-off in clustering granularity control.<br>\[翻译\]：由于锚点构建中可能出现语义不同消息被错误分组的情况，该模型在部分消息块上的性能可能略有下降。此外，效率提升在一定程度上以聚类粒度控制的精细度为代价。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]为什么用双曲空间？ 现实世界的事件和话题往往具有层次结构（如“体育 -> 足球 -> 世界杯”）。双曲空间的几何特性（指数级增长的空间）能更自然、更紧凑地嵌入这种树状或层次化数据。<br>\[通俗核心\]通过消息各属性的相同性（用户、标签）构建网络；通过方法精简网络边【压缩1】；根据相关性将相似信息聚类为锚点，锚点之间有节点相连的构建边，得到锚点图【压缩2】；映射到双曲空间进行自监督重建训练（图自编码器GAE）获得聚合模型；模型输出根据特征向量距离自底向上聚合形成划分树，该树即表示消息各层级聚类关系。每个聚类节点都代表了一个某层级事件（如体育、世界杯、新冠）\[引用文\]HyperSED demonstrates how structural and geometric inductive biases can be integrated into scalable unsupervised learning \(Yu et al., 2025\). By compressing the message graph into semantic anchors and learning a partitioning tree in hyperbolic space—where internal nodes formed through bottom?up aggregation represent concrete event categories—the framework not only enhances detection efficiency but also captures the multi?scale organization of social events.<br><br>\[翻译\]HyperSED展示了如何将结构与几何归纳偏置融入可扩展的无监督学习（Yu et al., 2025）。该框架通过将消息图压缩为语义锚点，并在双曲空间中学习划分树——其中通过自底向上聚合形成的内部节点代表具体的事件类别——不仅提升了检测效率，还捕捉了社交事件的多尺度组织特征。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Neural%20Information%20Processing-blue)]()<br>[A Three-Stage Framework for Event-Event Relation Extraction with Large Language Model](https://link.springer.com/10.1007/978-981-99-8181-6_33) <br> Feng Huang,Qiang Huang,YueTong Zhao,ZhiXiao Qi,BingKun Wang,YongFeng Huang,SongBin Li <br> 2024|通过结构化prompt构建的，无训练零样本的，依赖于本地知识库的，事件抽取方法|<img width="1200" alt="pipeline" src="figures/ThreeEERE.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks. \[翻译\] 传统事件关系提取方法严重依赖标注数据，成本高且难以扩展。大语言模型在时序与因果关系任务中的零样本能力尚未充分挖掘。 **[innovation]** A three-stage framework \(ThreeEERE\) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training. \[翻译\] 提出三阶段框架ThreeEERE，融合改进的Auto-CoT提示策略与本地知识检索，实现无需任务特定训练的零样本事件-关系提取。 **[method]** 构建示范样例（包含cot部分）-&gt;检索本地知识-&gt;取高于阈值的答案 **[conclusion/contribution]** ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets. \[翻译\] 在多个数据集上的事件、时序与因果关系提取任务中，ThreeEERE优于标准提示方法，并达到或超越若干监督基线。 **[limitation/future]** Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base. \[翻译\] 示范中生成的推理链与标准答案之间可能存在不一致，可能引入噪声并影响模型稳定性。且依赖于本地知识库构建">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Traditional event relation extraction methods rely heavily on annotated data, which is costly and difficult to scale. The zero-shot capability of large language models remains underexplored for temporal and causal relation tasks.<br>\[翻译\]<br>传统事件关系提取方法严重依赖标注数据，成本高且难以扩展。大语言模型在时序与因果关系任务中的零样本能力尚未充分挖掘。<br>**[innovation]** A three-stage framework \(ThreeEERE\) is proposed, integrating an improved Auto-CoT prompting strategy with local knowledge retrieval to enable zero-shot event-event relation extraction without task-specific training.<br>\[翻译\]<br>提出三阶段框架ThreeEERE，融合改进的Auto-CoT提示策略与本地知识检索，实现无需任务特定训练的零样本事件-关系提取。<br>**[method]** 构建示范样例（包含cot部分）->检索本地知识->取高于阈值的答案<br>**[conclusion/contribution]** ThreeEERE outperforms standard prompting methods and matches or surpasses several supervised baselines in event, temporal, and causal relation extraction across multiple datasets.<br>\[翻译\]<br>在多个数据集上的事件、时序与因果关系提取任务中，ThreeEERE优于标准提示方法，并达到或超越若干监督基线。<br>**[limitation/future]** Potential inconsistency between generated reasoning chains and gold answers in demonstrations may introduce noise and affect model stability.And it relies on the construction of a local knowledge base.<br>\[翻译\]<br>示范中生成的推理链与标准答案之间可能存在不一致，可能引入噪声并影响模型稳定性。且依赖于本地知识库构建</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[notes\]聚类只是为了选择最接近聚类中心的测试样本，作为示范样例（因为接近中心意味着更能代表该聚类语义特征），之后的操作就是输入测试样例和这些示范样例（答案部分替换为标准答案）以及检索得到的本地知识，最终取超过阈值的结果<br>\[引用文\]The three-stage framework proposed by Huang et al. \(2024\) integrates chain-of-thought reasoning with localized knowledge, demonstrating the feasibility of eliciting zero-shot inference of complex event relations from large language models through meticulously designed prompts, without the need for supervised fine-tuning.<br>\[翻译\]<br>Huang等人（2024）提出的三阶段框架，将思维链推理与本地化知识相结合，证明了通过精心设计的提示词，无需监督微调即可从大语言模型中激发出对复杂事件关系的零样本推断能力。</div></details></div></div>|

### Social Psychological Phenomena Analysis (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/Liskie/cognitive-fixation-evaluation.svg?style=social&label=Star)](https://github.com/Liskie/cognitive-fixation-evaluation) [![Publish](https://img.shields.io/badge/Conference-EMNLP%202025%EF%BC%88arxiv%E7%89%88%E6%9C%AC%EF%BC%89-blue)]()<br>[Evaluating cognitive-behavioral fixation via multimodal user viewing patterns on social media](http://arxiv.org/abs/2509.04823) <br> Yujie Wang, Yunwei Zhao, Jing Yang, Han Han, Shiguang Shan, Jie Zhang <br> 2025-09-05|固化检测，评估用户注意力是否集中于狭窄领域，因此主要先对用户关注历史主题建模，然后聚类|<img width="1200" alt="pipeline" src="figures/CBF-Eval.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** It addresses the risk of cognitive-behavioral fixation \(e.g., echo chambers, compulsive engagement\) shaped by algorithmic curation on social media, which lacks scalable computational assessment methods. 它旨在解决由社交媒体算法策展所引发的认知行为固化（如信息茧房、强迫性参与）风险，该领域此前缺乏可扩展的计算评估方法。 **[innovation]** It proposes the first computational framework to quantify attention fixation by hierarchically modeling user interests from multimodal data \(text and video\) and integrating diversity, dominance, and recurrence metrics. 它首次提出了一个计算框架，通过对多模态数据（文本和视频）进行用户兴趣的层次化建模，并综合多样性、主导性和复现性指标，以量化注意力固化。 **[method]** The framework first extracts fine-grained topic phrases from multimodal content, then clusters them into higher-level thematic categories to model user attention history. Fixation is quantified by a composite score fusing entropy \(diversity\), HHI \(dominance\), and burstiness \(recurrence\). 该框架首先从多模态内容中提取细粒度主题短语，随后将其聚类为高层主题类别以建模用户注意力历史。固化程度通过一个融合了熵（多样性）、HHI指数（主导性）和突发性（复现性）的复合分数进行量化。 **[conclusion/contribution]** The method outperforms baselines in topic modeling on multimodal datasets. On a real-world browsing dataset \(XUB\), it identified 8.59% of users with strong fixation tendencies, validated by human annotations \(F1 ≈ 0.857\). 该方法在多模态数据集的主题建模上优于基线。在一个真实浏览数据集\(XUB\)上，它识别出8.59%的用户具有强固化倾向，并得到了人工标注的验证（F1 ≈ 0.857）。Limitations include modality constraints \(lacking audio/interaction data\), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization. 局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。 **[limitation/future]** Limitations include modality constraints \(lacking audio/interaction data\), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization. 局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** It addresses the risk of cognitive-behavioral fixation \(e.g., echo chambers, compulsive engagement\) shaped by algorithmic curation on social media, which lacks scalable computational assessment methods.<br>它旨在解决由社交媒体算法策展所引发的认知行为固化（如信息茧房、强迫性参与）风险，该领域此前缺乏可扩展的计算评估方法。<br>**[innovation]** It proposes the first computational framework to quantify attention fixation by hierarchically modeling user interests from multimodal data \(text and video\) and integrating diversity, dominance, and recurrence metrics.<br>它首次提出了一个计算框架，通过对多模态数据（文本和视频）进行用户兴趣的层次化建模，并综合多样性、主导性和复现性指标，以量化注意力固化。<br>**[method]** The framework first extracts fine-grained topic phrases from multimodal content, then clusters them into higher-level thematic categories to model user attention history. Fixation is quantified by a composite score fusing entropy \(diversity\), HHI \(dominance\), and burstiness \(recurrence\).<br>该框架首先从多模态内容中提取细粒度主题短语，随后将其聚类为高层主题类别以建模用户注意力历史。固化程度通过一个融合了熵（多样性）、HHI指数（主导性）和突发性（复现性）的复合分数进行量化。<br>**[conclusion/contribution]** The method outperforms baselines in topic modeling on multimodal datasets. On a real-world browsing dataset \(XUB\), it identified 8.59% of users with strong fixation tendencies, validated by human annotations \(F1 ≈ 0.857\).<br>该方法在多模态数据集的主题建模上优于基线。在一个真实浏览数据集\(XUB\)上，它识别出8.59%的用户具有强固化倾向，并得到了人工标注的验证（F1 ≈ 0.857）。Limitations include modality constraints \(lacking audio/interaction data\), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization.<br>局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。<br>**[limitation/future]** Limitations include modality constraints \(lacking audio/interaction data\), potential biases from underlying vision-language models, and equal weighting in the composite score awaiting further optimization.<br>局限性包括模态限制（缺乏音频/交互数据）、底层视觉-语言模型的潜在偏差，以及复合分数中等权设置有待进一步优化。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]To computationally assess how platform algorithms may narrow user attention, Wang et al. \(2025\) propose a novel framework for evaluating cognitive-behavioral fixation. They first employ multimodal hierarchical topic modeling to extract and cluster thematic interests from users' viewing histories. Then, they quantify fixation by integrating metrics of topical diversity, dominance, and temporal recurrence into a unified score. Validated on a dedicated dataset, this approach provides an interpretable measure for identifying users trapped in narrow engagement loops, offering a tool for individual-level behavioral modeling within larger social simulations.<br>\[翻译\]<br>为了从计算角度评估平台算法如何收窄用户注意力，Wang等人\(2025\)提出了一个评估认知行为固化的新框架。他们首先采用多模态分层主题建模，从用户的浏览历史中提取并聚类主题兴趣。然后，通过将主题多样性、主导性和时间复现性指标整合为一个统一分数来量化固化程度。该方法在专用数据集上得到验证，为识别陷入狭窄参与循环的用户提供了一个可解释的度量，为在更大规模社会仿真中进行个体层面的行为建模提供了工具。</div></details></div></div>|

### User Identity Understanding (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Susceptibility of Communities Against Low-Credibility Content in Social News Websites](https://ojs.aaai.org/index.php/ICWSM/article/view/35813) <br> Yigit Ege Bayiz, Arash Amini, Radu Marculescu, Ufuk Topcu <br> 2025-06-07 <br> <span style="color:cyan">[multi-category：[User Identity Understanding](#User-Identity-Understanding-2-papers), [Misinformation Analysis](#Misinformation-Analysis-7-papers)]</span>|This work presents a computational framework for identifying and profiling ideological communities on social news platforms based on their susceptibility to low-credibility and biased content, using stance-derived user embeddings.<br>\[翻译\]<br>本研究提出了一个计算框架，利用立场导出的用户嵌入，来识别社交新闻平台上的意识形态社区并刻画其对于低可信度和偏见内容的易感性特征。|<img width="1200" alt="pipeline" src="figures/SC-LCC.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** The proliferation of low-credibility and highly biased content on social news platforms like Reddit necessitates moving beyond individual fake-news detection to understanding systemic vulnerabilities at the community level. This study is motivated by the need to identify ideological communities that are particularly susceptible to such content. \[翻译\] Reddit等社交新闻平台上低可信度和高偏见内容的泛滥，要求研究超越个体假新闻检测，转向理解社区层面的系统性脆弱性。本研究旨在识别对此类内容特别易感的意识形态社区。 **[innovation]** Its primary innovation lies in a novel framework that detects ideological communities based on user stance-aware embeddings, rather than platform-defined groups. It uniquely combines fine-tuned LLM-based stance detection, a learned affine transformation for contrary opinions, and spectral clustering to map communities onto a credibility-bias space for susceptibility analysis. \[翻译\] 其主要创新在于一个新颖的框架，该框架基于用户立场感知嵌入而非平台定义的群组来检测意识形态社区。它独特地结合了基于微调LLM的立场检测、用于相反观点的仿射变换学习以及谱聚类，将社区映射到可信度-偏见空间以进行易感性分析。 **[method]** The methodology first embeds post titles via SBERT. It then employs a LoRA-tuned LLM to detect user stances \(favor/against/neutral\) in comments relative to parent posts. Comment embeddings are assigned based on these stances, using the post embedding or its learned affine-transformed negation. User embeddings are derived by averaging their comment embeddings. User-level credibility and bias scores are similarly aggregated from stance-adjusted scores of news sources \(per Ad Fontes Media\). Finally, spectral clustering on user embeddings reveals communities, whose susceptibility is profiled via the aggregated scores. \[翻译\] 该方法首先通过SBERT嵌入帖子标题，然后使用经LoRA微调的大语言模型检测评论中用户相对于父帖的立场（支持/反对/中立）。根据这些立场，使用帖子嵌入或其学习到的仿射变换否定结果为评论分配嵌入向量。通过对用户的评论嵌入取平均得到用户嵌入。用户级的可信度与偏见分数以类似方式，根据立场调整后的新闻源分数进行聚合。最后，对用户嵌入进行谱聚类以揭示社区，并通过聚合分数分析其易感性。 **[conclusion/contribution]** The study demonstrates significant variance in susceptibility across the identified ideological clusters. For instance, the proportion of users prone to low-credibility content differed by 34 percentage points between the most and least susceptible clusters. A correlation was observed between the constructed user embedding space and the credibility-bias space, indicating that latent representations capture susceptibility-related features. \[翻译\] 研究表明，所识别的不同意识形态聚类之间的易感性存在显著差异。例如，对低可信度内容易感的用户比例在最具易感性和最不具易感性的聚类间相差34个百分点。研究观察到构建的用户嵌入空间与可信度-偏见空间之间存在相关性，表明潜在表征捕捉到了与易感性相关的特征。 **[limitation/future]** Limitations include reliance on a single external source for news credibility/bias labels, potential platform-specific biases in the Reddit dataset, and the inherent assumption equating opposition to high-credibility content with low-credibility preference. Future work suggests incorporating comment semantics and user interaction graphs for richer embeddings. \[翻译\] 局限性包括依赖单一外部来源进行新闻可信度/偏见标注、Reddit数据集中可能存在的平台特定偏见，以及将反对高可信度内容等同于偏好低可信度内容的内在假设。未来工作建议融入评论语义和用户交互图以获得更丰富的嵌入表征。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** The proliferation of low-credibility and highly biased content on social news platforms like Reddit necessitates moving beyond individual fake-news detection to understanding systemic vulnerabilities at the community level. This study is motivated by the need to identify ideological communities that are particularly susceptible to such content.<br>\[翻译\]<br>Reddit等社交新闻平台上低可信度和高偏见内容的泛滥，要求研究超越个体假新闻检测，转向理解社区层面的系统性脆弱性。本研究旨在识别对此类内容特别易感的意识形态社区。<br>**[innovation]** Its primary innovation lies in a novel framework that detects ideological communities based on user stance-aware embeddings, rather than platform-defined groups. It uniquely combines fine-tuned LLM-based stance detection, a learned affine transformation for contrary opinions, and spectral clustering to map communities onto a credibility-bias space for susceptibility analysis.<br>\[翻译\]<br>其主要创新在于一个新颖的框架，该框架基于用户立场感知嵌入而非平台定义的群组来检测意识形态社区。它独特地结合了基于微调LLM的立场检测、用于相反观点的仿射变换学习以及谱聚类，将社区映射到可信度-偏见空间以进行易感性分析。<br>**[method]** The methodology first embeds post titles via SBERT. It then employs a LoRA-tuned LLM to detect user stances \(favor/against/neutral\) in comments relative to parent posts. Comment embeddings are assigned based on these stances, using the post embedding or its learned affine-transformed negation. User embeddings are derived by averaging their comment embeddings. User-level credibility and bias scores are similarly aggregated from stance-adjusted scores of news sources \(per Ad Fontes Media\). Finally, spectral clustering on user embeddings reveals communities, whose susceptibility is profiled via the aggregated scores.<br>\[翻译\]<br>该方法首先通过SBERT嵌入帖子标题，然后使用经LoRA微调的大语言模型检测评论中用户相对于父帖的立场（支持/反对/中立）。根据这些立场，使用帖子嵌入或其学习到的仿射变换否定结果为评论分配嵌入向量。通过对用户的评论嵌入取平均得到用户嵌入。用户级的可信度与偏见分数以类似方式，根据立场调整后的新闻源分数进行聚合。最后，对用户嵌入进行谱聚类以揭示社区，并通过聚合分数分析其易感性。<br>**[conclusion/contribution]** The study demonstrates significant variance in susceptibility across the identified ideological clusters. For instance, the proportion of users prone to low-credibility content differed by 34 percentage points between the most and least susceptible clusters. A correlation was observed between the constructed user embedding space and the credibility-bias space, indicating that latent representations capture susceptibility-related features.<br>\[翻译\]<br>研究表明，所识别的不同意识形态聚类之间的易感性存在显著差异。例如，对低可信度内容易感的用户比例在最具易感性和最不具易感性的聚类间相差34个百分点。研究观察到构建的用户嵌入空间与可信度-偏见空间之间存在相关性，表明潜在表征捕捉到了与易感性相关的特征。<br>**[limitation/future]** Limitations include reliance on a single external source for news credibility/bias labels, potential platform-specific biases in the Reddit dataset, and the inherent assumption equating opposition to high-credibility content with low-credibility preference. Future work suggests incorporating comment semantics and user interaction graphs for richer embeddings.<br>\[翻译\]<br>局限性包括依赖单一外部来源进行新闻可信度/偏见标注、Reddit数据集中可能存在的平台特定偏见，以及将反对高可信度内容等同于偏好低可信度内容的内在假设。未来工作建议融入评论语义和用户交互图以获得更丰富的嵌入表征。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【使用**立场检测**得到用户嵌入、然后**谱聚类用于社区分析**】\[方法概括\]<br>1.帖子进行embedding获得特征向量，帖子的所有回复进行相对于帖子的立场检测。2.为评论分配特征向量（相同同帖子，相反为仿射，中立为均值）。3.对每个用户的所有评论进行特征聚合得到用户特征向量（特征向量只用于聚类）。4.通过比较源媒体数据为帖子内容分配可信度和偏见分数，根据对应评论的立场为其分配两个值，同样的聚合得到用户两值。5.根据用户特征向量进行聚类，结合用户两值获得聚类的两值，进行分析\[引用文\]Situated within the evolving scholarly focus that bridges pattern recognition and the simulation of collective social dynamics, Bayiz et al. \(2025\) shift the unit of analysis from individual users or sources to ideological communities to study their susceptibility to misinformation. This is achieved by constructing stance-aware user embeddings—where the stance of comments towards posts, identified via stance detection, is used to infer latent representations—followed by the application of spectral clustering to discover communities based on ideological alignment. They examine these communities within a credibility-bias space, revealing significant inter-community differences in susceptibility to misinformation<br>\[翻译\]<br>置于连接模式识别与集体社会动态仿真的学术演进焦点中，Bayiz等人（2025）将分析单元从个体用户或信源转向意识形态社区，以研究其对错误信息的易感性。这是通过构建立场感知的用户嵌入来实现的——其中，通过立场检测识别出的评论对帖子的立场被用于推断潜在表征——随后应用谱聚类来发现基于意识形态一致性的社区。他们在可信度-偏见空间中研究这些社区，揭示了对错误信息易感性的显著社群间差异。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-Sn%20Comput.%20Sci.-blue)]()<br>[Behavior Based Group Recommendation from Social Media Dataset by Using Deep Learning and Topic Mo...](https://link.springer.com/10.1007/s42979-024-03055-1) <br> Md. Saddam Hossain Mukta, Jubaer Ahmed, Mohaimenul Azam Khan Raiaan, Nur Mohammad Fahad, Muhammad Nazrul Islam, Nafiz Imtiaz, ... <br> 2024-07-16 <br> <span style="color:cyan">[multi-category：[User Identity Understanding](#User-Identity-Understanding-2-papers), [User Profiling](#User-Profiling-2-papers)]</span>|TLDR: A graph dataset is compiled using the strongest correlation among the features and then a graph clustering technique is applied to identify a suitable hedonist group \(i.e., one dimension of values\) for users’ recommendations, which is validated in real life by introducing two hypotheses.|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/BBGR.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/BBGR-GHV.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/BBGR-CPHV.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** This research addresses the underexplored task of identifying user groups based on shared psychological attributes, proposing that similarity in Basic Human Values, derived from social media, can predict aligned real-world behaviors.  \[翻译\] 本研究旨在解决一个未被充分探索的任务：基于共享的心理属性识别用户群体，并提出从社交媒体衍生的基本人类价值观的相似性可以预测一致的真实世界行为。 **[innovation]** Its novelty lies in fusing graph neural networks with psycholinguistic analysis to model user values \(e.g., hedonism\) for group recommendation, introducing both graph-based \(GHV\) and context-psychological \(CPHV\) clustering methods.  \[翻译\] 其创新点在于融合图神经网络与心理语言分析，为用户价值观（如快乐主义）建模以进行群体推荐，并引入了基于图的（GHV）和上下文-心理的（CPHV）两种聚类方法。 **[method]** The methodology employs two parallel tracks: GHV uses GNNs and spectral clustering on user value scores, while CPHV further integrates topic modeling \(LSA/BERT\) and psychological lexicon \(LIWC\) analysis to refine group identification.  \[翻译\] 该方法采用双轨并行：GHV在用户价值分数上应用GNN和谱聚类，而CPHV进一步整合主题建模（LSA/BERT）和心理词典（LIWC）分析以优化群体识别。 **[conclusion/contribution]** The proposed CPHV method achieved superior clustering performance \(SCC: 76%, ICC: 60%\), validating that users grouped by high hedonism scores share common interests in areas like movies and technology.  \[翻译\] 所提出的CPHV方法取得了优越的聚类性能（SCC：76%，ICC：60%），验证了按高快乐主义分数分组的用户在电影、技术等领域具有共同的兴趣。 **[limitation/future]** Limitations include reliance on sufficient digital footprints and a static view of values. Future work suggests dynamic modeling and extension to other value dimensions and platforms.  \[翻译\] 局限性包括对足够数字足迹的依赖和对价值观的静态审视。未来工作建议进行动态建模，并将方法扩展到其他价值维度与平台。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** This research addresses the underexplored task of identifying user groups based on shared psychological attributes, proposing that similarity in Basic Human Values, derived from social media, can predict aligned real-world behaviors.<br><br>\[翻译\]<br>本研究旨在解决一个未被充分探索的任务：基于共享的心理属性识别用户群体，并提出从社交媒体衍生的基本人类价值观的相似性可以预测一致的真实世界行为。<br>**[innovation]** Its novelty lies in fusing graph neural networks with psycholinguistic analysis to model user values \(e.g., hedonism\) for group recommendation, introducing both graph-based \(GHV\) and context-psychological \(CPHV\) clustering methods.<br><br>\[翻译\]<br>其创新点在于融合图神经网络与心理语言分析，为用户价值观（如快乐主义）建模以进行群体推荐，并引入了基于图的（GHV）和上下文-心理的（CPHV）两种聚类方法。<br>**[method]** The methodology employs two parallel tracks: GHV uses GNNs and spectral clustering on user value scores, while CPHV further integrates topic modeling \(LSA/BERT\) and psychological lexicon \(LIWC\) analysis to refine group identification.<br><br>\[翻译\]<br>该方法采用双轨并行：GHV在用户价值分数上应用GNN和谱聚类，而CPHV进一步整合主题建模（LSA/BERT）和心理词典（LIWC）分析以优化群体识别。<br>**[conclusion/contribution]** The proposed CPHV method achieved superior clustering performance \(SCC: 76%, ICC: 60%\), validating that users grouped by high hedonism scores share common interests in areas like movies and technology.<br><br>\[翻译\]<br>所提出的CPHV方法取得了优越的聚类性能（SCC：76%，ICC：60%），验证了按高快乐主义分数分组的用户在电影、技术等领域具有共同的兴趣。<br>**[limitation/future]** Limitations include reliance on sufficient digital footprints and a static view of values. Future work suggests dynamic modeling and extension to other value dimensions and platforms.<br><br>\[翻译\]<br>局限性包括对足够数字足迹的依赖和对价值观的静态审视。未来工作建议进行动态建模，并将方法扩展到其他价值维度与平台。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]Mukta et al. \(2024\) advance beyond surface-level analytics by modeling the latent psychological attributes of users, specifically their Basic Human Values, from social media traces. Their fusion of GNNs with psychometric analysis exemplifies a shift towards cognitive-level understanding of user collectives, forming a crucial bridge between pattern recognition and the simulation of motivation-driven group behaviors.<br>\[翻译\]<br>Mukta等人（2024）通过从社交媒体痕迹中建模用户的潜在心理属性（特别是其基本人类价值观），推进了超越表层分析的研究。他们将GNN与心理测量分析相融合，例证了向认知层面理解用户集体的转变，这在模式识别与动机驱动的群体行为仿真之间构成了关键的桥梁。</div></details></div></div>|

### User Profiling (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-Sn%20Comput.%20Sci.-blue)]()<br>[Behavior Based Group Recommendation from Social Media Dataset by Using Deep Learning and Topic Mo...](https://link.springer.com/10.1007/s42979-024-03055-1) <br> Md. Saddam Hossain Mukta, Jubaer Ahmed, Mohaimenul Azam Khan Raiaan, Nur Mohammad Fahad, Muhammad Nazrul Islam, Nafiz Imtiaz, ... <br> 2024-07-16 <br> <span style="color:cyan">[multi-category：[User Identity Understanding](#User-Identity-Understanding-2-papers), [User Profiling](#User-Profiling-2-papers)]</span>|TLDR: A graph dataset is compiled using the strongest correlation among the features and then a graph clustering technique is applied to identify a suitable hedonist group \(i.e., one dimension of values\) for users’ recommendations, which is validated in real life by introducing two hypotheses.|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/BBGR.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/BBGR-GHV.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/BBGR-CPHV.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** This research addresses the underexplored task of identifying user groups based on shared psychological attributes, proposing that similarity in Basic Human Values, derived from social media, can predict aligned real-world behaviors.  \[翻译\] 本研究旨在解决一个未被充分探索的任务：基于共享的心理属性识别用户群体，并提出从社交媒体衍生的基本人类价值观的相似性可以预测一致的真实世界行为。 **[innovation]** Its novelty lies in fusing graph neural networks with psycholinguistic analysis to model user values \(e.g., hedonism\) for group recommendation, introducing both graph-based \(GHV\) and context-psychological \(CPHV\) clustering methods.  \[翻译\] 其创新点在于融合图神经网络与心理语言分析，为用户价值观（如快乐主义）建模以进行群体推荐，并引入了基于图的（GHV）和上下文-心理的（CPHV）两种聚类方法。 **[method]** The methodology employs two parallel tracks: GHV uses GNNs and spectral clustering on user value scores, while CPHV further integrates topic modeling \(LSA/BERT\) and psychological lexicon \(LIWC\) analysis to refine group identification.  \[翻译\] 该方法采用双轨并行：GHV在用户价值分数上应用GNN和谱聚类，而CPHV进一步整合主题建模（LSA/BERT）和心理词典（LIWC）分析以优化群体识别。 **[conclusion/contribution]** The proposed CPHV method achieved superior clustering performance \(SCC: 76%, ICC: 60%\), validating that users grouped by high hedonism scores share common interests in areas like movies and technology.  \[翻译\] 所提出的CPHV方法取得了优越的聚类性能（SCC：76%，ICC：60%），验证了按高快乐主义分数分组的用户在电影、技术等领域具有共同的兴趣。 **[limitation/future]** Limitations include reliance on sufficient digital footprints and a static view of values. Future work suggests dynamic modeling and extension to other value dimensions and platforms.  \[翻译\] 局限性包括对足够数字足迹的依赖和对价值观的静态审视。未来工作建议进行动态建模，并将方法扩展到其他价值维度与平台。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** This research addresses the underexplored task of identifying user groups based on shared psychological attributes, proposing that similarity in Basic Human Values, derived from social media, can predict aligned real-world behaviors.<br><br>\[翻译\]<br>本研究旨在解决一个未被充分探索的任务：基于共享的心理属性识别用户群体，并提出从社交媒体衍生的基本人类价值观的相似性可以预测一致的真实世界行为。<br>**[innovation]** Its novelty lies in fusing graph neural networks with psycholinguistic analysis to model user values \(e.g., hedonism\) for group recommendation, introducing both graph-based \(GHV\) and context-psychological \(CPHV\) clustering methods.<br><br>\[翻译\]<br>其创新点在于融合图神经网络与心理语言分析，为用户价值观（如快乐主义）建模以进行群体推荐，并引入了基于图的（GHV）和上下文-心理的（CPHV）两种聚类方法。<br>**[method]** The methodology employs two parallel tracks: GHV uses GNNs and spectral clustering on user value scores, while CPHV further integrates topic modeling \(LSA/BERT\) and psychological lexicon \(LIWC\) analysis to refine group identification.<br><br>\[翻译\]<br>该方法采用双轨并行：GHV在用户价值分数上应用GNN和谱聚类，而CPHV进一步整合主题建模（LSA/BERT）和心理词典（LIWC）分析以优化群体识别。<br>**[conclusion/contribution]** The proposed CPHV method achieved superior clustering performance \(SCC: 76%, ICC: 60%\), validating that users grouped by high hedonism scores share common interests in areas like movies and technology.<br><br>\[翻译\]<br>所提出的CPHV方法取得了优越的聚类性能（SCC：76%，ICC：60%），验证了按高快乐主义分数分组的用户在电影、技术等领域具有共同的兴趣。<br>**[limitation/future]** Limitations include reliance on sufficient digital footprints and a static view of values. Future work suggests dynamic modeling and extension to other value dimensions and platforms.<br><br>\[翻译\]<br>局限性包括对足够数字足迹的依赖和对价值观的静态审视。未来工作建议进行动态建模，并将方法扩展到其他价值维度与平台。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]Mukta et al. \(2024\) advance beyond surface-level analytics by modeling the latent psychological attributes of users, specifically their Basic Human Values, from social media traces. Their fusion of GNNs with psychometric analysis exemplifies a shift towards cognitive-level understanding of user collectives, forming a crucial bridge between pattern recognition and the simulation of motivation-driven group behaviors.<br>\[翻译\]<br>Mukta等人（2024）通过从社交媒体痕迹中建模用户的潜在心理属性（特别是其基本人类价值观），推进了超越表层分析的研究。他们将GNN与心理测量分析相融合，例证了向认知层面理解用户集体的转变，这在模式识别与动机驱动的群体行为仿真之间构成了关键的桥梁。</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-LREC--COLING%202024-blue)]()<br>[PASUM: A pre-training architecture for social media user modeling based on text graph](https://aclanthology.org/2024.lrec-main.1107/) <br> Kun Wu, Xinyi Mou, Lanqing Xue, Zhenzhe Ying, Weiqiang Wang, Qi Zhang, Xuanjing Huang, Zhongyu Wei <br> 2024-05|利用关注图网络的结构进行自监督训练（不同用户间对比学习，同用户不同社群间对比学习），使用词图结构聚合为用户表征，尝试解决长文本问题|<img width="1200" alt="pipeline" src="figures/PASUM.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** To overcome the limitations of existing methods that struggle with lengthy user texts and the unavailability of explicit social graphs, this work addresses the challenge of learning generalizable user representations without relying on complete social network data.  \[翻译\] 为克服现有方法在处理用户长文本和显式社交图谱缺失时的局限性，本工作旨在解决不依赖完整社交网络数据而学习可泛化用户表示的挑战。 **[innovation]** Its core innovation lies in an inductive pre-training architecture that represents users solely via personal text graphs and injects social structural awareness through inter-user and intra-user contrastive learning, eliminating the need for explicit social network input during inference.  \[翻译\] 其核心创新在于一个归纳式预训练架构：仅通过个人文本图表征用户，并借助用户间与用户内对比学习注入社交结构感知，从而在推理时无需显式的社交网络输入。 **[method]** The PASUM framework first constructs a text graph from each user&#x27;s microblogs. It then employs a Graph Isomorphism Network \(GIN\) to encode the graph into a user representation. Finally, it pre-trains the encoder using contrastive loss functions defined over user pairs \(based on follow relations\) and subgraph pairs \(based on community membership\).  \[翻译\] PASUM框架首先从每位用户的微博构建文本图，随后使用图同构网络（GIN）将图表编码为用户表示，最后利用基于用户对（关注关系）和子图对（社区归属）定义的对比损失函数对编码器进行预训练。 **[conclusion/contribution]** Extensive experiments on user profiling tasks demonstrate that PASUM outperforms text-based and graph-based baselines, particularly showing robustness when social connections are sparse or absent, validating the effectiveness of its structure-infused pre-training.  \[翻译\] 在多个用户画像任务上的实验表明，PASUM优于基于文本和基于图的方法基线，尤其在社交连接稀疏或缺失时表现出鲁棒性，验证了其融入结构的预训练策略的有效性。 **[limitation/future]** Limitations include mediocre few-shot performance and reliance solely on network-derived structural signals. Future work could integrate multimodal user behaviors and attributes to enrich the pre-training paradigm.  \[翻译\] 其局限性包括小样本学习性能一般，且仅依赖于网络衍生的结构信号。未来工作可整合多模态用户行为与属性，以丰富预训练范式。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** To overcome the limitations of existing methods that struggle with lengthy user texts and the unavailability of explicit social graphs, this work addresses the challenge of learning generalizable user representations without relying on complete social network data.<br><br>\[翻译\] 为克服现有方法在处理用户长文本和显式社交图谱缺失时的局限性，本工作旨在解决不依赖完整社交网络数据而学习可泛化用户表示的挑战。<br>**[innovation]** Its core innovation lies in an inductive pre-training architecture that represents users solely via personal text graphs and injects social structural awareness through inter-user and intra-user contrastive learning, eliminating the need for explicit social network input during inference.<br><br>\[翻译\] 其核心创新在于一个归纳式预训练架构：仅通过个人文本图表征用户，并借助用户间与用户内对比学习注入社交结构感知，从而在推理时无需显式的社交网络输入。<br>**[method]** The PASUM framework first constructs a text graph from each user's microblogs. It then employs a Graph Isomorphism Network \(GIN\) to encode the graph into a user representation. Finally, it pre-trains the encoder using contrastive loss functions defined over user pairs \(based on follow relations\) and subgraph pairs \(based on community membership\).<br><br>\[翻译\] PASUM框架首先从每位用户的微博构建文本图，随后使用图同构网络（GIN）将图表编码为用户表示，最后利用基于用户对（关注关系）和子图对（社区归属）定义的对比损失函数对编码器进行预训练。<br>**[conclusion/contribution]** Extensive experiments on user profiling tasks demonstrate that PASUM outperforms text-based and graph-based baselines, particularly showing robustness when social connections are sparse or absent, validating the effectiveness of its structure-infused pre-training.<br><br>\[翻译\] 在多个用户画像任务上的实验表明，PASUM优于基于文本和基于图的方法基线，尤其在社交连接稀疏或缺失时表现出鲁棒性，验证了其融入结构的预训练策略的有效性。<br>**[limitation/future]** Limitations include mediocre few-shot performance and reliance solely on network-derived structural signals. Future work could integrate multimodal user behaviors and attributes to enrich the pre-training paradigm.<br><br>\[翻译\] 其局限性包括小样本学习性能一般，且仅依赖于网络衍生的结构信号。未来工作可整合多模态用户行为与属性，以丰富预训练范式。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[note\]关注网络的网络关系只是实现了训练数据的标注，并不是将整个图输入模型，**这相当于将图拓扑信息蒸馏到了非GNN模型中**。预训练时用户的特征表示也是词图聚合得到的。\[引用文\]In a technical approach to user modeling that does not require a global social graph at inference time, PASUM \(Wu et al., 2024\) pre-trains a user encoder by leveraging social network data only to generate supervision signals. The model processes a user's aggregated microblogs as a local text graph, and during pre-training, it is optimized so that its output representations satisfy constraints derived from follow networks \(homophily\) and community memberships \(multi-faceted roles\). This approach achieved superior accuracy on several downstream profiling tasks compared to methods that directly input social adjacency matrices, demonstrating the efficacy of distilling structural information into the model parameters via contrastive learning.<br><br>\[翻译\] 作为一种在推理时无需全局社交图谱的用户建模技术方案，PASUM \(Wu et al., 2024\) 预训练用户编码器的方法仅利用社交网络数据来生成监督信号。该模型将用户聚合的微博处理为局部文本图，并在预训练期间进行优化，使其输出的表示满足源自关注网络（同质性）和社区归属（多面角色）的约束。与直接输入社交邻接矩阵的方法相比，该方法在多个下游画像任务上取得了更高的准确率，证明了通过对比学习将结构信息蒸馏到模型参数中的有效性。</div></details></div></div>|

### User Behavior Prediction (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-IEEE%20Trans.%20Netw.%20Sci.%20Eng.-blue)]()<br>[Predicting Participation Shift of Users at the Next Stage in Social Networks](https://ieeexplore.ieee.org/document/10829773/) <br> Yichao Zhang, Zejian Wang, Huangxin Zhuang, Lei Song, Guanghui Wen, Jihong Guan, Shuigeng Zhou <br> 2025-03 <br> <span style="color:cyan">[multi-category：[User Behavior Prediction](#User-Behavior-Prediction-1-papers), [Information Diffusion Analysis](#Information-Diffusion-Analysis-1-papers)]</span>|一个参与可能性排序算法，综合曝光时间排名、社会引力排名（借用万有引力思想）、级联相似度排名（与历史级联中的其他用户特征对比）|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/TR-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/TR-2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the granularity gap in diffusion analysis by shifting focus from macro-level popularity prediction to micro-level participation shift prediction \(i.e., identifying specific users transitioning from listeners to spreaders at the next timestamp\), particularly under data-sparse &quot;cold start&quot; conditions. \[翻译\] 解决了传播分析中的粒度差距问题，将关注点从宏观流行度预测转移到微观层面的参与转变预测（即识别在下一时间戳从听众转变为传播者的具体用户），特别是在数据稀疏的“冷启动”条件下。 **[innovation]** Proposes an unsupervised Triple Ranking \(TR\) framework that integrates physics-inspired Social Gravity with temporal and sequential features, interpreting information cascades not merely as similarity measures but as dynamic activation signals that exert &quot;gravitational forces&quot; on potential candidates. \[翻译\] 提出了一种无监督的三重排名（TR）框架，该框架将受物理学启发的社会引力与时间和序列特征相结合，不仅将信息级联视为相似性度量，更将其视为对潜在候选人施加“引力”的动态激活信号。 **[method]** Decomposes the diffusion lifecycle into discrete stages and calculates three rankings for candidates: Exposure Time Ranking \(based on response latency distributions derived from cascade timestamps\), Social Gravity Ranking \(modeling influence as physical forces from active neighbors in the cascade subgraph\), and Cascade Similarity Ranking \(learning latent user correlations via Skip-gram embeddings\), which are fused linearly or via Graph Neural Networks \(T-GCN/T-GAT\). \[翻译\] 将传播生命周期分解为离散阶段，并为候选人计算三种排名：曝光时间排名（基于从级联时间戳导出的响应延迟分布）、社会引力排名（将影响力建模为级联子图中活跃邻居的物理作用力）和级联相似度排名（通过Skip-gram嵌入学习潜在的用户相关性），这些排名通过线性加权或图神经网络（T-GCN/T-GAT）进行融合。 **[conclusion/contribution]** Experimental evaluations on three Twitter datasets \(Higgs, Munmun, Virality2013\) demonstrate that the unsupervised TR model and its supervised variants consistently outperform probabilistic baselines \(IC, DT, GT\) and state-of-the-art GNNs \(DeepInf\) in Precision, Recall, and F1-Measure, with significantly reduced computational complexity. \[翻译\] 在三个Twitter数据集（Higgs, Munmun, Virality2013）上的实验评估表明，无监督TR模型及其有监督变体在精确率、召回率和F1值上均优于概率基线（IC, DT, GT）和最先进的GNN模型（DeepInf），且计算复杂度显著降低。 **[limitation/future]** The model currently relies exclusively on topological structure and temporal traces, neglecting semantic information \(textual content\) and assuming a static underlying network topology without accounting for structural evolution over time. \[翻译\] 该模型目前仅依赖拓扑结构和时间轨迹，忽略了语义信息（文本内容），且假设底层网络拓扑是静态的，未考虑结构随时间的演化。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the granularity gap in diffusion analysis by shifting focus from macro-level popularity prediction to micro-level participation shift prediction \(i.e., identifying specific users transitioning from listeners to spreaders at the next timestamp\), particularly under data-sparse "cold start" conditions.<br>\[翻译\] 解决了传播分析中的粒度差距问题，将关注点从宏观流行度预测转移到微观层面的参与转变预测（即识别在下一时间戳从听众转变为传播者的具体用户），特别是在数据稀疏的“冷启动”条件下。<br>**[innovation]** Proposes an unsupervised Triple Ranking \(TR\) framework that integrates physics-inspired Social Gravity with temporal and sequential features, interpreting information cascades not merely as similarity measures but as dynamic activation signals that exert "gravitational forces" on potential candidates.<br>\[翻译\] 提出了一种无监督的三重排名（TR）框架，该框架将受物理学启发的社会引力与时间和序列特征相结合，不仅将信息级联视为相似性度量，更将其视为对潜在候选人施加“引力”的动态激活信号。<br>**[method]** Decomposes the diffusion lifecycle into discrete stages and calculates three rankings for candidates: Exposure Time Ranking \(based on response latency distributions derived from cascade timestamps\), Social Gravity Ranking \(modeling influence as physical forces from active neighbors in the cascade subgraph\), and Cascade Similarity Ranking \(learning latent user correlations via Skip-gram embeddings\), which are fused linearly or via Graph Neural Networks \(T-GCN/T-GAT\).<br>\[翻译\] 将传播生命周期分解为离散阶段，并为候选人计算三种排名：曝光时间排名（基于从级联时间戳导出的响应延迟分布）、社会引力排名（将影响力建模为级联子图中活跃邻居的物理作用力）和级联相似度排名（通过Skip-gram嵌入学习潜在的用户相关性），这些排名通过线性加权或图神经网络（T-GCN/T-GAT）进行融合。<br>**[conclusion/contribution]** Experimental evaluations on three Twitter datasets \(Higgs, Munmun, Virality2013\) demonstrate that the unsupervised TR model and its supervised variants consistently outperform probabilistic baselines \(IC, DT, GT\) and state-of-the-art GNNs \(DeepInf\) in Precision, Recall, and F1-Measure, with significantly reduced computational complexity.<br>\[翻译\] 在三个Twitter数据集（Higgs, Munmun, Virality2013）上的实验评估表明，无监督TR模型及其有监督变体在精确率、召回率和F1值上均优于概率基线（IC, DT, GT）和最先进的GNN模型（DeepInf），且计算复杂度显著降低。<br>**[limitation/future]** The model currently relies exclusively on topological structure and temporal traces, neglecting semantic information \(textual content\) and assuming a static underlying network topology without accounting for structural evolution over time.<br>\[翻译\] 该模型目前仅依赖拓扑结构和时间轨迹，忽略了语义信息（文本内容），且假设底层网络拓扑是静态的，未考虑结构随时间的演化。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【用户参与行为预测（方法），下一阶段会有哪些用户成为传播者（应用）】【也是一个不关注内容的，只关注级联图结构（包含时间）】\[引用文\]To understand the micro-dynamics of propagation, Zhang et al. \[2025\] move beyond static topological analysis to predict participation shifts at specific cascade stages. Their Triple Ranking \(TR\) model treats information cascades as dynamic subgraphs that actively influence the underlying user network. By introducing a physics-inspired Social Gravity mechanism, the method quantifies the cumulative impact of active neighbors on candidates as a resultant force, integrated with Exposure Time distributions and Cascade Similarity embeddings. This approach effectively addresses the cold-start problem in behavior prediction by fusing these structural and temporal signals into a unified ranking system, demonstrating that agent-based heuristics can effectively capture diffusion probabilities without extensive supervised training.<br>\[翻译\] 为了理解传播的微观动态，Zhang等人 \[2025\] 超越了静态拓扑分析，转而预测特定级联阶段的参与转变。他们的三重排名（TR）模型将信息级联视为主动影响底层用户网络的动态子图。通过引入受物理学启发的社会引力机制，该方法将活跃邻居对候选人的累积影响量化为合力，并与曝光时间分布和级联相似度嵌入相结合。该方法通过将这些结构和时间信号融合到一个统一的排名系统中，有效解决了行为预测中的冷启动问题，证明了基于智能体的启发式方法无需大量监督训练即可有效捕捉传播概率。</div></details></div></div>|

### Information Diffusion Analysis (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-IEEE%20Trans.%20Netw.%20Sci.%20Eng.-blue)]()<br>[Predicting Participation Shift of Users at the Next Stage in Social Networks](https://ieeexplore.ieee.org/document/10829773/) <br> Yichao Zhang, Zejian Wang, Huangxin Zhuang, Lei Song, Guanghui Wen, Jihong Guan, Shuigeng Zhou <br> 2025-03 <br> <span style="color:cyan">[multi-category：[User Behavior Prediction](#User-Behavior-Prediction-1-papers), [Information Diffusion Analysis](#Information-Diffusion-Analysis-1-papers)]</span>|一个参与可能性排序算法，综合曝光时间排名、社会引力排名（借用万有引力思想）、级联相似度排名（与历史级联中的其他用户特征对比）|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/TR-1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/TR-2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addresses the granularity gap in diffusion analysis by shifting focus from macro-level popularity prediction to micro-level participation shift prediction \(i.e., identifying specific users transitioning from listeners to spreaders at the next timestamp\), particularly under data-sparse &quot;cold start&quot; conditions. \[翻译\] 解决了传播分析中的粒度差距问题，将关注点从宏观流行度预测转移到微观层面的参与转变预测（即识别在下一时间戳从听众转变为传播者的具体用户），特别是在数据稀疏的“冷启动”条件下。 **[innovation]** Proposes an unsupervised Triple Ranking \(TR\) framework that integrates physics-inspired Social Gravity with temporal and sequential features, interpreting information cascades not merely as similarity measures but as dynamic activation signals that exert &quot;gravitational forces&quot; on potential candidates. \[翻译\] 提出了一种无监督的三重排名（TR）框架，该框架将受物理学启发的社会引力与时间和序列特征相结合，不仅将信息级联视为相似性度量，更将其视为对潜在候选人施加“引力”的动态激活信号。 **[method]** Decomposes the diffusion lifecycle into discrete stages and calculates three rankings for candidates: Exposure Time Ranking \(based on response latency distributions derived from cascade timestamps\), Social Gravity Ranking \(modeling influence as physical forces from active neighbors in the cascade subgraph\), and Cascade Similarity Ranking \(learning latent user correlations via Skip-gram embeddings\), which are fused linearly or via Graph Neural Networks \(T-GCN/T-GAT\). \[翻译\] 将传播生命周期分解为离散阶段，并为候选人计算三种排名：曝光时间排名（基于从级联时间戳导出的响应延迟分布）、社会引力排名（将影响力建模为级联子图中活跃邻居的物理作用力）和级联相似度排名（通过Skip-gram嵌入学习潜在的用户相关性），这些排名通过线性加权或图神经网络（T-GCN/T-GAT）进行融合。 **[conclusion/contribution]** Experimental evaluations on three Twitter datasets \(Higgs, Munmun, Virality2013\) demonstrate that the unsupervised TR model and its supervised variants consistently outperform probabilistic baselines \(IC, DT, GT\) and state-of-the-art GNNs \(DeepInf\) in Precision, Recall, and F1-Measure, with significantly reduced computational complexity. \[翻译\] 在三个Twitter数据集（Higgs, Munmun, Virality2013）上的实验评估表明，无监督TR模型及其有监督变体在精确率、召回率和F1值上均优于概率基线（IC, DT, GT）和最先进的GNN模型（DeepInf），且计算复杂度显著降低。 **[limitation/future]** The model currently relies exclusively on topological structure and temporal traces, neglecting semantic information \(textual content\) and assuming a static underlying network topology without accounting for structural evolution over time. \[翻译\] 该模型目前仅依赖拓扑结构和时间轨迹，忽略了语义信息（文本内容），且假设底层网络拓扑是静态的，未考虑结构随时间的演化。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addresses the granularity gap in diffusion analysis by shifting focus from macro-level popularity prediction to micro-level participation shift prediction \(i.e., identifying specific users transitioning from listeners to spreaders at the next timestamp\), particularly under data-sparse "cold start" conditions.<br>\[翻译\] 解决了传播分析中的粒度差距问题，将关注点从宏观流行度预测转移到微观层面的参与转变预测（即识别在下一时间戳从听众转变为传播者的具体用户），特别是在数据稀疏的“冷启动”条件下。<br>**[innovation]** Proposes an unsupervised Triple Ranking \(TR\) framework that integrates physics-inspired Social Gravity with temporal and sequential features, interpreting information cascades not merely as similarity measures but as dynamic activation signals that exert "gravitational forces" on potential candidates.<br>\[翻译\] 提出了一种无监督的三重排名（TR）框架，该框架将受物理学启发的社会引力与时间和序列特征相结合，不仅将信息级联视为相似性度量，更将其视为对潜在候选人施加“引力”的动态激活信号。<br>**[method]** Decomposes the diffusion lifecycle into discrete stages and calculates three rankings for candidates: Exposure Time Ranking \(based on response latency distributions derived from cascade timestamps\), Social Gravity Ranking \(modeling influence as physical forces from active neighbors in the cascade subgraph\), and Cascade Similarity Ranking \(learning latent user correlations via Skip-gram embeddings\), which are fused linearly or via Graph Neural Networks \(T-GCN/T-GAT\).<br>\[翻译\] 将传播生命周期分解为离散阶段，并为候选人计算三种排名：曝光时间排名（基于从级联时间戳导出的响应延迟分布）、社会引力排名（将影响力建模为级联子图中活跃邻居的物理作用力）和级联相似度排名（通过Skip-gram嵌入学习潜在的用户相关性），这些排名通过线性加权或图神经网络（T-GCN/T-GAT）进行融合。<br>**[conclusion/contribution]** Experimental evaluations on three Twitter datasets \(Higgs, Munmun, Virality2013\) demonstrate that the unsupervised TR model and its supervised variants consistently outperform probabilistic baselines \(IC, DT, GT\) and state-of-the-art GNNs \(DeepInf\) in Precision, Recall, and F1-Measure, with significantly reduced computational complexity.<br>\[翻译\] 在三个Twitter数据集（Higgs, Munmun, Virality2013）上的实验评估表明，无监督TR模型及其有监督变体在精确率、召回率和F1值上均优于概率基线（IC, DT, GT）和最先进的GNN模型（DeepInf），且计算复杂度显著降低。<br>**[limitation/future]** The model currently relies exclusively on topological structure and temporal traces, neglecting semantic information \(textual content\) and assuming a static underlying network topology without accounting for structural evolution over time.<br>\[翻译\] 该模型目前仅依赖拓扑结构和时间轨迹，忽略了语义信息（文本内容），且假设底层网络拓扑是静态的，未考虑结构随时间的演化。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【用户参与行为预测（方法），下一阶段会有哪些用户成为传播者（应用）】【也是一个不关注内容的，只关注级联图结构（包含时间）】\[引用文\]To understand the micro-dynamics of propagation, Zhang et al. \[2025\] move beyond static topological analysis to predict participation shifts at specific cascade stages. Their Triple Ranking \(TR\) model treats information cascades as dynamic subgraphs that actively influence the underlying user network. By introducing a physics-inspired Social Gravity mechanism, the method quantifies the cumulative impact of active neighbors on candidates as a resultant force, integrated with Exposure Time distributions and Cascade Similarity embeddings. This approach effectively addresses the cold-start problem in behavior prediction by fusing these structural and temporal signals into a unified ranking system, demonstrating that agent-based heuristics can effectively capture diffusion probabilities without extensive supervised training.<br>\[翻译\] 为了理解传播的微观动态，Zhang等人 \[2025\] 超越了静态拓扑分析，转而预测特定级联阶段的参与转变。他们的三重排名（TR）模型将信息级联视为主动影响底层用户网络的动态子图。通过引入受物理学启发的社会引力机制，该方法将活跃邻居对候选人的累积影响量化为合力，并与曝光时间分布和级联相似度嵌入相结合。该方法通过将这些结构和时间信号融合到一个统一的排名系统中，有效解决了行为预测中的冷启动问题，证明了基于智能体的启发式方法无需大量监督训练即可有效捕捉传播概率。</div></details></div></div>|

### | Generation (4 papers)


### Comment Generation (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Project](https://img.shields.io/badge/Project-View-blue)](https://netsys.surrey.ac.uk/datasets/slashdot/) [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[Conversation Kernels: A Flexible Mechanism to Learn Relevant Context for Online Conversation Unde...](https://ojs.aaai.org/index.php/ICWSM/article/view/35800) <br> Vibhor Agarwal,Arjoo Gupta,Suparna De,Nishanth Sastry <br> 2025-06-07 <br> <span style="color:cyan">[multi-category：[Base Techniques](#-Base-Techniques-2-papers), [Comment Generation](#Comment-Generation-2-papers)]</span>|A flexible, structural context discovery framework that enhances conversation understanding by learning to attend to relevant topological neighborhoods within conversation trees.\[翻译\] 一个灵活的结构化上下文发现框架，通过学习关注对话树内相关的拓扑邻域来增强对话理解能力。|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Conversation Kernels2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion. \[翻译\] 针对在线言论固有的稀疏性和语境依赖性问题，即传统模型往往难以捕捉对话树内的隐式依赖关系，或因无差别地引入上下文而产生噪声 **[innovation]** The proposal of &quot;Conversation Kernels,&quot; a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the &quot;right&quot; structural neighborhood rather than merely increasing context length. \[翻译\] 提出了“对话核”这一通用机制，利用灵活的拓扑形状来检索细粒度的结构化对话上下文；其独到之处在于通过识别“正确”的结构邻域而非单纯增加上下文长度来理解对话。 **[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder. \[翻译\] 一个端到端训练的概率框架，首先通过相似度评分检索相关的结构化窗口（如祖先、邻居），随后通过对RoBERTa编码器生成的预测分布进行加权求和（边缘化），从而融合这些上下文信息。\[通俗核心\]针对目标评论构建回复树，取几个窗口（如父评论窗口、1跳窗口），每个窗口中所有评论与原评论拼接，并进行预测，最后不同窗口与原评论的相关性经过softmax作为权重，对所有预测置信度加权和，得到最终结果 **[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns. \[翻译\] 在Slashdot数据上的广泛实验表明，上下文增强的核机制在准确率上比基线Transformer模型高出20%，并在特定分类任务中超越了通用大语言模型（GPT-3.5/4），揭示了不同任务需要截然不同的结构化上下文模式。 **[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context. \[翻译\] 该方法严重依赖显式的树状回复线索，限制了其在扁平化讨论形式中的适用性，并且在上下文稀疏的对话早期阶段可能面临冷启动挑战。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Addressing the sparsity and context-dependency of individual online utterances, where traditional models often fail to capture implicit dependencies within conversation trees or introduce noise through indiscriminate context inclusion.<br>\[翻译\] 针对在线言论固有的稀疏性和语境依赖性问题，即传统模型往往难以捕捉对话树内的隐式依赖关系，或因无差别地引入上下文而产生噪声<br>**[innovation]** The proposal of "Conversation Kernels," a general-purpose mechanism that employs flexible topological shapes to retrieve fine-grained, structured conversational context, distinguishing itself by identifying the "right" structural neighborhood rather than merely increasing context length.<br>\[翻译\] 提出了“对话核”这一通用机制，利用灵活的拓扑形状来检索细粒度的结构化对话上下文；其独到之处在于通过识别“正确”的结构邻域而非单纯增加上下文长度来理解对话。<br>**[method]** An end-to-end trained probabilistic framework that first retrieves relevant structural windows \(e.g., ancestors, neighbors\) via similarity scoring, and subsequently fuses these contexts through a weighted marginalization of the predictive distributions generated by a RoBERTa-based encoder.<br>\[翻译\] 一个端到端训练的概率框架，首先通过相似度评分检索相关的结构化窗口（如祖先、邻居），随后通过对RoBERTa编码器生成的预测分布进行加权求和（边缘化），从而融合这些上下文信息。\[通俗核心\]针对目标评论构建回复树，取几个窗口（如父评论窗口、1跳窗口），每个窗口中所有评论与原评论拼接，并进行预测，最后不同窗口与原评论的相关性经过softmax作为权重，对所有预测置信度加权和，得到最终结果<br>**[conclusion/contribution]** Extensive experiments on Slashdot data demonstrate that context-augmented kernels outperform baseline transformers by up to 20% in accuracy and surpass general-purpose LLMs \(GPT-3.5/4\) in specific categorization tasks, revealing that different tasks require distinct structural context patterns.<br>\[翻译\] 在Slashdot数据上的广泛实验表明，上下文增强的核机制在准确率上比基线Transformer模型高出20%，并在特定分类任务中超越了通用大语言模型（GPT-3.5/4），揭示了不同任务需要截然不同的结构化上下文模式。<br>**[limitation/future]** The approach relies heavily on explicit tree-structured reply threads, limiting applicability in flat discussion formats, and may face cold-start challenges in early-stage conversations with sparse context.<br>\[翻译\] 该方法严重依赖显式的树状回复线索，限制了其在扁平化讨论形式中的适用性，并且在上下文稀疏的对话早期阶段可能面临冷启动挑战。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【基础技术—上下文感知方法】可用于所有内容理解任务，论文中的实验用的是是否受欢迎二分类<br>\[引用文\]To better bridge pattern recognition with social interaction structures, Agarwal et al. \(2025\) proposed Conversation Kernels, an end-to-end framework designed to extract fine-grained context from conversation trees. By dynamically retrieving and weighting specific topological neighborhoods \(e.g., ancestors or siblings\) rather than ingesting linear history, their method effectively filters noise inherent in social discussions. This structural selectivity demonstrates that incorporating explicit interaction topologies is crucial for accurately decoding the nature of online conversations, yielding performance that surpasses even general-purpose Large Language Models like GPT-4.<br>\[翻译\]<br>为了更好地将模式识别与社会互动结构联系起来，Agarwal等人 \(2025\) 提出了“对话核（Conversation Kernels）”，这是一种旨在从对话树中提取细粒度上下文的端到端框架。通过动态检索并加权特定的拓扑邻域（如祖先或兄弟节点）而非摄入线性历史，该方法有效地过滤了社会讨论中固有的噪声。这种结构选择性证明，结合显式的互动拓扑对于准确解读在线对话的性质至关重要，其表现甚至超越了像 GPT-4 这样的通用大语言模型。</div></details></div></div>|
|[![Star](https://img.shields.io/github/stars/ErxinYu/PopALM.svg?style=social&label=Star)](https://github.com/ErxinYu/PopALM) [![Publish](https://img.shields.io/badge/Conference-LREC--COLING%202024-blue)]()<br>[PopALM: Popularity-aligned language models for social media trendy response prediction](https://aclanthology.org/2024.lrec-main.1127/) <br> Erxin Yu1,Jing Li1?,Chunpu Xu <br> 2024-05|先练“选手”（SFT），再练“裁判”（RM），最后让“裁判”指导“选手”训练（RL）|<img width="1200" alt="pipeline" src="figures/PopALM.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** Motivated by the need to simulate mainstream public reactions on social media, this study identifies response popularity—quantified by &quot;like&quot; counts—as a crucial yet noisy signal for aligning language models with collective preferences. \[翻译\] 出于模拟社交媒体上主流公众反应的需求，本研究将通过“点赞数”量化的回复流行度视为一种关键信号，旨在将语言模型与群体偏好对齐，尽管该指标本身存在噪声。 **[innovation]** The authors propose PopALM, which introduces a curriculum learning-enhanced Proximal Policy Optimization \(CL-PPO\) strategy to robustly align generation with popularity by mitigating the significant noise inherent in \[翻译\] 作者提出了 PopALM，该模型引入了一种增强了课程学习的近端策略优化（CL-PPO）策略，通过缓解原始互动指标中存在的显著噪声，稳健地将生成内容与流行度对齐。 **[method]** The framework follows a sequential &quot;SFT-RM-RL&quot; pipeline, where the CL-PPO algorithm specifically incorporates reward enhancement, ranking, and self-paced sampling to transition training from high-confidence samples to complex scenarios, thereby filtering environmental noise. \[翻译\] 该框架遵循顺序的“有监督微调-奖励建模-强化学习”流程，其中CL-PPO算法特别结合了奖励增强、排序和自步采样机制，以实现从高置信度样本到复杂场景的过渡训练，从而过滤环境噪声。 **[conclusion/contribution]** Experiments on a large-scale Weibo benchmark demonstrate that PopALM outperforms state-of-the-art baselines in both automatic metrics and human evaluation, generating responses that are more specific and aligned with public sentiment. \[翻译\] 在大规模微博基准上的实验表明，PopALM 在自动指标和人工评估方面均优于最先进的基线模型，生成的回复更加具体且符合公众情绪。 **[limitation/future]** A primary limitation lies in the reliance on &quot;like&quot; counts as the sole proxy for popularity, which may not fully capture multi-dimensional user engagement or generalize across different platform algorithms. \[翻译\] 一个主要的局限性在于依赖“点赞数”作为衡量流行度的单一代理指标，这可能无法完全捕捉多维度的用户参与度，也难以在不同平台的算法间泛化。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** Motivated by the need to simulate mainstream public reactions on social media, this study identifies response popularity—quantified by "like" counts—as a crucial yet noisy signal for aligning language models with collective preferences.<br>\[翻译\] 出于模拟社交媒体上主流公众反应的需求，本研究将通过“点赞数”量化的回复流行度视为一种关键信号，旨在将语言模型与群体偏好对齐，尽管该指标本身存在噪声。<br>**[innovation]** The authors propose PopALM, which introduces a curriculum learning-enhanced Proximal Policy Optimization \(CL-PPO\) strategy to robustly align generation with popularity by mitigating the significant noise inherent in<br>\[翻译\] 作者提出了 PopALM，该模型引入了一种增强了课程学习的近端策略优化（CL-PPO）策略，通过缓解原始互动指标中存在的显著噪声，稳健地将生成内容与流行度对齐。<br>**[method]** The framework follows a sequential "SFT-RM-RL" pipeline, where the CL-PPO algorithm specifically incorporates reward enhancement, ranking, and self-paced sampling to transition training from high-confidence samples to complex scenarios, thereby filtering environmental noise.<br>\[翻译\] 该框架遵循顺序的“有监督微调-奖励建模-强化学习”流程，其中CL-PPO算法特别结合了奖励增强、排序和自步采样机制，以实现从高置信度样本到复杂场景的过渡训练，从而过滤环境噪声。<br>**[conclusion/contribution]** Experiments on a large-scale Weibo benchmark demonstrate that PopALM outperforms state-of-the-art baselines in both automatic metrics and human evaluation, generating responses that are more specific and aligned with public sentiment.<br>\[翻译\] 在大规模微博基准上的实验表明，PopALM 在自动指标和人工评估方面均优于最先进的基线模型，生成的回复更加具体且符合公众情绪。<br>**[limitation/future]** A primary limitation lies in the reliance on "like" counts as the sole proxy for popularity, which may not fully capture multi-dimensional user engagement or generalize across different platform algorithms.<br>\[翻译\] 一个主要的局限性在于依赖“点赞数”作为衡量流行度的单一代理指标，这可能无法完全捕捉多维度的用户参与度，也难以在不同平台的算法间泛化。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[备注\]该论文在会议上没有doi，使用的是arxiv版的doi【经典微调+RL范式】噪声指的是受各种因素影响，点赞数的具体值难以公平对比<br>\[引用文\]<br>In the pursuit of simulating collective social behaviors rather than merely generating coherent text, aligning models with mainstream public sentiment becomes critical. However, social feedback signals, such as "like" counts, are often fraught with noise stemming from non-content factors like posting time or author influence. To address this, PopALM \(Yu et al., 2024\) proposes a PPO algorithm enhanced by curriculum learning. This approach operates on the premise that models should prioritize high-confidence samples—where popularity strongly correlates with content quality—to establish a robust foundation. By adopting a self-paced sampling strategy that transitions from easy-to-learn instances to noisier ones, PopALM effectively mitigates the significant noise inherent in using "like" counts as popularity indicators.<br>\[翻译\]<br>在追求模拟群体社会行为而非仅仅生成连贯文本的过程中，将模型与主流公众情绪对齐变得至关重要。然而，诸如“点赞数”之类的社会反馈信号往往充满了源自非内容因素（如发布时间或作者影响力）的噪声。针对这一问题，PopALM \(Yu et al., 2024\) 提出了一种增强了课程学习的PPO算法。该方法基于这样一个前提：模型应优先学习那些置信度高（即流行度与内容质量强相关）的样本，从而打下坚实的基础。通过采用一种从易学样本到噪声样本过渡的自步采样策略，PopALM 有效缓解了点赞数作为热度指标存在大量噪声的问题。</div></details></div></div>|

### Humor Generation (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/Social-AI-Studio/MemeCraft.svg?style=social&label=Star)](https://github.com/Social-AI-Studio/MemeCraft) [![Publish](https://img.shields.io/badge/Conference-Proceedings%20of%20the%20ACM%20Web%20Conference%202024%EF%BC%88WWW%20%2724%29-blue)]()<br>[MemeCraft: Contextual and stance-driven multimodal meme generation](https://dl.acm.org/doi/10.1145/3589334.3648151) <br> Han Wang, Roy Ka-Wei Lee <br> 2024-05-13 <br> <span style="color:cyan">[multi-category：[Meme Analysis](#Meme-Analysis-2-papers), [Humor Generation](#Humor-Generation-1-papers)]</span>|This work presents an end-to-end, training-free meme generator that operates through a sequence of template retrieval, visual description generation, text synthesis via structured prompting, meme composition, and final hate speech detection.<br>\[翻译\] 端到端无训练meme生成器：获得模板->生成模板描述->结构化prompt生成meme文本->组合为meme->仇恨检测。|<img width="1200" alt="pipeline" src="figures/MemeCraft.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** While internet memes have evolved into potent vehicles for social and political discourse, existing generation tools often lack the capability to align content with specific ideological stances or ensure safety against hate speech. \[翻译\] 虽然网络迷因已演变为社会和政治话语的有力载体，但现有的生成工具往往缺乏将内容与特定意识形态立场对齐的能力，也难以确保内容安全以防止仇恨言论。 **[innovation]** This work proposes a novel framework utilizing off-the-shelf Large Language Models \(LLMs\) and Visual Language Models \(VLMs\) to generate advocacy-driven memes without fine-tuning, incorporating a dedicated safety mechanism to mitigate the production of hateful content. \[翻译\] 该工作提出了一个利用现成的多模态大模型（LLMs和VLMs）生成宣传性迷因的新颖框架，无需进行微调，并内置了专门的安全机制以减少仇恨内容的产生。 **[method]** The authors devise an inference-only pipeline that decouples visual processing from text generation: a VLM first converts meme templates into textual descriptions, which serve as context for an LLM conditioned on structured prompts \(e.g., stance, persuasion technique\) to synthesize humorous captions. \[翻译\] 作者设计了一个仅推理（inference-only）的流水线，将视觉处理与文本生成解耦：首先由VLM将迷因模板转换为文本描述，随后将其作为上下文，结合结构化提示（如立场、说服技巧）引导LLM合成幽默配文。 **[conclusion/contribution]** Experimental evaluations focusing on UN Sustainable Development Goals demonstrate that the approach, particularly when leveraging ChatGPT, significantly outperforms state-of-the-art baselines in terms of hilarity and persuasiveness, achieving authenticity scores comparable to human-created content. \[翻译\] 针对联合国可持续发展目标的实验评估表明，该方法（尤其是基于ChatGPT的版本）在幽默感和说服力方面显著优于最先进的基线模型，并达到了与人类创作内容相当的真实性评分。 **[limitation/future]** A notable limitation lies in the information bottleneck introduced by converting visual data into text descriptions, which may fail to capture fine-grained visual nuances or pixel-level text-image interplay compared to end-to-end multimodal training. \[翻译\] 一个显著的局限性在于将视觉数据转换为文本描述所引入的信息瓶颈，与端到端的多模态训练相比，这种方法可能难以捕捉细粒度的视觉细微差别或像素级的图文互动。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** While internet memes have evolved into potent vehicles for social and political discourse, existing generation tools often lack the capability to align content with specific ideological stances or ensure safety against hate speech.<br>\[翻译\] 虽然网络迷因已演变为社会和政治话语的有力载体，但现有的生成工具往往缺乏将内容与特定意识形态立场对齐的能力，也难以确保内容安全以防止仇恨言论。<br>**[innovation]** This work proposes a novel framework utilizing off-the-shelf Large Language Models \(LLMs\) and Visual Language Models \(VLMs\) to generate advocacy-driven memes without fine-tuning, incorporating a dedicated safety mechanism to mitigate the production of hateful content.<br>\[翻译\] 该工作提出了一个利用现成的多模态大模型（LLMs和VLMs）生成宣传性迷因的新颖框架，无需进行微调，并内置了专门的安全机制以减少仇恨内容的产生。<br>**[method]** The authors devise an inference-only pipeline that decouples visual processing from text generation: a VLM first converts meme templates into textual descriptions, which serve as context for an LLM conditioned on structured prompts \(e.g., stance, persuasion technique\) to synthesize humorous captions.<br>\[翻译\] 作者设计了一个仅推理（inference-only）的流水线，将视觉处理与文本生成解耦：首先由VLM将迷因模板转换为文本描述，随后将其作为上下文，结合结构化提示（如立场、说服技巧）引导LLM合成幽默配文。<br>**[conclusion/contribution]** Experimental evaluations focusing on UN Sustainable Development Goals demonstrate that the approach, particularly when leveraging ChatGPT, significantly outperforms state-of-the-art baselines in terms of hilarity and persuasiveness, achieving authenticity scores comparable to human-created content.<br>\[翻译\] 针对联合国可持续发展目标的实验评估表明，该方法（尤其是基于ChatGPT的版本）在幽默感和说服力方面显著优于最先进的基线模型，并达到了与人类创作内容相当的真实性评分。<br>**[limitation/future]** A notable limitation lies in the information bottleneck introduced by converting visual data into text descriptions, which may fail to capture fine-grained visual nuances or pixel-level text-image interplay compared to end-to-end multimodal training.<br>\[翻译\] 一个显著的局限性在于将视觉数据转换为文本描述所引入的信息瓶颈，与端到端的多模态训练相比，这种方法可能难以捕捉细粒度的视觉细微差别或像素级的图文互动。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]In the pursuit of deploying generative AI for specific social goals, Wang and Lee \[1\] introduce MemeCraft, a framework designed to fabricate memes advocating for UN Sustainable Development Goals \(e.g., climate action\). It functions as an end-to-end, inference-only generation framework where visual semantics are compressed into textual descriptions by a VLM to guide an LLM in generating stance-aligned captions. While this structured prompting approach ensures high controllability and safety in propagating social messages, the reliance on intermediate textual representations instead of joint multimodal embedding implies a potential granularity loss in capturing complex visual-semantic interplay.<br>\[翻译\] 在探索将生成式AI应用于特定社会目标的背景下，Wang和Lee \[1\] 推出了MemeCraft，这是一个旨在制作倡导联合国可持续发展目标（如气候行动）迷因的框架。这是一个端到端的、仅推理（inference-only）的生成框架，通过VLM将视觉语义压缩为文本描述，进而引导LLM生成与立场一致的配文。虽然这种结构化提示方法在传播社会信息时确保了高度的可控性和安全性，但依赖中间文本表示而非联合多模态嵌入的做法，也意味着在捕捉复杂的视觉-语义交互时可能存在细粒度信息的缺失。</div></details></div></div>|

### Social Bots (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[The persuasive power of large language models](https://ojs.aaai.org/index.php/ICWSM/article/view/31304) <br> Simon Martin Breum, Daniel V?dele Egdal, Victor Gram Mortensen, Anders Giovanni M?ller, Luca Maria Aiello <br> 2024-05-28 <br> <span style="color:cyan">[multi-category：[Social Bots](#Social-Bots-1-papers), [Other](#-Other-1-papers)]</span>|TLDR: 显示了SIRS过程在具有大型扩展子图的图（例如社交网络模型）上的生存时间的阈值行为，显示了随机图的严格阈值。|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Persuasive-Power1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Persuasive-Power2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] Investigating whether LLM-generated arguments can persuade and if AI agents can simulate human-like opinion dynamics. 探究LLM生成的论点能否说服他人，以及AI智能体能否模拟类人的观点动态。\[翻译\] **[innovation]** \[AI generated\] Proposes a synthetic persuasion dialogue framework using LLM agents to study opinion dynamics and identifies effective persuasive argument types. \[翻译\] 提出了一个使用LLM智能体进行合成说服对话的框架来研究观点动力学，并识别出有效的说服性论据类型。 **[method]** \[AI generated\] Designed a synthetic persuasion dialogue on climate change, where an AI &#x27;convincer&#x27; generates arguments for an AI &#x27;skeptic&#x27; to evaluate opinion change, incorporating psycho-linguistic dimensions. \[翻译\] 设计了一个关于气候变化的合成说服对话场景，其中一个AI“说服者”生成论点供AI“怀疑者”评估其内部观点是否改变，并融入了心理语言学维度。 **[conclusion/contribution]** \[AI generated\] The study found that arguments incorporating factual knowledge, trust markers, support expressions, and conveyed status were most persuasive to both AI agents and human judges, with humans showing a strong preference for knowledge-based arguments. \[翻译\] 研究发现，包含事实知识、信任标记、支持表达和地位传达的论点对AI智能体和人类评判者最具说服力，人类尤其偏好基于知识的论点。 **[limitation/future]** \[AI generated\] The study&#x27;s in-silico framework and single-topic focus may not fully capture the complexity of real-world human persuasion dynamics. \[翻译\] 该研究的计算机模拟框架和单一话题焦点可能无法完全捕捉现实世界人类说服动态的复杂性。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] Investigating whether LLM-generated arguments can persuade and if AI agents can simulate human-like opinion dynamics.<br>探究LLM生成的论点能否说服他人，以及AI智能体能否模拟类人的观点动态。\[翻译\]<br>**[innovation]** \[AI generated\] Proposes a synthetic persuasion dialogue framework using LLM agents to study opinion dynamics and identifies effective persuasive argument types.<br>\[翻译\]<br>提出了一个使用LLM智能体进行合成说服对话的框架来研究观点动力学，并识别出有效的说服性论据类型。<br>**[method]** \[AI generated\] Designed a synthetic persuasion dialogue on climate change, where an AI 'convincer' generates arguments for an AI 'skeptic' to evaluate opinion change, incorporating psycho-linguistic dimensions.<br>\[翻译\]<br>设计了一个关于气候变化的合成说服对话场景，其中一个AI“说服者”生成论点供AI“怀疑者”评估其内部观点是否改变，并融入了心理语言学维度。<br>**[conclusion/contribution]** \[AI generated\] The study found that arguments incorporating factual knowledge, trust markers, support expressions, and conveyed status were most persuasive to both AI agents and human judges, with humans showing a strong preference for knowledge-based arguments.<br>\[翻译\]<br>研究发现，包含事实知识、信任标记、支持表达和地位传达的论点对AI智能体和人类评判者最具说服力，人类尤其偏好基于知识的论点。<br>**[limitation/future]** \[AI generated\] The study's in-silico framework and single-topic focus may not fully capture the complexity of real-world human persuasion dynamics.<br>\[翻译\]<br>该研究的计算机模拟框架和单一话题焦点可能无法完全捕捉现实世界人类说服动态的复杂性。</div></details></div>|

### | Simulation and Deduction (6 papers)


### Social Simulation (4 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
|[![Star](https://img.shields.io/github/stars/FudanDISC/SocioVerse.svg?style=social&label=Star)](https://github.com/FudanDISC/SocioVerse)<br>[SocioVerse: A world model for social simulation powered by LLM agents and a pool of 10 million re...](http://arxiv.org/abs/2504.10157) <br> Xinnong Zhang, Jiayu Lin, Xinyi Mou, Shiyue Yang, Xiawei Liu, Libo Sun, Hanjia Lyu, Yihang Yang, Weihong Qi, Yue Chen, Guanying Li, ... <br> 2025-07-15|TLDR: SocioVerse is introduced, an LLM-agent-driven world model for social simulation that can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.|<img width="1200" alt="pipeline" src="figures/SocioVerse.png">| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] To address alignment challenges in environment, target users, interaction mechanisms, and behavioral patterns for social simulation. \[翻译\] 旨在解决社会模拟中环境、目标用户、交互机制和行为模式的对齐挑战。 **[innovation]** \[AI generated\] Proposes a world model with four alignment components and a 10-million-user pool for large-scale, credible social simulation. \[翻译\] 提出了一个包含四个对齐组件和千万级用户池的世界模型，用于大规模、可信的社会模拟。 **[method]** \[AI generated\] SocioVerse employs four alignment components and a pool of 10 million real users to drive LLM agents for social simulation. \[翻译\] SocioVerse采用四个对齐组件和一个包含1000万真实用户的池来驱动LLM智能体进行社会模拟。 **[conclusion/contribution]** \[AI generated\] SocioVerse demonstrates the ability to reflect large-scale population dynamics with diversity, credibility, and representativeness across political, news, and economic domains. \[翻译\] SocioVerse在政治、新闻和经济领域展现出模拟大规模人口动态的能力，并确保了多样性、可信度和代表性。 **[limitation/future]** \[AI generated\] The framework&#x27;s reliance on LLMs&#x27; inherent capabilities and the static nature of its massive user pool may limit adaptability to novel, unforeseen social dynamics. \[翻译\] 该框架对LLM固有能力及静态海量用户池的依赖，可能限制其对新颖、未预见社会动态的适应能力。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] To address alignment challenges in environment, target users, interaction mechanisms, and behavioral patterns for social simulation.<br>\[翻译\]<br>旨在解决社会模拟中环境、目标用户、交互机制和行为模式的对齐挑战。<br>**[innovation]** \[AI generated\] Proposes a world model with four alignment components and a 10-million-user pool for large-scale, credible social simulation.<br>\[翻译\]<br>提出了一个包含四个对齐组件和千万级用户池的世界模型，用于大规模、可信的社会模拟。<br>**[method]** \[AI generated\] SocioVerse employs four alignment components and a pool of 10 million real users to drive LLM agents for social simulation. \[翻译\] SocioVerse采用四个对齐组件和一个包含1000万真实用户的池来驱动LLM智能体进行社会模拟。<br>**[conclusion/contribution]** \[AI generated\] SocioVerse demonstrates the ability to reflect large-scale population dynamics with diversity, credibility, and representativeness across political, news, and economic domains.<br>\[翻译\]<br>SocioVerse在政治、新闻和经济领域展现出模拟大规模人口动态的能力，并确保了多样性、可信度和代表性。<br>**[limitation/future]** \[AI generated\] The framework's reliance on LLMs' inherent capabilities and the static nature of its massive user pool may limit adaptability to novel, unforeseen social dynamics.<br>\[翻译\]<br>该框架对LLM固有能力及静态海量用户池的依赖，可能限制其对新颖、未预见社会动态的适应能力。</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Understanding Online Polarization Through Human-Agent Interaction in a Synthetic LLM-Based Social...](https://ojs.aaai.org/index.php/ICWSM/article/view/35826) <br> Tim Donkers, Jürgen Ziegler <br> 2025-10-08 <br> <span style="color:cyan">[multi-category：[Social Simulation](#Social-Simulation-4-papers), [Macrosocial Phenomena Analysis](#Macrosocial-Phenomena-Analysis-1-papers)]</span>|\[AI generated\] This study uses a digital petri dish of AI agents to observe how online echo chambers amplify human polarization. \[翻译\] 这项研究利用AI智能体构成的数字培养皿，观察网络回音室如何放大人类观点的极化。|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction. \[翻译\] 通过受控的人机交互，研究极化在线环境如何影响个体感知与行为。 **[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics. \[翻译\] 提出了一种在基于LLM的合成社交网络中进行人机交互的新颖框架，用于实验性地研究极化动态。 **[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation. \[翻译\] 一种新颖的实验框架，使人类参与者能够在受控的合成社交网络模拟中与基于大语言模型的人工智能体进行互动。 **[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation. \[翻译\] 本研究利用基于大语言模型的社交模拟，提供了因果证据，表明极化的在线环境会增加情绪性和群体认同，同时减少不确定性。 **[limitation/future]** \[AI generated\] The study&#x27;s reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics. \[翻译\] 该研究依赖基于LLM的合成模拟，其发现推广到真实世界社交媒体动态的普适性可能受限。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction.<br>\[翻译\]<br>通过受控的人机交互，研究极化在线环境如何影响个体感知与行为。<br>**[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics.<br>\[翻译\]<br>提出了一种在基于LLM的合成社交网络中进行人机交互的新颖框架，用于实验性地研究极化动态。<br>**[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation.<br>\[翻译\]<br>一种新颖的实验框架，使人类参与者能够在受控的合成社交网络模拟中与基于大语言模型的人工智能体进行互动。<br>**[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation.<br>\[翻译\]<br>本研究利用基于大语言模型的社交模拟，提供了因果证据，表明极化的在线环境会增加情绪性和群体认同，同时减少不确定性。<br>**[limitation/future]** \[AI generated\] The study's reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics.<br>\[翻译\]<br>该研究依赖基于LLM的合成模拟，其发现推广到真实世界社交媒体动态的普适性可能受限。</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-Political%20Analysis-blue)]()<br>[Out of one, many: Using language models to simulate human samples](https://www.cambridge.org/core/journals/political-analysis/article/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49) <br> Lisa P. Argyle,Ethan C. Busby,Nancy Fulda2, Joshua R. Gubler,Christopher Rytting and David Wingate <br> 2023-07|让LLM模仿人类进行社会学实验，通过与真实情况对齐来判断LLM相关预测能力|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** LLM&#x27;s well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.  \[翻译\]模型复制社会偏见的倾向通常被视为缺陷，但本文将其重新视为一种潜在优势，认为这些偏见反映了内嵌于人类亚群体中复杂、细粒度的态度分布。 **[innovation]** \(i\) proposing the novel concept of “algorithmic fidelity” and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; \(ii\) introducing “silicon sampling,” a method that conditions models on real demographic backstories to generate representative virtual samples \[翻译\] \(i\) 提出“算法保真度”新概念及其四个标准，建立了量化LLM模拟人类群体效果的框架；\(ii\) 引入“硅采样”方法，基于真实人口背景故事对模型进行条件化，以生成有代表性的虚拟样本 **[method]** \(i\) extracting sociodemographic profiles from large-scale human surveys; \(ii\) constructing first-person narrative backstories as conditioning prompts; \(iii\) feeding these prompts into GPT-3 to generate responses \(“silicon samples”\) to specific questions; \(iv\) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.  \[翻译\] \(i\) 从大规模人类调查中提取社会人口学特征；\(ii\) 构建第一人称叙事背景故事作为条件化提示；\(iii\) 将这些提示输入GPT-3，以生成针对特定问题的回答（“硅样本”）；\(iv\) 从多维度统计上比较生成数据与原始人类数据，以验证算法保真度。\[通俗核心\]方法很简单，使用提示词模版填入符合人口统计特征的受访者特征，让LLM输出指定回答，与人类样本做对齐 **[conclusion/contribution]** The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions \(e.g., vote shares\) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.  \[翻译\] 研究表明GPT-3表现出高算法保真度：人类评估者难以区分其输出与人类文本，其生成的数据不仅紧密复现了聚合意见分布（如投票份额），还复现了真实人类数据中人口特征、态度和行为之间复杂的相关性结构。 **[limitation/future]** 提示词中显示标明角色身份，会让LLM过度重视，有走捷径之嫌">**[summary]**</summary><div style="margin-top:6px">**[motivation]** LLM's well-documented propensity to replicate societal biases is often viewed as a liability, but this paper reconsiders it as a potential asset, suggesting these biases reflect the complex, fine-grained attitudinal distributions embedded within human subpopulations.<br><br>\[翻译\]模型复制社会偏见的倾向通常被视为缺陷，但本文将其重新视为一种潜在优势，认为这些偏见反映了内嵌于人类亚群体中复杂、细粒度的态度分布。<br>**[innovation]** \(i\) proposing the novel concept of “algorithmic fidelity” and its four criteria, establishing a framework to quantify how well LLMs simulate human populations; \(ii\) introducing “silicon sampling,” a method that conditions models on real demographic backstories to generate representative virtual samples<br>\[翻译\] \(i\) 提出“算法保真度”新概念及其四个标准，建立了量化LLM模拟人类群体效果的框架；\(ii\) 引入“硅采样”方法，基于真实人口背景故事对模型进行条件化，以生成有代表性的虚拟样本<br>**[method]** \(i\) extracting sociodemographic profiles from large-scale human surveys; \(ii\) constructing first-person narrative backstories as conditioning prompts; \(iii\) feeding these prompts into GPT-3 to generate responses \(“silicon samples”\) to specific questions; \(iv\) statistically comparing the generated data with original human data to validate algorithmic fidelity across various metrics.<br><br>\[翻译\] \(i\) 从大规模人类调查中提取社会人口学特征；\(ii\) 构建第一人称叙事背景故事作为条件化提示；\(iii\) 将这些提示输入GPT-3，以生成针对特定问题的回答（“硅样本”）；\(iv\) 从多维度统计上比较生成数据与原始人类数据，以验证算法保真度。\[通俗核心\]方法很简单，使用提示词模版填入符合人口统计特征的受访者特征，让LLM输出指定回答，与人类样本做对齐<br>**[conclusion/contribution]** The study demonstrates that GPT-3 exhibits high algorithmic fidelity: human evaluators struggle to distinguish its outputs from human text, and its generated data closely replicates not only aggregate opinion distributions \(e.g., vote shares\) but also the complex correlational structures between demographics, attitudes, and behaviors found in real human data.<br><br>\[翻译\] 研究表明GPT-3表现出高算法保真度：人类评估者难以区分其输出与人类文本，其生成的数据不仅紧密复现了聚合意见分布（如投票份额），还复现了真实人类数据中人口特征、态度和行为之间复杂的相关性结构。<br>**[limitation/future]** 提示词中显示标明角色身份，会让LLM过度重视，有走捷径之嫌</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]Argyle et al. \(2023\) represent a pivotal shift from viewing LLMs as mere pattern recognition tools to employing them as tools for social simulation. Their work provides a paradigmatic methodology—centered on the concept of “algorithmic fidelity”—for experimentally testing whether and how the statistical predictions of an LLM align with nuanced human societal patterns. By conditioning GPT-3 on detailed demographic backstories within prompts \(“silicon sampling”\), they demonstrated that the model itself could generate attitudes and internal correlations that closely mirror those of real human subgroups. This marks a transition from goal-oriented text generation to the study of simulated social emergence.<br><br>\[翻译\]<br>Argyle等人\(2023\)的研究标志着一个关键转变：从将LLM视为单纯的模式识别工具，转向将其用作社会仿真的工具。他们的工作提供了一种范式方法——围绕“算法保真度”概念——来实验性地测试LLM的统计预测是否及如何与人类社会模式对齐。通过在提示词中为GPT-3施加详细的人口背景故事条件（“硅采样”），他们证明了该模型能够涌现出与真实人类亚群体高度吻合的态度及内部关联。标志着从目标导向的文本生成向模拟社会涌现研究的过渡</div></details></div></div>|
| [![Publish](https://img.shields.io/badge/Conference-EMNLP%20Findings-blue)]()<br>[Are Large Language Models \\(LLMs\\) Good Social Predictors?](https://aclanthology.org/2024.findings-emnlp.153) <br> Kaiqi Yang\*,Hang Li\*,Hongzhi Wen,Tai-Quan Peng,Jiliang Tang,Hui Liu <br> 2024|消融了最能影响预测结果的“意识形态自我定位”和“党派认同”，发现预测能力接近于随机|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** 论文Out of one, many: Using language models to simulate human samples可能利用了捷径特性，且能力难以从宏观细化到个体 **[innovation]** \[AI generated\] Proposes a novel social prediction benchmark \(Soc-PRF\) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts. \[翻译\]：提出了一个按特征可变性分类的新颖社会预测基准（Soc-PRF），以严格评估LLMs，并揭示了其对输入捷径的依赖。 **[method]** First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated “shortcut” inputs \(e.g., party ID\). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability \(low: demographics; high: attitudes/behaviors\). Three prediction settings are defined—low-to-high, high-to-low, and high-to-high—simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric. \[翻译\]：首先，在ANES投票数据集上进行复制和消融研究，量化了移除高度相关的“捷径”输入（如党派身份）后的性能下降。其次，使用盖洛普世界民意调查数据构建了一个新基准。特征按可变性分类（低：人口统计学特征；高：态度/行为）。定义了三种预测设定——低推高、高推低和高推高——以模拟现实的数据收集场景。在零样本提示下评估了多种LLMs，以AUC为主要指标。 **[conclusion/contribution]** The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels \(e.g., ~61% for GPT-3.5\). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs \(including GPT-4\) perform no better than random guessing \(AUC ~50\). \[翻译\]： 先前投票预测中的高性能消失，准确率下降至接近随机水平（例如，GPT-3.5约为61%）。在排除捷径的严格Soc-PRF设定中，所有测试的LLMs（包括GPT-4）的表现均不优于随机猜测（AUC ~50）。 **[limitation/future]** \[AI generated\] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. \[翻译\]：LLMs在社会预测中的优异表现严重依赖不现实的捷径特征，其使用普通输入泛化到真实场景的能力存疑。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** 论文Out of one, many: Using language models to simulate human samples可能利用了捷径特性，且能力难以从宏观细化到个体<br>**[innovation]** \[AI generated\] Proposes a novel social prediction benchmark \(Soc-PRF\) categorizing features by mutability to rigorously evaluate LLMs and reveals their reliance on input shortcuts.<br>\[翻译\]：提出了一个按特征可变性分类的新颖社会预测基准（Soc-PRF），以严格评估LLMs，并揭示了其对输入捷径的依赖。<br>**[method]** First, a replication and ablation study on the ANES voting dataset quantifies the performance drop when removing highly correlated “shortcut” inputs \(e.g., party ID\). Second, a new benchmark is constructed using Gallup World Poll data. Features are categorized by mutability \(low: demographics; high: attitudes/behaviors\). Three prediction settings are defined—low-to-high, high-to-low, and high-to-high—simulating realistic data collection scenarios. Multiple LLMs are evaluated under zero-shot prompting, with AUC as the primary metric.<br>\[翻译\]：首先，在ANES投票数据集上进行复制和消融研究，量化了移除高度相关的“捷径”输入（如党派身份）后的性能下降。其次，使用盖洛普世界民意调查数据构建了一个新基准。特征按可变性分类（低：人口统计学特征；高：态度/行为）。定义了三种预测设定——低推高、高推低和高推高——以模拟现实的数据收集场景。在零样本提示下评估了多种LLMs，以AUC为主要指标。<br>**[conclusion/contribution]** The high performance in prior voting prediction vanishes when shortcuts are removed, with accuracy dropping to near-random levels \(e.g., ~61% for GPT-3.5\). In the stringent Soc-PRF settings devoid of shortcuts, all tested LLMs \(including GPT-4\) perform no better than random guessing \(AUC ~50\). \[翻译\]： 先前投票预测中的高性能消失，准确率下降至接近随机水平（例如，GPT-3.5约为61%）。在排除捷径的严格Soc-PRF设定中，所有测试的LLMs（包括GPT-4）的表现均不优于随机猜测（AUC ~50）。<br>**[limitation/future]** \[AI generated\] The promising performance of LLMs in social prediction heavily relies on unrealistic shortcut features, and their ability to generalize to real-world scenarios with ordinary inputs remains questionable. \[翻译\]：LLMs在社会预测中的优异表现严重依赖不现实的捷径特征，其使用普通输入泛化到真实场景的能力存疑。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">\[引用文\]As the field evolves from pattern recognition towards social simulation and emergent understanding, a critical reassessment of our tools is imperative. Yang et al. \(2024\) provide a pivotal corrective in this transition. Their work challenges the optimistic narrative that LLMs can serve as accurate social predictors. They demonstrate that previously reported successes in tasks like vote prediction critically depended on "shortcut features" \(e.g., using party identification to predict vote choice\) and, by introducing a novel shortcut-free benchmark \(Soc-PRF\), reveal a significant gap. In settings devoid of such shortcuts, even state-of-the-art LLMs perform at random levels. This finding underscores a fundamental limitation: while current LLMs are excellent pattern recognizers of surface correlations, they lack the deeper causal or contextual reasoning necessary for genuine social simulation and the emergence of robust socio-behavioral understanding. Their research suggests that achieving true social fidelity requires moving beyond exploiting statistical artifacts in data.<br><br>\[翻译\]<br><br>随着该领域从模式识别向社会仿真与涌现性理解演进，对我们的工具进行批判性重估势在必行。Yang等人（2024）在这一转变中提供了一个关键修正。他们的工作挑战了“LLMs能作为准确社会预测器”的乐观论述。他们证明，先前在投票预测等任务中报告的成功，关键依赖于“捷径特征”（例如，用党派身份预测投票选择），并通过引入一个新颖的、无捷径的基准（Soc-PRF），揭示了一个显著的差距。在缺少此类捷径的设定中，即使是最先进的LLMs表现也处于随机水平。这一发现强调了一个根本性局限：当前的LLMs虽然是优秀的表面相关性模式识别器，但缺乏真正的社会仿真以及涌现出稳健社会行为理解所必需的、更深层的因果或语境推理能力。他们的研究表明，要实现真正的社会拟真度，需要超越对数据中统计假象的利用。</div></details></div></div>|

### Social Network Simulation (2 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Temporal Triadic Closure: Finding Dense Substructures in Social Networks That Evolve over Time](https://ojs.aaai.org/index.php/AAAI/article/view/34899) <br> Tom Davot, Jessica Enright, Jayakrishnan Madathil, Kitty Meeks <br> 2025-04-11|\[AI generated\] This method tracks evolving social clusters like watching shifting constellations in a night sky. \[翻译\]该方法追踪演化的社交集群，如同观测夜空中移动的星群。|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] Introducing the concept of temporal c-closed graphs to model the evolving triadic closure property in real-world social networks. \[翻译\] 引入时序c闭包图的概念，以建模现实世界社交网络中不断演化的三元闭包特性。 **[innovation]** \[AI generated\] Introduces the concept of temporal c-closed graphs to model evolving social networks and provides efficient algorithms for enumerating dense substructures within them. \[翻译\] 提出了时序c闭包图的概念来建模演化的社交网络，并为其稠密子结构的枚举提供了高效算法。 **[method]** \[AI generated\] Introduces the concept of temporal c-closed graphs, where edges form if vertices share enough common neighbors within a short time window. Studies enumeration algorithms for maximal cliques and dense subgraphs in such slowly evolving temporal graphs. \[翻译\] 提出了时序c-闭包图的概念，即若顶点在短时间内拥有足够多的共同邻居，则它们之间形成连接。研究了在此类缓慢演化的时序 **[conclusion/contribution]** \[AI generated\] Introduces temporal c-closed graphs and shows efficient enumeration of dense substructures in slowly evolving temporal networks. \[翻译\] 提出了时序c-闭图概念，并证明了在缓慢演化的时序网络中能高效枚举稠密子结构。 **[limitation/future]** \[AI generated\] The proposed temporal c-closure model and efficient algorithms rely on the assumption of slow network evolution, which may not hold for all real-world dynamic social networks. \[翻译\] 所提出的时序c-闭包模型及高效算法依赖于网络缓慢演化的假设，这一假设可能不适用于所有现实世界的动态社交网络。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] Introducing the concept of temporal c-closed graphs to model the evolving triadic closure property in real-world social networks.<br>\[翻译\]<br>引入时序c闭包图的概念，以建模现实世界社交网络中不断演化的三元闭包特性。<br>**[innovation]** \[AI generated\] Introduces the concept of temporal c-closed graphs to model evolving social networks and provides efficient algorithms for enumerating dense substructures within them.<br>\[翻译\]<br>提出了时序c闭包图的概念来建模演化的社交网络，并为其稠密子结构的枚举提供了高效算法。<br>**[method]** \[AI generated\] Introduces the concept of temporal c-closed graphs, where edges form if vertices share enough common neighbors within a short time window. Studies enumeration algorithms for maximal cliques and dense subgraphs in such slowly evolving temporal graphs.<br>\[翻译\]<br>提出了时序c-闭包图的概念，即若顶点在短时间内拥有足够多的共同邻居，则它们之间形成连接。研究了在此类缓慢演化的时序<br>**[conclusion/contribution]** \[AI generated\] Introduces temporal c-closed graphs and shows efficient enumeration of dense substructures in slowly evolving temporal networks.<br>\[翻译\]<br>提出了时序c-闭图概念，并证明了在缓慢演化的时序网络中能高效枚举稠密子结构。<br>**[limitation/future]** \[AI generated\] The proposed temporal c-closure model and efficient algorithms rely on the assumption of slow network evolution, which may not hold for all real-world dynamic social networks.<br>\[翻译\]<br>所提出的时序c-闭包模型及高效算法依赖于网络缓慢演化的假设，这一假设可能不适用于所有现实世界的动态社交网络。</div></details></div>|
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[LIN: Latent Influence Network for Discovering Hidden Directed Influence Links on Social Media](https://ojs.aaai.org/index.php/ICWSM/article/view/35842) <br> Chenhao Gu, Zainab Razia Zaidi, Ling Luo, Shanika Karunasekera <br> 2025-06-07|\[AI generated\] LIN acts like a social X-ray, revealing hidden influence pathways by analyzing user behavior patterns.  <br>\[翻译\]  <br>LIN如同社交X光，通过分析用户行为模式揭示隐藏的影响力路径。|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] To discover hidden and complex pathways of influence beyond apparent user interactions on social media. \[翻译\] 旨在发现社交媒体上超越显性用户交互的、隐藏且复杂的影响路径。 **[innovation]** \[AI generated\] Proposes a Latent Influence Network \(LIN\) within the LIDET framework to discover hidden directed influence links from user behavior, significantly outperforming traditional models. \[翻译\] 提出了潜在影响网络（LIN）及LIDET框架，通过用户行为发现隐藏的有向影响链路，性能显著优于传统模型。 **[method]** \[AI generated\] Proposes the Latent Influence Network \(LIN\) within the LIDET framework, which identifies optimal network configurations based on user behavior labels to reveal hidden influence pathways. \[翻译\] 提出了潜在影响网络（LIN）及其检测框架LIDET，该框架基于用户行为标签识别最优网络配置，以揭示隐藏的影响路径。 **[conclusion/contribution]** \[AI generated\] LIN significantly outperforms traditional models in revealing hidden influence pathways, achieving 99% accuracy in a COVID-19 case study. \[翻译\] LIN在揭示隐藏影响路径方面显著优于传统模型，在COVID-19案例研究中实现了99%的分类准确率。 **[limitation/future]** \[AI generated\] The framework&#x27;s performance heavily depends on the quality and granularity of user behavior labels, which may not always be available or reliable. \[翻译\] 该框架的性能严重依赖于用户行为标签的质量和粒度，而这些标签可能并非总是可用或可靠。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] To discover hidden and complex pathways of influence beyond apparent user interactions on social media.<br>\[翻译\]<br>旨在发现社交媒体上超越显性用户交互的、隐藏且复杂的影响路径。<br>**[innovation]** \[AI generated\] Proposes a Latent Influence Network \(LIN\) within the LIDET framework to discover hidden directed influence links from user behavior, significantly outperforming traditional models.<br>\[翻译\]<br>提出了潜在影响网络（LIN）及LIDET框架，通过用户行为发现隐藏的有向影响链路，性能显著优于传统模型。<br>**[method]** \[AI generated\] Proposes the Latent Influence Network \(LIN\) within the LIDET framework, which identifies optimal network configurations based on user behavior labels to reveal hidden influence pathways.<br>\[翻译\]<br>提出了潜在影响网络（LIN）及其检测框架LIDET，该框架基于用户行为标签识别最优网络配置，以揭示隐藏的影响路径。<br>**[conclusion/contribution]** \[AI generated\] LIN significantly outperforms traditional models in revealing hidden influence pathways, achieving 99% accuracy in a COVID-19 case study.<br>\[翻译\]<br>LIN在揭示隐藏影响路径方面显著优于传统模型，在COVID-19案例研究中实现了99%的分类准确率。<br>**[limitation/future]** \[AI generated\] The framework's performance heavily depends on the quality and granularity of user behavior labels, which may not always be available or reliable.<br>\[翻译\]<br>该框架的性能严重依赖于用户行为标签的质量和粒度，而这些标签可能并非总是可用或可靠。</div></details><div style="margin-top:6px"><details><summary>**[notes]**</summary><div style="margin-top:6px">【之前的精读论文】</div></details></div></div>|

### Macrosocial Phenomena Analysis (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-AAAI-blue)]()<br>[Understanding Online Polarization Through Human-Agent Interaction in a Synthetic LLM-Based Social...](https://ojs.aaai.org/index.php/ICWSM/article/view/35826) <br> Tim Donkers, Jürgen Ziegler <br> 2025-10-08 <br> <span style="color:cyan">[multi-category：[Social Simulation](#Social-Simulation-4-papers), [Macrosocial Phenomena Analysis](#Macrosocial-Phenomena-Analysis-1-papers)]</span>|\[AI generated\] This study uses a digital petri dish of AI agents to observe how online echo chambers amplify human polarization. \[翻译\] 这项研究利用AI智能体构成的数字培养皿，观察网络回音室如何放大人类观点的极化。|| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction. \[翻译\] 通过受控的人机交互，研究极化在线环境如何影响个体感知与行为。 **[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics. \[翻译\] 提出了一种在基于LLM的合成社交网络中进行人机交互的新颖框架，用于实验性地研究极化动态。 **[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation. \[翻译\] 一种新颖的实验框架，使人类参与者能够在受控的合成社交网络模拟中与基于大语言模型的人工智能体进行互动。 **[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation. \[翻译\] 本研究利用基于大语言模型的社交模拟，提供了因果证据，表明极化的在线环境会增加情绪性和群体认同，同时减少不确定性。 **[limitation/future]** \[AI generated\] The study&#x27;s reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics. \[翻译\] 该研究依赖基于LLM的合成模拟，其发现推广到真实世界社交媒体动态的普适性可能受限。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] Investigating how polarized online environments influence individual perceptions and behaviors through controlled human-agent interaction.<br>\[翻译\]<br>通过受控的人机交互，研究极化在线环境如何影响个体感知与行为。<br>**[innovation]** \[AI generated\] Proposes a novel human-agent interaction framework within a synthetic LLM-based social network to experimentally study polarization dynamics.<br>\[翻译\]<br>提出了一种在基于LLM的合成社交网络中进行人机交互的新颖框架，用于实验性地研究极化动态。<br>**[method]** \[AI generated\] A novel experimental framework that enables human participants to interact with LLM-based artificial agents within a controlled, synthetic social network simulation.<br>\[翻译\]<br>一种新颖的实验框架，使人类参与者能够在受控的合成社交网络模拟中与基于大语言模型的人工智能体进行互动。<br>**[conclusion/contribution]** \[AI generated\] This study provides causal evidence that polarized online environments increase emotionality and group identity while reducing uncertainty, using a novel LLM-based social simulation.<br>\[翻译\]<br>本研究利用基于大语言模型的社交模拟，提供了因果证据，表明极化的在线环境会增加情绪性和群体认同，同时减少不确定性。<br>**[limitation/future]** \[AI generated\] The study's reliance on a synthetic, LLM-based simulation may limit the generalizability of its findings to real-world social media dynamics.<br>\[翻译\]<br>该研究依赖基于LLM的合成模拟，其发现推广到真实世界社交媒体动态的普适性可能受限。</div></details></div>|

### | Other (1 papers)

| Title & Info | Analogy Summary | Pipeline | Summary |
|:--| :---: | :----: | :---: |
| [![Publish](https://img.shields.io/badge/Conference-ICWSM-blue)]()<br>[The persuasive power of large language models](https://ojs.aaai.org/index.php/ICWSM/article/view/31304) <br> Simon Martin Breum, Daniel V?dele Egdal, Victor Gram Mortensen, Anders Giovanni M?ller, Luca Maria Aiello <br> 2024-05-28 <br> <span style="color:cyan">[multi-category：[Social Bots](#Social-Bots-1-papers), [Other](#-Other-1-papers)]</span>|TLDR: 显示了SIRS过程在具有大型扩展子图的图（例如社交网络模型）上的生存时间的阈值行为，显示了随机图的严格阈值。|<div style="display:flex;flex-direction:column;gap:6px;align-items:center"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Persuasive-Power1.png"><img width="1000" style="display:block;margin:6px auto" alt="pipeline" src="figures/Persuasive-Power2.png"></div>| <div style="line-height: 1.05;font-size: 0.8em"> <details><summary title="**[motivation]** \[AI generated\] Investigating whether LLM-generated arguments can persuade and if AI agents can simulate human-like opinion dynamics. 探究LLM生成的论点能否说服他人，以及AI智能体能否模拟类人的观点动态。\[翻译\] **[innovation]** \[AI generated\] Proposes a synthetic persuasion dialogue framework using LLM agents to study opinion dynamics and identifies effective persuasive argument types. \[翻译\] 提出了一个使用LLM智能体进行合成说服对话的框架来研究观点动力学，并识别出有效的说服性论据类型。 **[method]** \[AI generated\] Designed a synthetic persuasion dialogue on climate change, where an AI &#x27;convincer&#x27; generates arguments for an AI &#x27;skeptic&#x27; to evaluate opinion change, incorporating psycho-linguistic dimensions. \[翻译\] 设计了一个关于气候变化的合成说服对话场景，其中一个AI“说服者”生成论点供AI“怀疑者”评估其内部观点是否改变，并融入了心理语言学维度。 **[conclusion/contribution]** \[AI generated\] The study found that arguments incorporating factual knowledge, trust markers, support expressions, and conveyed status were most persuasive to both AI agents and human judges, with humans showing a strong preference for knowledge-based arguments. \[翻译\] 研究发现，包含事实知识、信任标记、支持表达和地位传达的论点对AI智能体和人类评判者最具说服力，人类尤其偏好基于知识的论点。 **[limitation/future]** \[AI generated\] The study&#x27;s in-silico framework and single-topic focus may not fully capture the complexity of real-world human persuasion dynamics. \[翻译\] 该研究的计算机模拟框架和单一话题焦点可能无法完全捕捉现实世界人类说服动态的复杂性。">**[summary]**</summary><div style="margin-top:6px">**[motivation]** \[AI generated\] Investigating whether LLM-generated arguments can persuade and if AI agents can simulate human-like opinion dynamics.<br>探究LLM生成的论点能否说服他人，以及AI智能体能否模拟类人的观点动态。\[翻译\]<br>**[innovation]** \[AI generated\] Proposes a synthetic persuasion dialogue framework using LLM agents to study opinion dynamics and identifies effective persuasive argument types.<br>\[翻译\]<br>提出了一个使用LLM智能体进行合成说服对话的框架来研究观点动力学，并识别出有效的说服性论据类型。<br>**[method]** \[AI generated\] Designed a synthetic persuasion dialogue on climate change, where an AI 'convincer' generates arguments for an AI 'skeptic' to evaluate opinion change, incorporating psycho-linguistic dimensions.<br>\[翻译\]<br>设计了一个关于气候变化的合成说服对话场景，其中一个AI“说服者”生成论点供AI“怀疑者”评估其内部观点是否改变，并融入了心理语言学维度。<br>**[conclusion/contribution]** \[AI generated\] The study found that arguments incorporating factual knowledge, trust markers, support expressions, and conveyed status were most persuasive to both AI agents and human judges, with humans showing a strong preference for knowledge-based arguments.<br>\[翻译\]<br>研究发现，包含事实知识、信任标记、支持表达和地位传达的论点对AI智能体和人类评判者最具说服力，人类尤其偏好基于知识的论点。<br>**[limitation/future]** \[AI generated\] The study's in-silico framework and single-topic focus may not fully capture the complexity of real-world human persuasion dynamics.<br>\[翻译\]<br>该研究的计算机模拟框架和单一话题焦点可能无法完全捕捉现实世界人类说服动态的复杂性。</div></details></div>|

=====List End=====
## Acknowledgement