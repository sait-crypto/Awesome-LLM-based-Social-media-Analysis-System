"""
é¡¹ç›®å…¥å£2ï¼šå°†æ›´æ–°æ–‡ä»¶ï¼ˆCSV/JSONï¼‰çš„å†…å®¹æ›´æ–°åˆ°æ ¸å¿ƒæ•°æ®åº“ï¼ˆCSVï¼‰
"""
import os
import sys
from typing import Dict, List, Tuple

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.core.config_loader import get_config_instance
from src.core.database_manager import DatabaseManager
from src.core.database_model import Paper, is_same_identity
from src.ai_generator import AIGenerator
from src.utils import get_current_timestamp, backup_file
from src.core.update_file_utils import get_update_file_utils

class UpdateProcessor:
    """æ›´æ–°å¤„ç†å™¨"""
    
    def __init__(self):
        self.config = get_config_instance()
        self.settings = get_config_instance().settings
        self.db_manager = DatabaseManager()
        self.ai_generator = AIGenerator()
        self.update_utils = get_update_file_utils()
        
        # è·å–æ‰€æœ‰å¯èƒ½çš„æ›´æ–°æ–‡ä»¶è·¯å¾„
        self.update_files = []
        paths = self.settings['paths']
        
        # æ ‡å‡†æ›´æ–°æ–‡ä»¶
        for k in ['update_csv', 'update_json', 'my_update_csv', 'my_update_json']:
            if paths.get(k):
                self.update_files.append(paths[k])
                
        # é¢å¤–æ›´æ–°æ–‡ä»¶
        extra = paths.get('extra_update_files_list', [])
        self.update_files.extend(extra)

        # å…¶ä»–é…ç½®
        self.default_contributor = self.settings['database']['default_contributor']
        self.ai_generate_mark = self.settings['ai'].get('ai_generate_mark', '[AI generated]')
        
        # å…¼å®¹é…ç½®é¡¹ä¸º bool æˆ– str
        remove_val = self.settings['database'].get('remove_added_paper_in_template', 'false')
        self.is_remove_added_paper = str(remove_val).lower() == 'true'

        # è¿™é‡Œçš„ enable_ai_generation æ§åˆ¶è‡ªåŠ¨æµç¨‹
        self.enable_ai = str(self.settings['ai'].get('enable_ai_generation', 'true')).lower() == 'true'
    
    def process_updates(self, conflict_resolution: str = 'mark') -> Dict:
        """
        å¤„ç†æ›´æ–°æ–‡ä»¶
        conflict_resolution: 'mark', 'skip', 'replace'
        """
        result = {
            'success': False,
            'new_papers': 0,
            'updated_papers': 0,
            'conflicts': [],
            'errors': [],
            'ai_generated': 0,
            'invalid_msg': []
        }
        
        # è¿‡æ»¤æœ‰æ•ˆæ–‡ä»¶
        valid_files = [f for f in self.update_files if f and os.path.exists(f)]
        
        if not valid_files:
            result['errors'].append("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ›´æ–°æ–‡ä»¶")
            return result

        print(f"æ£€æµ‹åˆ° {len(valid_files)} ä¸ªæ›´æ–°æ–‡ä»¶ï¼Œå¼€å§‹é€ä¸€å¤„ç†...")

        total_added_papers = []
        total_conflict_papers = []
        
        for file_path in valid_files:
            print(f"\nğŸ“--- å¤„ç†æ–‡ä»¶: {os.path.basename(file_path)} ---")
            
            # 1. åŠ è½½è®ºæ–‡
            try:
                current_papers = self.update_utils.read_data(file_path)
            except Exception as e:
                err = f"åŠ è½½æ–‡ä»¶ {file_path} å¤±è´¥: {e}"
                result['errors'].append(err)
                print(err)
                continue

            if not current_papers:
                print(f"âš  æ–‡ä»¶ä¸­æ²¡æœ‰è®ºæ–‡æ•°æ®")
                continue

            print(f"è¯»å–åˆ° {len(current_papers)} ç¯‡è®ºæ–‡")

            # 2. æœ¬åœ°å»é‡ (æ–‡ä»¶å†…å»é‡)
            unique_papers = self._deduplicate_papers(current_papers)
            if len(unique_papers) < len(current_papers):
                print(f"å»é‡åå‰©ä½™ {len(unique_papers)} ç¯‡è®ºæ–‡")

            # 3. æ•°æ®é¢„å¤„ç†
            valid_papers = []
            for paper in unique_papers:


                # æ—¶é—´æˆ³
                if not paper.submission_time:
                    paper.submission_time = get_current_timestamp()
                
                # è´¡çŒ®è€…
                if not paper.contributor:
                    paper.contributor = self.default_contributor
                
                # éªŒè¯
                valid, errors, _ = paper.validate_paper_fields(
                    self.config, check_required=True, check_non_empty=True, no_normalize=False
                )
                
                if not valid:
                    error_msg = f"[{os.path.basename(file_path)}] éªŒè¯å¤±è´¥: {paper.title[:30]}... - {', '.join(errors[:2])}"
                    result['errors'].append(error_msg)
                    # å³ä½¿éªŒè¯å¤±è´¥ï¼Œå¦‚æœæ˜¯é…ç½®ä¸ºä¸è·³è¿‡ï¼Œæˆ–è€…ä¸ºäº†ä¿ç•™æ•°æ®ï¼Œè¿™é‡Œæˆ‘ä»¬å…ˆä¸æ·»åŠ 
                    # ç­–ç•¥ï¼šåªæœ‰éªŒè¯é€šè¿‡çš„æ‰è‡ªåŠ¨å…¥åº“
                    print(f"è­¦å‘Š: {error_msg} (å·²è·³è¿‡å…¥åº“)")
                else:
                    valid_papers.append(paper)
            
            if not valid_papers:
                continue

            # 4. AI ç”Ÿæˆ (å¦‚æœå¯ç”¨)
            if self.enable_ai and self.ai_generator.is_available():
                print("ä½¿ç”¨AIç”Ÿæˆç¼ºå¤±å†…å®¹...")
                try:
                    enhanced_papers, is_enhanced = self.ai_generator.batch_enhance_papers(valid_papers)
                    valid_papers = enhanced_papers # æ›´æ–°å¼•ç”¨
                    
                    if is_enhanced:
                        # å›å†™åˆ°å½“å‰æ›´æ–°æ–‡ä»¶
                        try:
                            self.update_utils.persist_ai_generated_to_update_files(valid_papers, file_path)
                            print(f"AIå†…å®¹å·²å›å†™è‡³ {os.path.basename(file_path)}")
                        except Exception as e:
                            result['errors'].append(f"å›å†™AIå†…å®¹å¤±è´¥: {e}")
                        
                        # ç»Ÿè®¡
                        ai_count = 0
                        for p in valid_papers:
                            # ç®€å•æ£€æŸ¥æ˜¯å¦æœ‰ AI æ ‡è®°
                            if self.ai_generate_mark in str(p.to_dict()): 
                                ai_count += 1
                        result['ai_generated'] += ai_count
                except Exception as e:
                    result['errors'].append(f"AIç”Ÿæˆå¤±è´¥: {e}")

            # 5. æ·»åŠ åˆ°æ•°æ®åº“
            print(f"æ­£åœ¨æ›´æ–° {len(valid_papers)} ç¯‡è®ºæ–‡åˆ°æ•°æ®åº“...")
            try:
                added, conflicts, inv_msgs = self.db_manager.add_papers(
                    valid_papers, 
                    conflict_resolution
                )
                total_added_papers.extend(added)
                total_conflict_papers.extend(conflicts)
                result['invalid_msg'].extend(inv_msgs)
                result['new_papers'] += len(added)
            except Exception as e:
                err = f"æ•°æ®åº“æ“ä½œå¤±è´¥ ({file_path}): {e}"
                result['errors'].append(err)
                print(f"é”™è¯¯: {err}")
                continue

            # 6. ä»æ›´æ–°æ–‡ä»¶ç§»é™¤å·²å¤„ç†è®ºæ–‡
            if self.is_remove_added_paper:
                try:
                    # ä» valid_papers ä¸­æ‰¾å‡ºé‚£äº›å·²ç»æˆåŠŸ add æˆ– æ ‡è®°ä¸º conflict çš„
                    processed = added + conflicts
                    if processed:
                        # é‡æ–°è¯»å–å½“å‰æ–‡ä»¶ï¼ˆé˜²æ­¢è¦†ç›–æœŸé—´çš„å˜åŠ¨ï¼‰ï¼Œè¿‡æ»¤æ‰ processed
                        current_file_papers = self.update_utils.read_data(file_path)
                        remaining = []
                        
                        processed_keys = {p.get_key() for p in processed}
                        
                        for p in current_file_papers:
                            if p.get_key() not in processed_keys:
                                remaining.append(p)
                        
                        if len(remaining) < len(current_file_papers):
                            # å¤‡ä»½
                            backup_file(file_path, self.settings['paths']['backup_dir'])
                            # å†™å…¥
                            self.update_utils.write_data(file_path, remaining)
                            print(f"ğŸ—‘ï¸ å·²ä» {os.path.basename(file_path)} ç§»é™¤ {len(current_file_papers)-len(remaining)} ç¯‡å·²å¤„ç†è®ºæ–‡")
                            
                except Exception as e:
                    result['errors'].append(f"æ¸…ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}")

        # æ•´ç†å†²çªä¿¡æ¯
        conflicts_list = []
        # æ³¨æ„: add_papers è¿”å›çš„ conflicts å·²ç»æ˜¯ Paper å¯¹è±¡åˆ—è¡¨ï¼ˆå·²æ ‡è®°ï¼‰
        # è¿™é‡Œä¸ºäº† result æ˜¾ç¤ºï¼Œæˆ‘ä»¬éœ€è¦æ„é€ ä¸€ä¸‹ info
        for p in total_conflict_papers:
            conflicts_list.append({
                'new': p.to_dict(),
                'existing': None # ç®€åŒ–ï¼Œä¸å†æŸ¥æ‰¾æ—§å¯¹è±¡ï¼Œå› ä¸º new_p å·²ç» merge è¿›å»äº†
            })
        result['conflicts'] = conflicts_list
        result['invalid_msg'] = list(set(result['invalid_msg']))

        if result['new_papers'] > 0 or result['conflicts'] or result['ai_generated'] > 0:
            result['success'] = True

        return result
    
    def _deduplicate_papers(self, papers: List[Paper]) -> List[Paper]:
        """å»é‡è®ºæ–‡åˆ—è¡¨"""
        unique = []
        seen_keys = set()
        for p in papers:
            k = p.get_key()
            # å¦‚æœ DOI å’Œ Title éƒ½ä¸ºç©ºï¼Œè·³è¿‡
            if not k[0] and not k[1]:
                continue
            if k in seen_keys:
                continue
            seen_keys.add(k)
            unique.append(p)
        return unique
    
    def print_result(self, result: Dict):
        """æ‰“å°ç»“æœ"""
        print("\n" + "="*50)
        print("æ›´æ–°å¤„ç†å®Œæˆ")
        print("="*50)
        
        if result['success']:
            print(f"âœ“ æˆåŠŸæ·»åŠ  {result['new_papers']} ç¯‡æ–°è®ºæ–‡")
            if result['ai_generated'] > 0:
                print(f"âœ“ AIç”Ÿæˆäº† {result['ai_generated']} å¤„å†…å®¹")
            if result['conflicts']:
                print(f"âš  å‘ç° {len(result['conflicts'])} å¤„å†²çªï¼Œå·²æ ‡è®°å¹¶æ·»åŠ ï¼Œè¯·åœ¨ GUI ä¸­æœç´¢ '{self.settings['database']['conflict_marker']}' å¤„ç†")
        else:
            print("- æ²¡æœ‰äº§ç”Ÿæœ‰æ•ˆæ›´æ–°")
            
        if result['errors']:
            print("\nâŒ é”™è¯¯:")
            for e in result['errors']: print(f"  - {e}")
            
        if result['invalid_msg']:
            print(f"\nâš  æ•°æ®åº“æ ¼å¼è­¦å‘Š ({len(result['invalid_msg'])}):")
            for m in result['invalid_msg'][:5]: print(f"  - {m}")
            if len(result['invalid_msg']) > 5: print("  ...")

def main():
    print("å¼€å§‹å¤„ç†æ›´æ–°...")
    processor = UpdateProcessor()
    result = processor.process_updates(conflict_resolution='mark')
    processor.print_result(result)
    
    if result['success']:
        print("\næ­£åœ¨é‡æ–°ç”Ÿæˆ README...")
        try:
            from src.convert import ReadmeGenerator
            gen = ReadmeGenerator()
            if gen.update_readme_file():
                print("âœ“ README æ›´æ–°æˆåŠŸ")
            else:
                print("âŒ README æ›´æ–°å¤±è´¥")
        except Exception as e:
            print(f"âŒ README ç”Ÿæˆå‡ºé”™: {e}")

if __name__ == "__main__":
    main()